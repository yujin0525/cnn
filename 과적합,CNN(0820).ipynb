{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과적합 : 와인종류 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 업데이트하기  \n",
    "에포크마다 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.29722, saving model to ./model\\01-0.2972.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.29722 to 0.25425, saving model to ./model\\02-0.2543.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.25425 to 0.23356, saving model to ./model\\03-0.2336.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23356 to 0.21444, saving model to ./model\\04-0.2144.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21444 to 0.19984, saving model to ./model\\05-0.1998.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.19984 to 0.19539, saving model to ./model\\06-0.1954.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.19539 to 0.19016, saving model to ./model\\07-0.1902.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.19016\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.19016 to 0.18586, saving model to ./model\\09-0.1859.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.18586 to 0.18406, saving model to ./model\\10-0.1841.hdf5\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.18406\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.18406 to 0.17748, saving model to ./model\\12-0.1775.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.17748 to 0.17532, saving model to ./model\\13-0.1753.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.17532 to 0.17184, saving model to ./model\\14-0.1718.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.17184 to 0.16910, saving model to ./model\\15-0.1691.hdf5\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16910\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.16910 to 0.16181, saving model to ./model\\17-0.1618.hdf5\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16181\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.16181 to 0.15618, saving model to ./model\\19-0.1562.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.15618 to 0.15234, saving model to ./model\\20-0.1523.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.15234 to 0.14853, saving model to ./model\\21-0.1485.hdf5\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.14853 to 0.14607, saving model to ./model\\22-0.1461.hdf5\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.14607\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.14607 to 0.14017, saving model to ./model\\24-0.1402.hdf5\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.14017 to 0.13896, saving model to ./model\\25-0.1390.hdf5\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.13896 to 0.13648, saving model to ./model\\26-0.1365.hdf5\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.13648 to 0.13404, saving model to ./model\\27-0.1340.hdf5\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.13404\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.13404 to 0.12704, saving model to ./model\\29-0.1270.hdf5\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.12704 to 0.12473, saving model to ./model\\30-0.1247.hdf5\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.12473 to 0.12384, saving model to ./model\\31-0.1238.hdf5\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.12384 to 0.12259, saving model to ./model\\32-0.1226.hdf5\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.12259 to 0.11661, saving model to ./model\\33-0.1166.hdf5\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.11661 to 0.11613, saving model to ./model\\34-0.1161.hdf5\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.11613 to 0.11273, saving model to ./model\\35-0.1127.hdf5\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.11273\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.11273\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.11273 to 0.10735, saving model to ./model\\38-0.1074.hdf5\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.10735 to 0.10549, saving model to ./model\\39-0.1055.hdf5\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.10549\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.10549\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.10549 to 0.09682, saving model to ./model\\42-0.0968.hdf5\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.09682 to 0.09665, saving model to ./model\\43-0.0967.hdf5\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.09665\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.09665 to 0.09266, saving model to ./model\\45-0.0927.hdf5\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.09266 to 0.09130, saving model to ./model\\46-0.0913.hdf5\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.09130\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.09130\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.09130 to 0.08785, saving model to ./model\\49-0.0879.hdf5\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.08785 to 0.08720, saving model to ./model\\50-0.0872.hdf5\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.08720 to 0.08371, saving model to ./model\\51-0.0837.hdf5\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.08371\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.08371\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.08371\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.08371 to 0.07985, saving model to ./model\\55-0.0798.hdf5\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.07985 to 0.07835, saving model to ./model\\56-0.0784.hdf5\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.07835 to 0.07805, saving model to ./model\\57-0.0781.hdf5\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.07805\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.07805 to 0.07646, saving model to ./model\\59-0.0765.hdf5\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.07646 to 0.07473, saving model to ./model\\60-0.0747.hdf5\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.07473\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.07473\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.07473\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.07473 to 0.07291, saving model to ./model\\64-0.0729.hdf5\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.07291\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.07291 to 0.07016, saving model to ./model\\66-0.0702.hdf5\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.07016\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.07016 to 0.06992, saving model to ./model\\68-0.0699.hdf5\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.06992\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.06992\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.06992 to 0.06726, saving model to ./model\\71-0.0673.hdf5\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.06726\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.06726\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.06726 to 0.06652, saving model to ./model\\74-0.0665.hdf5\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.06652\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.06652\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.06652 to 0.06574, saving model to ./model\\77-0.0657.hdf5\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.06574 to 0.06550, saving model to ./model\\78-0.0655.hdf5\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.06550\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.06550\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.06550\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.06550 to 0.06544, saving model to ./model\\82-0.0654.hdf5\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.06544 to 0.06391, saving model to ./model\\83-0.0639.hdf5\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.06391 to 0.06286, saving model to ./model\\84-0.0629.hdf5\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.06286\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.06286\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.06286\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.06286 to 0.06137, saving model to ./model\\88-0.0614.hdf5\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.06137\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.06137\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.06137\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.06137\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.06137 to 0.06019, saving model to ./model\\93-0.0602.hdf5\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.06019\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.06019\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.06019 to 0.06018, saving model to ./model\\96-0.0602.hdf5\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.06018\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.06018 to 0.05950, saving model to ./model\\98-0.0595.hdf5\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.05950\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.05950\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.05950 to 0.05810, saving model to ./model\\101-0.0581.hdf5\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.05810\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.05810\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.05810 to 0.05765, saving model to ./model\\104-0.0577.hdf5\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.05765 to 0.05686, saving model to ./model\\105-0.0569.hdf5\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.05686\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.05686\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.05686\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.05686\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.05686\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.05686 to 0.05665, saving model to ./model\\111-0.0567.hdf5\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.05665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00113: val_loss improved from 0.05665 to 0.05583, saving model to ./model\\113-0.0558.hdf5\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.05583\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.05583\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.05583\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.05583 to 0.05531, saving model to ./model\\117-0.0553.hdf5\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.05531\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.05531\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.05531\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.05531\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.05531\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.05531\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.05531\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.05531 to 0.05483, saving model to ./model\\125-0.0548.hdf5\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.05483\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.05483\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.05483 to 0.05457, saving model to ./model\\128-0.0546.hdf5\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.05457\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.05457 to 0.05359, saving model to ./model\\130-0.0536.hdf5\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.05359\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.05359\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.05359\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.05359\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.05359 to 0.05315, saving model to ./model\\135-0.0532.hdf5\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.05315\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.05315\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.05315\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.05315\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.05315\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.05315 to 0.05294, saving model to ./model\\141-0.0529.hdf5\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.05294\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.05294\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.05294\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.05294\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.05294\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.05294 to 0.05247, saving model to ./model\\147-0.0525.hdf5\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.05247\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.05247\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.05247\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.05247\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.05247\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.05247\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.05247\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.05247\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.05247 to 0.05240, saving model to ./model\\156-0.0524.hdf5\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.05240\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.05240\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.05240\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.05240\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.05240\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.05240 to 0.05213, saving model to ./model\\162-0.0521.hdf5\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.05213\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.05213\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.05213\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.05213 to 0.05133, saving model to ./model\\166-0.0513.hdf5\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.05133\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.05133 to 0.05058, saving model to ./model\\197-0.0506.hdf5\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.05058\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.05058\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.05058\n",
      "  1/204 [..............................] - ETA: 0s - loss: 0.0275 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "204/204 [==============================] - 0s 590us/step - loss: 0.0454 - accuracy: 0.9877\n",
      "Accuracy:0.9876866340637207\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "\n",
    "seed=0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "df_pre=pd.read_csv('C:/Users/user/machine_learning1/wine.csv',header=None)\n",
    "df=df_pre.sample(frac=1) #100% 읽어옴 frac=1\n",
    "dataset=df.values\n",
    "X=dataset[:,0:12]   \n",
    "Y=dataset[:,12] \n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(30,input_dim=12,activation='relu'))\n",
    "model.add(Dense(12,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "MODEL_DIR='./model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "modelpath='./model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "#save_best_only=True : 에포크가 진행되면서 모든 값이 저장되는 것이 아니라, 테스트 오차를 실행한 결과값이 향상되었을 때에만 저장됨\n",
    "checkpointer=ModelCheckpoint(filepath=modelpath,monitor='val_loss',verbose=1,save_best_only=True) \n",
    "\n",
    "hist=model.fit(X,Y,validation_split=0.2,epochs=200,batch_size=200,verbose=0,callbacks=[checkpointer])\n",
    "\n",
    "print('Accuracy:{}'.format(model.evaluate(X,Y)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과적합 그래프  \n",
    "학습이 진행될수록, 학습셋의 정확도 상승 but 과적합으로 인해 테스트셋의 오차는 감소하다가 증가함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#모델 실행 및 저장\n",
    "#hist=model.fit(X,Y,validation_split=0.33,epochs=3500,batch_size=500)\n",
    "\n",
    "#테스트셋으로 실험결과의 오차값을 저장\n",
    "y_vloss=hist.history['val_loss']\n",
    "\n",
    "#학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc=hist.history['accuracy']\n",
    "\n",
    "#x값을 지정하고 정확도를 파란색으로,오차를 빨간색으로\n",
    "x_len=np.arange(len(y_acc))\n",
    "plt.plot(x_len,y_vloss,'o',c='red',markersize=3)\n",
    "plt.plot(x_len,y_acc,'o',c='blue',markersize=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EarlyStopping() : 과적합을 멈추게 하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.7851 - accuracy: 0.7720\n",
      "Epoch 00001: val_loss improved from inf to 0.57246, saving model to ./model\\01-0.5725.hdf5\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7844 - accuracy: 0.7596 - val_loss: 0.5725 - val_accuracy: 0.7795\n",
      "Epoch 2/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6172 - accuracy: 0.7660\n",
      "Epoch 00002: val_loss improved from 0.57246 to 0.41434, saving model to ./model\\02-0.4143.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5981 - accuracy: 0.7642 - val_loss: 0.4143 - val_accuracy: 0.7826\n",
      "Epoch 3/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4303 - accuracy: 0.7800\n",
      "Epoch 00003: val_loss improved from 0.41434 to 0.32497, saving model to ./model\\03-0.3250.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4410 - accuracy: 0.7718 - val_loss: 0.3250 - val_accuracy: 0.7950\n",
      "Epoch 4/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3603 - accuracy: 0.7840\n",
      "Epoch 00004: val_loss did not improve from 0.32497\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3739 - accuracy: 0.7734 - val_loss: 0.3308 - val_accuracy: 0.8416\n",
      "Epoch 5/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3731 - accuracy: 0.7980\n",
      "Epoch 00005: val_loss did not improve from 0.32497\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.8101 - val_loss: 0.3423 - val_accuracy: 0.9068\n",
      "Epoch 6/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3942 - accuracy: 0.8400\n",
      "Epoch 00006: val_loss did not improve from 0.32497\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3818 - accuracy: 0.8499 - val_loss: 0.3260 - val_accuracy: 0.9193\n",
      "Epoch 7/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3676 - accuracy: 0.8680\n",
      "Epoch 00007: val_loss improved from 0.32497 to 0.30584, saving model to ./model\\07-0.3058.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3588 - accuracy: 0.8698 - val_loss: 0.3058 - val_accuracy: 0.9130\n",
      "Epoch 8/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3336 - accuracy: 0.8740\n",
      "Epoch 00008: val_loss improved from 0.30584 to 0.29170, saving model to ./model\\08-0.2917.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3363 - accuracy: 0.8760 - val_loss: 0.2917 - val_accuracy: 0.9099\n",
      "Epoch 9/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3084 - accuracy: 0.8860\n",
      "Epoch 00009: val_loss improved from 0.29170 to 0.28683, saving model to ./model\\09-0.2868.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3218 - accuracy: 0.8821 - val_loss: 0.2868 - val_accuracy: 0.9037\n",
      "Epoch 10/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3293 - accuracy: 0.8740\n",
      "Epoch 00010: val_loss improved from 0.28683 to 0.28629, saving model to ./model\\10-0.2863.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3148 - accuracy: 0.8806 - val_loss: 0.2863 - val_accuracy: 0.8944\n",
      "Epoch 11/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3196 - accuracy: 0.8780\n",
      "Epoch 00011: val_loss did not improve from 0.28629\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3131 - accuracy: 0.8806 - val_loss: 0.2864 - val_accuracy: 0.8913\n",
      "Epoch 12/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2964 - accuracy: 0.8980\n",
      "Epoch 00012: val_loss improved from 0.28629 to 0.28582, saving model to ./model\\12-0.2858.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3126 - accuracy: 0.8867 - val_loss: 0.2858 - val_accuracy: 0.8851\n",
      "Epoch 13/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3112 - accuracy: 0.9020\n",
      "Epoch 00013: val_loss improved from 0.28582 to 0.28362, saving model to ./model\\13-0.2836.hdf5\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3110 - accuracy: 0.8928 - val_loss: 0.2836 - val_accuracy: 0.8913\n",
      "Epoch 14/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2789 - accuracy: 0.9060\n",
      "Epoch 00014: val_loss improved from 0.28362 to 0.27969, saving model to ./model\\14-0.2797.hdf5\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3086 - accuracy: 0.8913 - val_loss: 0.2797 - val_accuracy: 0.8944\n",
      "Epoch 15/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3203 - accuracy: 0.8940\n",
      "Epoch 00015: val_loss improved from 0.27969 to 0.27448, saving model to ./model\\15-0.2745.hdf5\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3041 - accuracy: 0.8943 - val_loss: 0.2745 - val_accuracy: 0.9037\n",
      "Epoch 16/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.3100 - accuracy: 0.8940\n",
      "Epoch 00016: val_loss improved from 0.27448 to 0.26895, saving model to ./model\\16-0.2690.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2990 - accuracy: 0.8989 - val_loss: 0.2690 - val_accuracy: 0.9037\n",
      "Epoch 17/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2918 - accuracy: 0.8980\n",
      "Epoch 00017: val_loss improved from 0.26895 to 0.26441, saving model to ./model\\17-0.2644.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2934 - accuracy: 0.8989 - val_loss: 0.2644 - val_accuracy: 0.9037\n",
      "Epoch 18/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2822 - accuracy: 0.9000\n",
      "Epoch 00018: val_loss improved from 0.26441 to 0.26094, saving model to ./model\\18-0.2609.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2890 - accuracy: 0.8989 - val_loss: 0.2609 - val_accuracy: 0.9068\n",
      "Epoch 19/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2720 - accuracy: 0.9120\n",
      "Epoch 00019: val_loss improved from 0.26094 to 0.25845, saving model to ./model\\19-0.2585.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2855 - accuracy: 0.9051 - val_loss: 0.2585 - val_accuracy: 0.9130\n",
      "Epoch 20/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2520 - accuracy: 0.9200\n",
      "Epoch 00020: val_loss improved from 0.25845 to 0.25746, saving model to ./model\\20-0.2575.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2818 - accuracy: 0.9066 - val_loss: 0.2575 - val_accuracy: 0.9161\n",
      "Epoch 21/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2679 - accuracy: 0.9180\n",
      "Epoch 00021: val_loss did not improve from 0.25746\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2801 - accuracy: 0.9081 - val_loss: 0.2581 - val_accuracy: 0.9130\n",
      "Epoch 22/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2788 - accuracy: 0.9080\n",
      "Epoch 00022: val_loss did not improve from 0.25746\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2787 - accuracy: 0.9081 - val_loss: 0.2586 - val_accuracy: 0.9099\n",
      "Epoch 23/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2927 - accuracy: 0.9040\n",
      "Epoch 00023: val_loss improved from 0.25746 to 0.25717, saving model to ./model\\23-0.2572.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2776 - accuracy: 0.9142 - val_loss: 0.2572 - val_accuracy: 0.9130\n",
      "Epoch 24/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2715 - accuracy: 0.9180\n",
      "Epoch 00024: val_loss improved from 0.25717 to 0.25360, saving model to ./model\\24-0.2536.hdf5\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2747 - accuracy: 0.9142 - val_loss: 0.2536 - val_accuracy: 0.9130\n",
      "Epoch 25/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2778 - accuracy: 0.9040\n",
      "Epoch 00025: val_loss improved from 0.25360 to 0.25026, saving model to ./model\\25-0.2503.hdf5\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2701 - accuracy: 0.9112 - val_loss: 0.2503 - val_accuracy: 0.9130\n",
      "Epoch 26/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2666 - accuracy: 0.9120\n",
      "Epoch 00026: val_loss improved from 0.25026 to 0.24851, saving model to ./model\\26-0.2485.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2668 - accuracy: 0.9066 - val_loss: 0.2485 - val_accuracy: 0.9161\n",
      "Epoch 27/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2826 - accuracy: 0.8980\n",
      "Epoch 00027: val_loss improved from 0.24851 to 0.24818, saving model to ./model\\27-0.2482.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2639 - accuracy: 0.9066 - val_loss: 0.2482 - val_accuracy: 0.9130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2647 - accuracy: 0.9040\n",
      "Epoch 00028: val_loss did not improve from 0.24818\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2632 - accuracy: 0.9051 - val_loss: 0.2482 - val_accuracy: 0.9130\n",
      "Epoch 29/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2525 - accuracy: 0.9100\n",
      "Epoch 00029: val_loss improved from 0.24818 to 0.24746, saving model to ./model\\29-0.2475.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2623 - accuracy: 0.9035 - val_loss: 0.2475 - val_accuracy: 0.9130\n",
      "Epoch 30/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2469 - accuracy: 0.9040\n",
      "Epoch 00030: val_loss improved from 0.24746 to 0.24529, saving model to ./model\\30-0.2453.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2603 - accuracy: 0.9035 - val_loss: 0.2453 - val_accuracy: 0.9161\n",
      "Epoch 31/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2664 - accuracy: 0.8980\n",
      "Epoch 00031: val_loss improved from 0.24529 to 0.24297, saving model to ./model\\31-0.2430.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2578 - accuracy: 0.9035 - val_loss: 0.2430 - val_accuracy: 0.9130\n",
      "Epoch 32/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2714 - accuracy: 0.9020\n",
      "Epoch 00032: val_loss improved from 0.24297 to 0.24118, saving model to ./model\\32-0.2412.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2552 - accuracy: 0.9081 - val_loss: 0.2412 - val_accuracy: 0.9130\n",
      "Epoch 33/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2301 - accuracy: 0.9180\n",
      "Epoch 00033: val_loss improved from 0.24118 to 0.23980, saving model to ./model\\33-0.2398.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2527 - accuracy: 0.9112 - val_loss: 0.2398 - val_accuracy: 0.9130\n",
      "Epoch 34/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2754 - accuracy: 0.9000\n",
      "Epoch 00034: val_loss improved from 0.23980 to 0.23863, saving model to ./model\\34-0.2386.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2513 - accuracy: 0.9127 - val_loss: 0.2386 - val_accuracy: 0.9161\n",
      "Epoch 35/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2517 - accuracy: 0.9160\n",
      "Epoch 00035: val_loss improved from 0.23863 to 0.23729, saving model to ./model\\35-0.2373.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2495 - accuracy: 0.9142 - val_loss: 0.2373 - val_accuracy: 0.9161\n",
      "Epoch 36/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2376 - accuracy: 0.9220\n",
      "Epoch 00036: val_loss improved from 0.23729 to 0.23601, saving model to ./model\\36-0.2360.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2478 - accuracy: 0.9158 - val_loss: 0.2360 - val_accuracy: 0.9193\n",
      "Epoch 37/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2252 - accuracy: 0.9320\n",
      "Epoch 00037: val_loss improved from 0.23601 to 0.23486, saving model to ./model\\37-0.2349.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2459 - accuracy: 0.9204 - val_loss: 0.2349 - val_accuracy: 0.9224\n",
      "Epoch 38/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2494 - accuracy: 0.9180\n",
      "Epoch 00038: val_loss improved from 0.23486 to 0.23357, saving model to ./model\\38-0.2336.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2441 - accuracy: 0.9204 - val_loss: 0.2336 - val_accuracy: 0.9255\n",
      "Epoch 39/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2448 - accuracy: 0.9220\n",
      "Epoch 00039: val_loss improved from 0.23357 to 0.23191, saving model to ./model\\39-0.2319.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2425 - accuracy: 0.9204 - val_loss: 0.2319 - val_accuracy: 0.9255\n",
      "Epoch 40/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2378 - accuracy: 0.9180\n",
      "Epoch 00040: val_loss improved from 0.23191 to 0.23021, saving model to ./model\\40-0.2302.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2407 - accuracy: 0.9204 - val_loss: 0.2302 - val_accuracy: 0.9255\n",
      "Epoch 41/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2443 - accuracy: 0.9180\n",
      "Epoch 00041: val_loss improved from 0.23021 to 0.22872, saving model to ./model\\41-0.2287.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2383 - accuracy: 0.9204 - val_loss: 0.2287 - val_accuracy: 0.9255\n",
      "Epoch 42/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2469 - accuracy: 0.9120\n",
      "Epoch 00042: val_loss improved from 0.22872 to 0.22735, saving model to ./model\\42-0.2273.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2362 - accuracy: 0.9204 - val_loss: 0.2273 - val_accuracy: 0.9255\n",
      "Epoch 43/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2337 - accuracy: 0.9300\n",
      "Epoch 00043: val_loss improved from 0.22735 to 0.22617, saving model to ./model\\43-0.2262.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2343 - accuracy: 0.9219 - val_loss: 0.2262 - val_accuracy: 0.9255\n",
      "Epoch 44/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2354 - accuracy: 0.9160\n",
      "Epoch 00044: val_loss improved from 0.22617 to 0.22507, saving model to ./model\\44-0.2251.hdf5\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2323 - accuracy: 0.9219 - val_loss: 0.2251 - val_accuracy: 0.9255\n",
      "Epoch 45/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2358 - accuracy: 0.9240\n",
      "Epoch 00045: val_loss improved from 0.22507 to 0.22388, saving model to ./model\\45-0.2239.hdf5\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2304 - accuracy: 0.9219 - val_loss: 0.2239 - val_accuracy: 0.9255\n",
      "Epoch 46/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2382 - accuracy: 0.9200\n",
      "Epoch 00046: val_loss improved from 0.22388 to 0.22270, saving model to ./model\\46-0.2227.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2284 - accuracy: 0.9219 - val_loss: 0.2227 - val_accuracy: 0.9255\n",
      "Epoch 47/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2250 - accuracy: 0.9220\n",
      "Epoch 00047: val_loss improved from 0.22270 to 0.22163, saving model to ./model\\47-0.2216.hdf5\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2264 - accuracy: 0.9219 - val_loss: 0.2216 - val_accuracy: 0.9255\n",
      "Epoch 48/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2232 - accuracy: 0.9280\n",
      "Epoch 00048: val_loss improved from 0.22163 to 0.22063, saving model to ./model\\48-0.2206.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2245 - accuracy: 0.9234 - val_loss: 0.2206 - val_accuracy: 0.9317\n",
      "Epoch 49/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2162 - accuracy: 0.9300\n",
      "Epoch 00049: val_loss improved from 0.22063 to 0.21939, saving model to ./model\\49-0.2194.hdf5\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2226 - accuracy: 0.9250 - val_loss: 0.2194 - val_accuracy: 0.9317\n",
      "Epoch 50/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2237 - accuracy: 0.9280\n",
      "Epoch 00050: val_loss improved from 0.21939 to 0.21770, saving model to ./model\\50-0.2177.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2210 - accuracy: 0.9250 - val_loss: 0.2177 - val_accuracy: 0.9286\n",
      "Epoch 51/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2264 - accuracy: 0.9200\n",
      "Epoch 00051: val_loss improved from 0.21770 to 0.21600, saving model to ./model\\51-0.2160.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2193 - accuracy: 0.9250 - val_loss: 0.2160 - val_accuracy: 0.9317\n",
      "Epoch 52/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2060 - accuracy: 0.9300\n",
      "Epoch 00052: val_loss improved from 0.21600 to 0.21432, saving model to ./model\\52-0.2143.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2176 - accuracy: 0.9250 - val_loss: 0.2143 - val_accuracy: 0.9348\n",
      "Epoch 53/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2282 - accuracy: 0.9200\n",
      "Epoch 00053: val_loss improved from 0.21432 to 0.21285, saving model to ./model\\53-0.2129.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2165 - accuracy: 0.9234 - val_loss: 0.2129 - val_accuracy: 0.9348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2090 - accuracy: 0.9280\n",
      "Epoch 00054: val_loss improved from 0.21285 to 0.21130, saving model to ./model\\54-0.2113.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2150 - accuracy: 0.9250 - val_loss: 0.2113 - val_accuracy: 0.9348\n",
      "Epoch 55/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2278 - accuracy: 0.9200\n",
      "Epoch 00055: val_loss improved from 0.21130 to 0.21019, saving model to ./model\\55-0.2102.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2136 - accuracy: 0.9265 - val_loss: 0.2102 - val_accuracy: 0.9348\n",
      "Epoch 56/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2031 - accuracy: 0.9340\n",
      "Epoch 00056: val_loss improved from 0.21019 to 0.20932, saving model to ./model\\56-0.2093.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2129 - accuracy: 0.9265 - val_loss: 0.2093 - val_accuracy: 0.9379\n",
      "Epoch 57/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2221 - accuracy: 0.9220\n",
      "Epoch 00057: val_loss improved from 0.20932 to 0.20829, saving model to ./model\\57-0.2083.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2115 - accuracy: 0.9280 - val_loss: 0.2083 - val_accuracy: 0.9379\n",
      "Epoch 58/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2133 - accuracy: 0.9220\n",
      "Epoch 00058: val_loss improved from 0.20829 to 0.20747, saving model to ./model\\58-0.2075.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2105 - accuracy: 0.9265 - val_loss: 0.2075 - val_accuracy: 0.9410\n",
      "Epoch 59/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2084 - accuracy: 0.9260\n",
      "Epoch 00059: val_loss improved from 0.20747 to 0.20663, saving model to ./model\\59-0.2066.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2096 - accuracy: 0.9265 - val_loss: 0.2066 - val_accuracy: 0.9410\n",
      "Epoch 60/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2070 - accuracy: 0.9300\n",
      "Epoch 00060: val_loss improved from 0.20663 to 0.20585, saving model to ./model\\60-0.2058.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2088 - accuracy: 0.9265 - val_loss: 0.2058 - val_accuracy: 0.9410\n",
      "Epoch 61/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2162 - accuracy: 0.9220\n",
      "Epoch 00061: val_loss improved from 0.20585 to 0.20510, saving model to ./model\\61-0.2051.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2081 - accuracy: 0.9265 - val_loss: 0.2051 - val_accuracy: 0.9410\n",
      "Epoch 62/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2117 - accuracy: 0.9200\n",
      "Epoch 00062: val_loss improved from 0.20510 to 0.20432, saving model to ./model\\62-0.2043.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2076 - accuracy: 0.9280 - val_loss: 0.2043 - val_accuracy: 0.9410\n",
      "Epoch 63/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2144 - accuracy: 0.9280\n",
      "Epoch 00063: val_loss improved from 0.20432 to 0.20340, saving model to ./model\\63-0.2034.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2070 - accuracy: 0.9280 - val_loss: 0.2034 - val_accuracy: 0.9410\n",
      "Epoch 64/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2237 - accuracy: 0.9220\n",
      "Epoch 00064: val_loss improved from 0.20340 to 0.20246, saving model to ./model\\64-0.2025.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2064 - accuracy: 0.9296 - val_loss: 0.2025 - val_accuracy: 0.9410\n",
      "Epoch 65/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2057 - accuracy: 0.9260\n",
      "Epoch 00065: val_loss improved from 0.20246 to 0.20167, saving model to ./model\\65-0.2017.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2058 - accuracy: 0.9296 - val_loss: 0.2017 - val_accuracy: 0.9410\n",
      "Epoch 66/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2124 - accuracy: 0.9320\n",
      "Epoch 00066: val_loss improved from 0.20167 to 0.20093, saving model to ./model\\66-0.2009.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2051 - accuracy: 0.9296 - val_loss: 0.2009 - val_accuracy: 0.9410\n",
      "Epoch 67/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2013 - accuracy: 0.9280\n",
      "Epoch 00067: val_loss improved from 0.20093 to 0.20014, saving model to ./model\\67-0.2001.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2044 - accuracy: 0.9296 - val_loss: 0.2001 - val_accuracy: 0.9410\n",
      "Epoch 68/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2022 - accuracy: 0.9320\n",
      "Epoch 00068: val_loss improved from 0.20014 to 0.19930, saving model to ./model\\68-0.1993.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2037 - accuracy: 0.9296 - val_loss: 0.1993 - val_accuracy: 0.9410\n",
      "Epoch 69/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1915 - accuracy: 0.9300\n",
      "Epoch 00069: val_loss improved from 0.19930 to 0.19853, saving model to ./model\\69-0.1985.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2032 - accuracy: 0.9296 - val_loss: 0.1985 - val_accuracy: 0.9410\n",
      "Epoch 70/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2004 - accuracy: 0.9240\n",
      "Epoch 00070: val_loss improved from 0.19853 to 0.19783, saving model to ./model\\70-0.1978.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2026 - accuracy: 0.9296 - val_loss: 0.1978 - val_accuracy: 0.9441\n",
      "Epoch 71/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2032 - accuracy: 0.9320\n",
      "Epoch 00071: val_loss improved from 0.19783 to 0.19731, saving model to ./model\\71-0.1973.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2022 - accuracy: 0.9296 - val_loss: 0.1973 - val_accuracy: 0.9441\n",
      "Epoch 72/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2015 - accuracy: 0.9260\n",
      "Epoch 00072: val_loss improved from 0.19731 to 0.19685, saving model to ./model\\72-0.1968.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2017 - accuracy: 0.9280 - val_loss: 0.1968 - val_accuracy: 0.9472\n",
      "Epoch 73/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2050 - accuracy: 0.9240\n",
      "Epoch 00073: val_loss improved from 0.19685 to 0.19645, saving model to ./model\\73-0.1965.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2013 - accuracy: 0.9280 - val_loss: 0.1965 - val_accuracy: 0.9472\n",
      "Epoch 74/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1925 - accuracy: 0.9340\n",
      "Epoch 00074: val_loss improved from 0.19645 to 0.19625, saving model to ./model\\74-0.1963.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2008 - accuracy: 0.9296 - val_loss: 0.1963 - val_accuracy: 0.9472\n",
      "Epoch 75/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2031 - accuracy: 0.9280\n",
      "Epoch 00075: val_loss improved from 0.19625 to 0.19599, saving model to ./model\\75-0.1960.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2006 - accuracy: 0.9296 - val_loss: 0.1960 - val_accuracy: 0.9472\n",
      "Epoch 76/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1998 - accuracy: 0.9280\n",
      "Epoch 00076: val_loss improved from 0.19599 to 0.19549, saving model to ./model\\76-0.1955.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2000 - accuracy: 0.9296 - val_loss: 0.1955 - val_accuracy: 0.9472\n",
      "Epoch 77/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1859 - accuracy: 0.9340\n",
      "Epoch 00077: val_loss improved from 0.19549 to 0.19519, saving model to ./model\\77-0.1952.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1992 - accuracy: 0.9296 - val_loss: 0.1952 - val_accuracy: 0.9472\n",
      "Epoch 78/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1950 - accuracy: 0.9340\n",
      "Epoch 00078: val_loss did not improve from 0.19519\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1989 - accuracy: 0.9311 - val_loss: 0.1957 - val_accuracy: 0.9503\n",
      "Epoch 79/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2048 - accuracy: 0.9220\n",
      "Epoch 00079: val_loss did not improve from 0.19519\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1994 - accuracy: 0.9296 - val_loss: 0.1959 - val_accuracy: 0.9472\n",
      "Epoch 80/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2171 - accuracy: 0.9180\n",
      "Epoch 00080: val_loss improved from 0.19519 to 0.19487, saving model to ./model\\80-0.1949.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1990 - accuracy: 0.9296 - val_loss: 0.1949 - val_accuracy: 0.9472\n",
      "Epoch 81/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1853 - accuracy: 0.9340\n",
      "Epoch 00081: val_loss improved from 0.19487 to 0.19417, saving model to ./model\\81-0.1942.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1984 - accuracy: 0.9311 - val_loss: 0.1942 - val_accuracy: 0.9472\n",
      "Epoch 82/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1846 - accuracy: 0.9320\n",
      "Epoch 00082: val_loss improved from 0.19417 to 0.19396, saving model to ./model\\82-0.1940.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1969 - accuracy: 0.9311 - val_loss: 0.1940 - val_accuracy: 0.9472\n",
      "Epoch 83/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2085 - accuracy: 0.9300\n",
      "Epoch 00083: val_loss did not improve from 0.19396\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1964 - accuracy: 0.9326 - val_loss: 0.1942 - val_accuracy: 0.9472\n",
      "Epoch 84/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2020 - accuracy: 0.9280\n",
      "Epoch 00084: val_loss did not improve from 0.19396\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1962 - accuracy: 0.9311 - val_loss: 0.1948 - val_accuracy: 0.9441\n",
      "Epoch 85/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2223 - accuracy: 0.9220\n",
      "Epoch 00085: val_loss did not improve from 0.19396\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1965 - accuracy: 0.9311 - val_loss: 0.1955 - val_accuracy: 0.9441\n",
      "Epoch 86/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2052 - accuracy: 0.9280\n",
      "Epoch 00086: val_loss did not improve from 0.19396\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1968 - accuracy: 0.9311 - val_loss: 0.1955 - val_accuracy: 0.9441\n",
      "Epoch 87/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1988 - accuracy: 0.9280\n",
      "Epoch 00087: val_loss did not improve from 0.19396\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1966 - accuracy: 0.9311 - val_loss: 0.1944 - val_accuracy: 0.9441\n",
      "Epoch 88/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1982 - accuracy: 0.9340\n",
      "Epoch 00088: val_loss improved from 0.19396 to 0.19252, saving model to ./model\\88-0.1925.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1958 - accuracy: 0.9311 - val_loss: 0.1925 - val_accuracy: 0.9472\n",
      "Epoch 89/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1911 - accuracy: 0.9400\n",
      "Epoch 00089: val_loss improved from 0.19252 to 0.19149, saving model to ./model\\89-0.1915.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1944 - accuracy: 0.9326 - val_loss: 0.1915 - val_accuracy: 0.9472\n",
      "Epoch 90/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1873 - accuracy: 0.9360\n",
      "Epoch 00090: val_loss improved from 0.19149 to 0.19098, saving model to ./model\\90-0.1910.hdf5\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1940 - accuracy: 0.9326 - val_loss: 0.1910 - val_accuracy: 0.9472\n",
      "Epoch 91/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1977 - accuracy: 0.9340\n",
      "Epoch 00091: val_loss improved from 0.19098 to 0.19081, saving model to ./model\\91-0.1908.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1934 - accuracy: 0.9326 - val_loss: 0.1908 - val_accuracy: 0.9472\n",
      "Epoch 92/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1905 - accuracy: 0.9380\n",
      "Epoch 00092: val_loss improved from 0.19081 to 0.19064, saving model to ./model\\92-0.1906.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1931 - accuracy: 0.9326 - val_loss: 0.1906 - val_accuracy: 0.9472\n",
      "Epoch 93/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2037 - accuracy: 0.9340\n",
      "Epoch 00093: val_loss improved from 0.19064 to 0.19039, saving model to ./model\\93-0.1904.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1927 - accuracy: 0.9326 - val_loss: 0.1904 - val_accuracy: 0.9472\n",
      "Epoch 94/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1804 - accuracy: 0.9400\n",
      "Epoch 00094: val_loss improved from 0.19039 to 0.19032, saving model to ./model\\94-0.1903.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1923 - accuracy: 0.9311 - val_loss: 0.1903 - val_accuracy: 0.9472\n",
      "Epoch 95/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1829 - accuracy: 0.9360\n",
      "Epoch 00095: val_loss did not improve from 0.19032\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1919 - accuracy: 0.9326 - val_loss: 0.1903 - val_accuracy: 0.9472\n",
      "Epoch 96/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1838 - accuracy: 0.9400\n",
      "Epoch 00096: val_loss improved from 0.19032 to 0.19025, saving model to ./model\\96-0.1902.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1916 - accuracy: 0.9326 - val_loss: 0.1902 - val_accuracy: 0.9472\n",
      "Epoch 97/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1917 - accuracy: 0.9300\n",
      "Epoch 00097: val_loss improved from 0.19025 to 0.19014, saving model to ./model\\97-0.1901.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1913 - accuracy: 0.9326 - val_loss: 0.1901 - val_accuracy: 0.9472\n",
      "Epoch 98/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1864 - accuracy: 0.9340\n",
      "Epoch 00098: val_loss improved from 0.19014 to 0.18995, saving model to ./model\\98-0.1900.hdf5\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1910 - accuracy: 0.9326 - val_loss: 0.1900 - val_accuracy: 0.9472\n",
      "Epoch 99/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1982 - accuracy: 0.9320\n",
      "Epoch 00099: val_loss improved from 0.18995 to 0.18973, saving model to ./model\\99-0.1897.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1907 - accuracy: 0.9342 - val_loss: 0.1897 - val_accuracy: 0.9503\n",
      "Epoch 100/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1634 - accuracy: 0.9440\n",
      "Epoch 00100: val_loss improved from 0.18973 to 0.18955, saving model to ./model\\100-0.1895.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1906 - accuracy: 0.9326 - val_loss: 0.1895 - val_accuracy: 0.9503\n",
      "Epoch 101/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2014 - accuracy: 0.9320\n",
      "Epoch 00101: val_loss improved from 0.18955 to 0.18942, saving model to ./model\\101-0.1894.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1905 - accuracy: 0.9326 - val_loss: 0.1894 - val_accuracy: 0.9503\n",
      "Epoch 102/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1869 - accuracy: 0.9340\n",
      "Epoch 00102: val_loss improved from 0.18942 to 0.18904, saving model to ./model\\102-0.1890.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1903 - accuracy: 0.9326 - val_loss: 0.1890 - val_accuracy: 0.9503\n",
      "Epoch 103/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2118 - accuracy: 0.9240\n",
      "Epoch 00103: val_loss improved from 0.18904 to 0.18879, saving model to ./model\\103-0.1888.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1896 - accuracy: 0.9326 - val_loss: 0.1888 - val_accuracy: 0.9503\n",
      "Epoch 104/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1818 - accuracy: 0.9360\n",
      "Epoch 00104: val_loss did not improve from 0.18879\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1890 - accuracy: 0.9357 - val_loss: 0.1889 - val_accuracy: 0.9472\n",
      "Epoch 105/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1976 - accuracy: 0.9320\n",
      "Epoch 00105: val_loss improved from 0.18879 to 0.18865, saving model to ./model\\105-0.1886.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1889 - accuracy: 0.9342 - val_loss: 0.1886 - val_accuracy: 0.9472\n",
      "Epoch 106/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2122 - accuracy: 0.9220\n",
      "Epoch 00106: val_loss improved from 0.18865 to 0.18830, saving model to ./model\\106-0.1883.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1890 - accuracy: 0.9342 - val_loss: 0.1883 - val_accuracy: 0.9472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1813 - accuracy: 0.9440\n",
      "Epoch 00107: val_loss did not improve from 0.18830\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1889 - accuracy: 0.9342 - val_loss: 0.1883 - val_accuracy: 0.9472\n",
      "Epoch 108/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2101 - accuracy: 0.9240\n",
      "Epoch 00108: val_loss improved from 0.18830 to 0.18719, saving model to ./model\\108-0.1872.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1887 - accuracy: 0.9342 - val_loss: 0.1872 - val_accuracy: 0.9472\n",
      "Epoch 109/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1956 - accuracy: 0.9280\n",
      "Epoch 00109: val_loss improved from 0.18719 to 0.18610, saving model to ./model\\109-0.1861.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1877 - accuracy: 0.9342 - val_loss: 0.1861 - val_accuracy: 0.9472\n",
      "Epoch 110/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1868 - accuracy: 0.9320\n",
      "Epoch 00110: val_loss improved from 0.18610 to 0.18495, saving model to ./model\\110-0.1849.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1869 - accuracy: 0.9342 - val_loss: 0.1849 - val_accuracy: 0.9472\n",
      "Epoch 111/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1831 - accuracy: 0.9380\n",
      "Epoch 00111: val_loss improved from 0.18495 to 0.18438, saving model to ./model\\111-0.1844.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1864 - accuracy: 0.9357 - val_loss: 0.1844 - val_accuracy: 0.9503\n",
      "Epoch 112/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1882 - accuracy: 0.9360\n",
      "Epoch 00112: val_loss improved from 0.18438 to 0.18422, saving model to ./model\\112-0.1842.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1864 - accuracy: 0.9342 - val_loss: 0.1842 - val_accuracy: 0.9503\n",
      "Epoch 113/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1892 - accuracy: 0.9280\n",
      "Epoch 00113: val_loss improved from 0.18422 to 0.18395, saving model to ./model\\113-0.1839.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1864 - accuracy: 0.9342 - val_loss: 0.1839 - val_accuracy: 0.9503\n",
      "Epoch 114/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1858 - accuracy: 0.9320\n",
      "Epoch 00114: val_loss improved from 0.18395 to 0.18374, saving model to ./model\\114-0.1837.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1861 - accuracy: 0.9342 - val_loss: 0.1837 - val_accuracy: 0.9503\n",
      "Epoch 115/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2003 - accuracy: 0.9280\n",
      "Epoch 00115: val_loss improved from 0.18374 to 0.18366, saving model to ./model\\115-0.1837.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1855 - accuracy: 0.9357 - val_loss: 0.1837 - val_accuracy: 0.9503\n",
      "Epoch 116/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1947 - accuracy: 0.9320\n",
      "Epoch 00116: val_loss improved from 0.18366 to 0.18344, saving model to ./model\\116-0.1834.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1849 - accuracy: 0.9357 - val_loss: 0.1834 - val_accuracy: 0.9472\n",
      "Epoch 117/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1919 - accuracy: 0.9340\n",
      "Epoch 00117: val_loss improved from 0.18344 to 0.18301, saving model to ./model\\117-0.1830.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1845 - accuracy: 0.9357 - val_loss: 0.1830 - val_accuracy: 0.9472\n",
      "Epoch 118/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2031 - accuracy: 0.9240\n",
      "Epoch 00118: val_loss improved from 0.18301 to 0.18290, saving model to ./model\\118-0.1829.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1844 - accuracy: 0.9357 - val_loss: 0.1829 - val_accuracy: 0.9472\n",
      "Epoch 119/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2018 - accuracy: 0.9280\n",
      "Epoch 00119: val_loss did not improve from 0.18290\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1840 - accuracy: 0.9357 - val_loss: 0.1835 - val_accuracy: 0.9441\n",
      "Epoch 120/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1839 - accuracy: 0.9360\n",
      "Epoch 00120: val_loss did not improve from 0.18290\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1843 - accuracy: 0.9342 - val_loss: 0.1838 - val_accuracy: 0.9441\n",
      "Epoch 121/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1805 - accuracy: 0.9360\n",
      "Epoch 00121: val_loss did not improve from 0.18290\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1842 - accuracy: 0.9342 - val_loss: 0.1832 - val_accuracy: 0.9441\n",
      "Epoch 122/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1768 - accuracy: 0.9380\n",
      "Epoch 00122: val_loss improved from 0.18290 to 0.18232, saving model to ./model\\122-0.1823.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1838 - accuracy: 0.9342 - val_loss: 0.1823 - val_accuracy: 0.9441\n",
      "Epoch 123/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1867 - accuracy: 0.9300\n",
      "Epoch 00123: val_loss improved from 0.18232 to 0.18183, saving model to ./model\\123-0.1818.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1828 - accuracy: 0.9357 - val_loss: 0.1818 - val_accuracy: 0.9503\n",
      "Epoch 124/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2038 - accuracy: 0.9300\n",
      "Epoch 00124: val_loss improved from 0.18183 to 0.18146, saving model to ./model\\124-0.1815.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1824 - accuracy: 0.9357 - val_loss: 0.1815 - val_accuracy: 0.9503\n",
      "Epoch 125/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1829 - accuracy: 0.9380\n",
      "Epoch 00125: val_loss improved from 0.18146 to 0.18117, saving model to ./model\\125-0.1812.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1819 - accuracy: 0.9357 - val_loss: 0.1812 - val_accuracy: 0.9503\n",
      "Epoch 126/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1874 - accuracy: 0.9320\n",
      "Epoch 00126: val_loss improved from 0.18117 to 0.18073, saving model to ./model\\126-0.1807.hdf5\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1817 - accuracy: 0.9357 - val_loss: 0.1807 - val_accuracy: 0.9503\n",
      "Epoch 127/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1835 - accuracy: 0.9380\n",
      "Epoch 00127: val_loss improved from 0.18073 to 0.18027, saving model to ./model\\127-0.1803.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1813 - accuracy: 0.9357 - val_loss: 0.1803 - val_accuracy: 0.9503\n",
      "Epoch 128/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1850 - accuracy: 0.9340\n",
      "Epoch 00128: val_loss improved from 0.18027 to 0.17984, saving model to ./model\\128-0.1798.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1811 - accuracy: 0.9357 - val_loss: 0.1798 - val_accuracy: 0.9503\n",
      "Epoch 129/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1965 - accuracy: 0.9280\n",
      "Epoch 00129: val_loss improved from 0.17984 to 0.17978, saving model to ./model\\129-0.1798.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1808 - accuracy: 0.9357 - val_loss: 0.1798 - val_accuracy: 0.9503\n",
      "Epoch 130/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1854 - accuracy: 0.9340\n",
      "Epoch 00130: val_loss did not improve from 0.17978\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1803 - accuracy: 0.9357 - val_loss: 0.1807 - val_accuracy: 0.9441\n",
      "Epoch 131/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1920 - accuracy: 0.9320\n",
      "Epoch 00131: val_loss did not improve from 0.17978\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1805 - accuracy: 0.9342 - val_loss: 0.1813 - val_accuracy: 0.9441\n",
      "Epoch 132/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.2030 - accuracy: 0.9260\n",
      "Epoch 00132: val_loss did not improve from 0.17978\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1808 - accuracy: 0.9342 - val_loss: 0.1814 - val_accuracy: 0.9441\n",
      "Epoch 133/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1897 - accuracy: 0.9300\n",
      "Epoch 00133: val_loss did not improve from 0.17978\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1808 - accuracy: 0.9342 - val_loss: 0.1806 - val_accuracy: 0.9441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1786 - accuracy: 0.9300\n",
      "Epoch 00134: val_loss improved from 0.17978 to 0.17856, saving model to ./model\\134-0.1786.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1799 - accuracy: 0.9342 - val_loss: 0.1786 - val_accuracy: 0.9472\n",
      "Epoch 135/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1695 - accuracy: 0.9380\n",
      "Epoch 00135: val_loss improved from 0.17856 to 0.17741, saving model to ./model\\135-0.1774.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1785 - accuracy: 0.9357 - val_loss: 0.1774 - val_accuracy: 0.9503\n",
      "Epoch 136/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1720 - accuracy: 0.9420\n",
      "Epoch 00136: val_loss did not improve from 0.17741\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1790 - accuracy: 0.9372 - val_loss: 0.1778 - val_accuracy: 0.9472\n",
      "Epoch 137/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1871 - accuracy: 0.9300\n",
      "Epoch 00137: val_loss improved from 0.17741 to 0.17735, saving model to ./model\\137-0.1773.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1801 - accuracy: 0.9387 - val_loss: 0.1773 - val_accuracy: 0.9472\n",
      "Epoch 138/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1978 - accuracy: 0.9280\n",
      "Epoch 00138: val_loss improved from 0.17735 to 0.17693, saving model to ./model\\138-0.1769.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1788 - accuracy: 0.9387 - val_loss: 0.1769 - val_accuracy: 0.9503\n",
      "Epoch 139/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1639 - accuracy: 0.9440\n",
      "Epoch 00139: val_loss did not improve from 0.17693\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1788 - accuracy: 0.9342 - val_loss: 0.1791 - val_accuracy: 0.9441\n",
      "Epoch 140/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1757 - accuracy: 0.9380\n",
      "Epoch 00140: val_loss did not improve from 0.17693\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1789 - accuracy: 0.9342 - val_loss: 0.1795 - val_accuracy: 0.9441\n",
      "Epoch 141/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1795 - accuracy: 0.9340\n",
      "Epoch 00141: val_loss did not improve from 0.17693\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1785 - accuracy: 0.9342 - val_loss: 0.1778 - val_accuracy: 0.9472\n",
      "Epoch 142/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1879 - accuracy: 0.9280\n",
      "Epoch 00142: val_loss improved from 0.17693 to 0.17603, saving model to ./model\\142-0.1760.hdf5\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1776 - accuracy: 0.9342 - val_loss: 0.1760 - val_accuracy: 0.9472\n",
      "Epoch 143/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1774 - accuracy: 0.9380\n",
      "Epoch 00143: val_loss improved from 0.17603 to 0.17552, saving model to ./model\\143-0.1755.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1765 - accuracy: 0.9357 - val_loss: 0.1755 - val_accuracy: 0.9472\n",
      "Epoch 144/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1863 - accuracy: 0.9320\n",
      "Epoch 00144: val_loss improved from 0.17552 to 0.17534, saving model to ./model\\144-0.1753.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1763 - accuracy: 0.9357 - val_loss: 0.1753 - val_accuracy: 0.9472\n",
      "Epoch 145/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1943 - accuracy: 0.9280\n",
      "Epoch 00145: val_loss improved from 0.17534 to 0.17528, saving model to ./model\\145-0.1753.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1761 - accuracy: 0.9357 - val_loss: 0.1753 - val_accuracy: 0.9472\n",
      "Epoch 146/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1850 - accuracy: 0.9300\n",
      "Epoch 00146: val_loss did not improve from 0.17528\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1757 - accuracy: 0.9357 - val_loss: 0.1757 - val_accuracy: 0.9472\n",
      "Epoch 147/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1910 - accuracy: 0.9280\n",
      "Epoch 00147: val_loss did not improve from 0.17528\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1755 - accuracy: 0.9357 - val_loss: 0.1766 - val_accuracy: 0.9441\n",
      "Epoch 148/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1597 - accuracy: 0.9400\n",
      "Epoch 00148: val_loss did not improve from 0.17528\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1761 - accuracy: 0.9342 - val_loss: 0.1768 - val_accuracy: 0.9441\n",
      "Epoch 149/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1862 - accuracy: 0.9280\n",
      "Epoch 00149: val_loss improved from 0.17528 to 0.17508, saving model to ./model\\149-0.1751.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1761 - accuracy: 0.9342 - val_loss: 0.1751 - val_accuracy: 0.9472\n",
      "Epoch 150/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1712 - accuracy: 0.9380\n",
      "Epoch 00150: val_loss improved from 0.17508 to 0.17323, saving model to ./model\\150-0.1732.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1749 - accuracy: 0.9342 - val_loss: 0.1732 - val_accuracy: 0.9472\n",
      "Epoch 151/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1644 - accuracy: 0.9380\n",
      "Epoch 00151: val_loss improved from 0.17323 to 0.17193, saving model to ./model\\151-0.1719.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1739 - accuracy: 0.9357 - val_loss: 0.1719 - val_accuracy: 0.9472\n",
      "Epoch 152/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1595 - accuracy: 0.9420\n",
      "Epoch 00152: val_loss did not improve from 0.17193\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1740 - accuracy: 0.9357 - val_loss: 0.1725 - val_accuracy: 0.9472\n",
      "Epoch 153/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1807 - accuracy: 0.9340\n",
      "Epoch 00153: val_loss did not improve from 0.17193\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1755 - accuracy: 0.9372 - val_loss: 0.1726 - val_accuracy: 0.9472\n",
      "Epoch 154/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1826 - accuracy: 0.9360\n",
      "Epoch 00154: val_loss did not improve from 0.17193\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1746 - accuracy: 0.9387 - val_loss: 0.1723 - val_accuracy: 0.9441\n",
      "Epoch 155/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1808 - accuracy: 0.9360\n",
      "Epoch 00155: val_loss did not improve from 0.17193\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1731 - accuracy: 0.9357 - val_loss: 0.1748 - val_accuracy: 0.9472\n",
      "Epoch 156/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1794 - accuracy: 0.9260\n",
      "Epoch 00156: val_loss did not improve from 0.17193\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1734 - accuracy: 0.9326 - val_loss: 0.1765 - val_accuracy: 0.9472\n",
      "Epoch 157/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1755 - accuracy: 0.9360\n",
      "Epoch 00157: val_loss did not improve from 0.17193\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1743 - accuracy: 0.9326 - val_loss: 0.1757 - val_accuracy: 0.9472\n",
      "Epoch 158/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1884 - accuracy: 0.9300\n",
      "Epoch 00158: val_loss did not improve from 0.17193\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1737 - accuracy: 0.9326 - val_loss: 0.1729 - val_accuracy: 0.9472\n",
      "Epoch 159/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1560 - accuracy: 0.9360\n",
      "Epoch 00159: val_loss improved from 0.17193 to 0.17084, saving model to ./model\\159-0.1708.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1719 - accuracy: 0.9326 - val_loss: 0.1708 - val_accuracy: 0.9472\n",
      "Epoch 160/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1713 - accuracy: 0.9360\n",
      "Epoch 00160: val_loss improved from 0.17084 to 0.17044, saving model to ./model\\160-0.1704.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1716 - accuracy: 0.9357 - val_loss: 0.1704 - val_accuracy: 0.9441\n",
      "Epoch 161/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1692 - accuracy: 0.9380\n",
      "Epoch 00161: val_loss did not improve from 0.17044\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1721 - accuracy: 0.9357 - val_loss: 0.1708 - val_accuracy: 0.9441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1749 - accuracy: 0.9340\n",
      "Epoch 00162: val_loss did not improve from 0.17044\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1730 - accuracy: 0.9357 - val_loss: 0.1705 - val_accuracy: 0.9441\n",
      "Epoch 163/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1647 - accuracy: 0.9400\n",
      "Epoch 00163: val_loss did not improve from 0.17044\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1719 - accuracy: 0.9342 - val_loss: 0.1707 - val_accuracy: 0.9472\n",
      "Epoch 164/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1606 - accuracy: 0.9420\n",
      "Epoch 00164: val_loss did not improve from 0.17044\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1710 - accuracy: 0.9342 - val_loss: 0.1716 - val_accuracy: 0.9472\n",
      "Epoch 165/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1814 - accuracy: 0.9260\n",
      "Epoch 00165: val_loss did not improve from 0.17044\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1703 - accuracy: 0.9326 - val_loss: 0.1707 - val_accuracy: 0.9472\n",
      "Epoch 166/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1709 - accuracy: 0.9360\n",
      "Epoch 00166: val_loss improved from 0.17044 to 0.16977, saving model to ./model\\166-0.1698.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1697 - accuracy: 0.9326 - val_loss: 0.1698 - val_accuracy: 0.9472\n",
      "Epoch 167/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1625 - accuracy: 0.9400\n",
      "Epoch 00167: val_loss improved from 0.16977 to 0.16893, saving model to ./model\\167-0.1689.hdf5\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.1690 - accuracy: 0.9342 - val_loss: 0.1689 - val_accuracy: 0.9441\n",
      "Epoch 168/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1877 - accuracy: 0.9240\n",
      "Epoch 00168: val_loss improved from 0.16893 to 0.16846, saving model to ./model\\168-0.1685.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1695 - accuracy: 0.9357 - val_loss: 0.1685 - val_accuracy: 0.9441\n",
      "Epoch 169/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1620 - accuracy: 0.9340\n",
      "Epoch 00169: val_loss improved from 0.16846 to 0.16840, saving model to ./model\\169-0.1684.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1692 - accuracy: 0.9342 - val_loss: 0.1684 - val_accuracy: 0.9441\n",
      "Epoch 170/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1664 - accuracy: 0.9340\n",
      "Epoch 00170: val_loss improved from 0.16840 to 0.16810, saving model to ./model\\170-0.1681.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1685 - accuracy: 0.9342 - val_loss: 0.1681 - val_accuracy: 0.9441\n",
      "Epoch 171/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1662 - accuracy: 0.9360\n",
      "Epoch 00171: val_loss improved from 0.16810 to 0.16747, saving model to ./model\\171-0.1675.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1681 - accuracy: 0.9342 - val_loss: 0.1675 - val_accuracy: 0.9441\n",
      "Epoch 172/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1653 - accuracy: 0.9380\n",
      "Epoch 00172: val_loss improved from 0.16747 to 0.16688, saving model to ./model\\172-0.1669.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1682 - accuracy: 0.9372 - val_loss: 0.1669 - val_accuracy: 0.9441\n",
      "Epoch 173/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1773 - accuracy: 0.9300\n",
      "Epoch 00173: val_loss improved from 0.16688 to 0.16654, saving model to ./model\\173-0.1665.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1676 - accuracy: 0.9342 - val_loss: 0.1665 - val_accuracy: 0.9441\n",
      "Epoch 174/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1708 - accuracy: 0.9300\n",
      "Epoch 00174: val_loss did not improve from 0.16654\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1667 - accuracy: 0.9342 - val_loss: 0.1674 - val_accuracy: 0.9472\n",
      "Epoch 175/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1603 - accuracy: 0.9340\n",
      "Epoch 00175: val_loss did not improve from 0.16654\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1676 - accuracy: 0.9342 - val_loss: 0.1679 - val_accuracy: 0.9472\n",
      "Epoch 176/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1506 - accuracy: 0.9440\n",
      "Epoch 00176: val_loss improved from 0.16654 to 0.16583, saving model to ./model\\176-0.1658.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1672 - accuracy: 0.9342 - val_loss: 0.1658 - val_accuracy: 0.9472\n",
      "Epoch 177/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1790 - accuracy: 0.9320\n",
      "Epoch 00177: val_loss improved from 0.16583 to 0.16489, saving model to ./model\\177-0.1649.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1666 - accuracy: 0.9342 - val_loss: 0.1649 - val_accuracy: 0.9441\n",
      "Epoch 178/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1657 - accuracy: 0.9340\n",
      "Epoch 00178: val_loss did not improve from 0.16489\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1662 - accuracy: 0.9372 - val_loss: 0.1650 - val_accuracy: 0.9441\n",
      "Epoch 179/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1748 - accuracy: 0.9320\n",
      "Epoch 00179: val_loss did not improve from 0.16489\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1653 - accuracy: 0.9357 - val_loss: 0.1664 - val_accuracy: 0.9472\n",
      "Epoch 180/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1660 - accuracy: 0.9320\n",
      "Epoch 00180: val_loss did not improve from 0.16489\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1651 - accuracy: 0.9342 - val_loss: 0.1677 - val_accuracy: 0.9472\n",
      "Epoch 181/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1553 - accuracy: 0.9340\n",
      "Epoch 00181: val_loss did not improve from 0.16489\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1653 - accuracy: 0.9342 - val_loss: 0.1676 - val_accuracy: 0.9472\n",
      "Epoch 182/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1674 - accuracy: 0.9320\n",
      "Epoch 00182: val_loss did not improve from 0.16489\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1652 - accuracy: 0.9342 - val_loss: 0.1669 - val_accuracy: 0.9472\n",
      "Epoch 183/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1611 - accuracy: 0.9360\n",
      "Epoch 00183: val_loss did not improve from 0.16489\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1644 - accuracy: 0.9342 - val_loss: 0.1668 - val_accuracy: 0.9472\n",
      "Epoch 184/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1577 - accuracy: 0.9320\n",
      "Epoch 00184: val_loss did not improve from 0.16489\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1640 - accuracy: 0.9342 - val_loss: 0.1666 - val_accuracy: 0.9472\n",
      "Epoch 185/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1679 - accuracy: 0.9300\n",
      "Epoch 00185: val_loss did not improve from 0.16489\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1637 - accuracy: 0.9357 - val_loss: 0.1666 - val_accuracy: 0.9441\n",
      "Epoch 186/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1767 - accuracy: 0.9280\n",
      "Epoch 00186: val_loss did not improve from 0.16489\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1638 - accuracy: 0.9372 - val_loss: 0.1677 - val_accuracy: 0.9472\n",
      "Epoch 187/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1662 - accuracy: 0.9300\n",
      "Epoch 00187: val_loss did not improve from 0.16489\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1631 - accuracy: 0.9342 - val_loss: 0.1710 - val_accuracy: 0.9472\n",
      "Epoch 188/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1685 - accuracy: 0.9360\n",
      "Epoch 00188: val_loss did not improve from 0.16489\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1647 - accuracy: 0.9357 - val_loss: 0.1705 - val_accuracy: 0.9472\n",
      "Epoch 189/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1566 - accuracy: 0.9400\n",
      "Epoch 00189: val_loss did not improve from 0.16489\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1639 - accuracy: 0.9357 - val_loss: 0.1656 - val_accuracy: 0.9472\n",
      "Epoch 190/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1592 - accuracy: 0.9380\n",
      "Epoch 00190: val_loss improved from 0.16489 to 0.16359, saving model to ./model\\190-0.1636.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1617 - accuracy: 0.9357 - val_loss: 0.1636 - val_accuracy: 0.9441\n",
      "Epoch 191/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1507 - accuracy: 0.9440\n",
      "Epoch 00191: val_loss did not improve from 0.16359\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1638 - accuracy: 0.9387 - val_loss: 0.1639 - val_accuracy: 0.9410\n",
      "Epoch 192/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1630 - accuracy: 0.9360\n",
      "Epoch 00192: val_loss improved from 0.16359 to 0.16205, saving model to ./model\\192-0.1621.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1655 - accuracy: 0.9357 - val_loss: 0.1621 - val_accuracy: 0.9441\n",
      "Epoch 193/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1634 - accuracy: 0.9420\n",
      "Epoch 00193: val_loss did not improve from 0.16205\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1615 - accuracy: 0.9387 - val_loss: 0.1637 - val_accuracy: 0.9472\n",
      "Epoch 194/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1648 - accuracy: 0.9340\n",
      "Epoch 00194: val_loss did not improve from 0.16205\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1622 - accuracy: 0.9342 - val_loss: 0.1687 - val_accuracy: 0.9472\n",
      "Epoch 195/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1432 - accuracy: 0.9480\n",
      "Epoch 00195: val_loss did not improve from 0.16205\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1644 - accuracy: 0.9372 - val_loss: 0.1655 - val_accuracy: 0.9472\n",
      "Epoch 196/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1706 - accuracy: 0.9340\n",
      "Epoch 00196: val_loss improved from 0.16205 to 0.16066, saving model to ./model\\196-0.1607.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1623 - accuracy: 0.9372 - val_loss: 0.1607 - val_accuracy: 0.9441\n",
      "Epoch 197/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1660 - accuracy: 0.9340\n",
      "Epoch 00197: val_loss improved from 0.16066 to 0.16021, saving model to ./model\\197-0.1602.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1601 - accuracy: 0.9372 - val_loss: 0.1602 - val_accuracy: 0.9441\n",
      "Epoch 198/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1595 - accuracy: 0.9400\n",
      "Epoch 00198: val_loss did not improve from 0.16021\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1606 - accuracy: 0.9387 - val_loss: 0.1603 - val_accuracy: 0.9441\n",
      "Epoch 199/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1696 - accuracy: 0.9360\n",
      "Epoch 00199: val_loss did not improve from 0.16021\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1592 - accuracy: 0.9372 - val_loss: 0.1622 - val_accuracy: 0.9472\n",
      "Epoch 200/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1624 - accuracy: 0.9340\n",
      "Epoch 00200: val_loss did not improve from 0.16021\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1592 - accuracy: 0.9342 - val_loss: 0.1664 - val_accuracy: 0.9472\n",
      "Epoch 201/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1628 - accuracy: 0.9340\n",
      "Epoch 00201: val_loss did not improve from 0.16021\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1612 - accuracy: 0.9372 - val_loss: 0.1666 - val_accuracy: 0.9472\n",
      "Epoch 202/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1535 - accuracy: 0.9400\n",
      "Epoch 00202: val_loss did not improve from 0.16021\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1604 - accuracy: 0.9372 - val_loss: 0.1628 - val_accuracy: 0.9472\n",
      "Epoch 203/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1609 - accuracy: 0.9380\n",
      "Epoch 00203: val_loss did not improve from 0.16021\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1583 - accuracy: 0.9357 - val_loss: 0.1606 - val_accuracy: 0.9441\n",
      "Epoch 204/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1432 - accuracy: 0.9440\n",
      "Epoch 00204: val_loss did not improve from 0.16021\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1582 - accuracy: 0.9357 - val_loss: 0.1607 - val_accuracy: 0.9441\n",
      "Epoch 205/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1558 - accuracy: 0.9400\n",
      "Epoch 00205: val_loss did not improve from 0.16021\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1598 - accuracy: 0.9387 - val_loss: 0.1605 - val_accuracy: 0.9441\n",
      "Epoch 206/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1533 - accuracy: 0.9440\n",
      "Epoch 00206: val_loss improved from 0.16021 to 0.15950, saving model to ./model\\206-0.1595.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1593 - accuracy: 0.9372 - val_loss: 0.1595 - val_accuracy: 0.9441\n",
      "Epoch 207/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1590 - accuracy: 0.9340\n",
      "Epoch 00207: val_loss did not improve from 0.15950\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1568 - accuracy: 0.9387 - val_loss: 0.1611 - val_accuracy: 0.9472\n",
      "Epoch 208/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1683 - accuracy: 0.9260\n",
      "Epoch 00208: val_loss did not improve from 0.15950\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1564 - accuracy: 0.9342 - val_loss: 0.1632 - val_accuracy: 0.9472\n",
      "Epoch 209/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1699 - accuracy: 0.9320\n",
      "Epoch 00209: val_loss did not improve from 0.15950\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1577 - accuracy: 0.9372 - val_loss: 0.1631 - val_accuracy: 0.9472\n",
      "Epoch 210/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1716 - accuracy: 0.9300\n",
      "Epoch 00210: val_loss did not improve from 0.15950\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1583 - accuracy: 0.9372 - val_loss: 0.1609 - val_accuracy: 0.9472\n",
      "Epoch 211/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1701 - accuracy: 0.9300\n",
      "Epoch 00211: val_loss improved from 0.15950 to 0.15837, saving model to ./model\\211-0.1584.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1570 - accuracy: 0.9372 - val_loss: 0.1584 - val_accuracy: 0.9472\n",
      "Epoch 212/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1582 - accuracy: 0.9380\n",
      "Epoch 00212: val_loss improved from 0.15837 to 0.15505, saving model to ./model\\212-0.1550.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1559 - accuracy: 0.9357 - val_loss: 0.1550 - val_accuracy: 0.9441\n",
      "Epoch 213/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1606 - accuracy: 0.9340\n",
      "Epoch 00213: val_loss improved from 0.15505 to 0.15377, saving model to ./model\\213-0.1538.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1550 - accuracy: 0.9357 - val_loss: 0.1538 - val_accuracy: 0.9441\n",
      "Epoch 214/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1298 - accuracy: 0.9540\n",
      "Epoch 00214: val_loss improved from 0.15377 to 0.15357, saving model to ./model\\214-0.1536.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1558 - accuracy: 0.9387 - val_loss: 0.1536 - val_accuracy: 0.9441\n",
      "Epoch 215/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1540 - accuracy: 0.9400\n",
      "Epoch 00215: val_loss did not improve from 0.15357\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1554 - accuracy: 0.9357 - val_loss: 0.1542 - val_accuracy: 0.9410\n",
      "Epoch 216/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1620 - accuracy: 0.9300\n",
      "Epoch 00216: val_loss did not improve from 0.15357\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1566 - accuracy: 0.9372 - val_loss: 0.1539 - val_accuracy: 0.9441\n",
      "Epoch 217/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1545 - accuracy: 0.9380\n",
      "Epoch 00217: val_loss did not improve from 0.15357\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1548 - accuracy: 0.9357 - val_loss: 0.1559 - val_accuracy: 0.9441\n",
      "Epoch 218/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1561 - accuracy: 0.9340\n",
      "Epoch 00218: val_loss did not improve from 0.15357\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1532 - accuracy: 0.9357 - val_loss: 0.1575 - val_accuracy: 0.9472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1574 - accuracy: 0.9300\n",
      "Epoch 00219: val_loss did not improve from 0.15357\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1538 - accuracy: 0.9357 - val_loss: 0.1578 - val_accuracy: 0.9472\n",
      "Epoch 220/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1697 - accuracy: 0.9300\n",
      "Epoch 00220: val_loss did not improve from 0.15357\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1537 - accuracy: 0.9372 - val_loss: 0.1571 - val_accuracy: 0.9472\n",
      "Epoch 221/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1309 - accuracy: 0.9440\n",
      "Epoch 00221: val_loss did not improve from 0.15357\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1530 - accuracy: 0.9357 - val_loss: 0.1559 - val_accuracy: 0.9441\n",
      "Epoch 222/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1599 - accuracy: 0.9320\n",
      "Epoch 00222: val_loss did not improve from 0.15357\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1523 - accuracy: 0.9372 - val_loss: 0.1551 - val_accuracy: 0.9441\n",
      "Epoch 223/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1578 - accuracy: 0.9360\n",
      "Epoch 00223: val_loss did not improve from 0.15357\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1534 - accuracy: 0.9387 - val_loss: 0.1548 - val_accuracy: 0.9441\n",
      "Epoch 224/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1505 - accuracy: 0.9400\n",
      "Epoch 00224: val_loss did not improve from 0.15357\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1521 - accuracy: 0.9387 - val_loss: 0.1557 - val_accuracy: 0.9441\n",
      "Epoch 225/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1454 - accuracy: 0.9380\n",
      "Epoch 00225: val_loss did not improve from 0.15357\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1508 - accuracy: 0.9342 - val_loss: 0.1580 - val_accuracy: 0.9472\n",
      "Epoch 226/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1523 - accuracy: 0.9380\n",
      "Epoch 00226: val_loss did not improve from 0.15357\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1515 - accuracy: 0.9372 - val_loss: 0.1585 - val_accuracy: 0.9472\n",
      "Epoch 227/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1620 - accuracy: 0.9340\n",
      "Epoch 00227: val_loss did not improve from 0.15357\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1515 - accuracy: 0.9372 - val_loss: 0.1568 - val_accuracy: 0.9441\n",
      "Epoch 228/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1463 - accuracy: 0.9360\n",
      "Epoch 00228: val_loss did not improve from 0.15357\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1500 - accuracy: 0.9372 - val_loss: 0.1548 - val_accuracy: 0.9441\n",
      "Epoch 229/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1478 - accuracy: 0.9420\n",
      "Epoch 00229: val_loss did not improve from 0.15357\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1496 - accuracy: 0.9387 - val_loss: 0.1539 - val_accuracy: 0.9441\n",
      "Epoch 230/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1563 - accuracy: 0.9360\n",
      "Epoch 00230: val_loss improved from 0.15357 to 0.15261, saving model to ./model\\230-0.1526.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1511 - accuracy: 0.9387 - val_loss: 0.1526 - val_accuracy: 0.9441\n",
      "Epoch 231/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1407 - accuracy: 0.9420\n",
      "Epoch 00231: val_loss did not improve from 0.15261\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1492 - accuracy: 0.9387 - val_loss: 0.1534 - val_accuracy: 0.9441\n",
      "Epoch 232/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1455 - accuracy: 0.9380\n",
      "Epoch 00232: val_loss did not improve from 0.15261\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1487 - accuracy: 0.9372 - val_loss: 0.1559 - val_accuracy: 0.9472\n",
      "Epoch 233/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1690 - accuracy: 0.9300\n",
      "Epoch 00233: val_loss did not improve from 0.15261\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1508 - accuracy: 0.9372 - val_loss: 0.1558 - val_accuracy: 0.9472\n",
      "Epoch 234/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1333 - accuracy: 0.9480\n",
      "Epoch 00234: val_loss improved from 0.15261 to 0.15195, saving model to ./model\\234-0.1519.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1508 - accuracy: 0.9372 - val_loss: 0.1519 - val_accuracy: 0.9472\n",
      "Epoch 235/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1535 - accuracy: 0.9360\n",
      "Epoch 00235: val_loss improved from 0.15195 to 0.14822, saving model to ./model\\235-0.1482.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1476 - accuracy: 0.9372 - val_loss: 0.1482 - val_accuracy: 0.9410\n",
      "Epoch 236/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1464 - accuracy: 0.9360\n",
      "Epoch 00236: val_loss did not improve from 0.14822\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1478 - accuracy: 0.9357 - val_loss: 0.1498 - val_accuracy: 0.9441\n",
      "Epoch 237/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1469 - accuracy: 0.9360\n",
      "Epoch 00237: val_loss improved from 0.14822 to 0.14786, saving model to ./model\\237-0.1479.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1519 - accuracy: 0.9372 - val_loss: 0.1479 - val_accuracy: 0.9441\n",
      "Epoch 238/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1618 - accuracy: 0.9320\n",
      "Epoch 00238: val_loss did not improve from 0.14786\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1473 - accuracy: 0.9387 - val_loss: 0.1511 - val_accuracy: 0.9472\n",
      "Epoch 239/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1519 - accuracy: 0.9340\n",
      "Epoch 00239: val_loss did not improve from 0.14786\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1468 - accuracy: 0.9372 - val_loss: 0.1575 - val_accuracy: 0.9472\n",
      "Epoch 240/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1523 - accuracy: 0.9340\n",
      "Epoch 00240: val_loss did not improve from 0.14786\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1514 - accuracy: 0.9372 - val_loss: 0.1570 - val_accuracy: 0.9503\n",
      "Epoch 241/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1543 - accuracy: 0.9340\n",
      "Epoch 00241: val_loss did not improve from 0.14786\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1500 - accuracy: 0.9372 - val_loss: 0.1502 - val_accuracy: 0.9441\n",
      "Epoch 242/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1431 - accuracy: 0.9400\n",
      "Epoch 00242: val_loss improved from 0.14786 to 0.14769, saving model to ./model\\242-0.1477.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1455 - accuracy: 0.9403 - val_loss: 0.1477 - val_accuracy: 0.9441\n",
      "Epoch 243/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1585 - accuracy: 0.9340\n",
      "Epoch 00243: val_loss improved from 0.14769 to 0.14728, saving model to ./model\\243-0.1473.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1474 - accuracy: 0.9387 - val_loss: 0.1473 - val_accuracy: 0.9441\n",
      "Epoch 244/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1521 - accuracy: 0.9380\n",
      "Epoch 00244: val_loss did not improve from 0.14728\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1460 - accuracy: 0.9403 - val_loss: 0.1482 - val_accuracy: 0.9441\n",
      "Epoch 245/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1435 - accuracy: 0.9360\n",
      "Epoch 00245: val_loss did not improve from 0.14728\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1442 - accuracy: 0.9387 - val_loss: 0.1518 - val_accuracy: 0.9503\n",
      "Epoch 246/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1514 - accuracy: 0.9340\n",
      "Epoch 00246: val_loss did not improve from 0.14728\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1465 - accuracy: 0.9372 - val_loss: 0.1497 - val_accuracy: 0.9503\n",
      "Epoch 247/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1482 - accuracy: 0.9400\n",
      "Epoch 00247: val_loss improved from 0.14728 to 0.14498, saving model to ./model\\247-0.1450.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1448 - accuracy: 0.9387 - val_loss: 0.1450 - val_accuracy: 0.9441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1522 - accuracy: 0.9360\n",
      "Epoch 00248: val_loss improved from 0.14498 to 0.14391, saving model to ./model\\248-0.1439.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1434 - accuracy: 0.9387 - val_loss: 0.1439 - val_accuracy: 0.9410\n",
      "Epoch 249/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1483 - accuracy: 0.9400\n",
      "Epoch 00249: val_loss did not improve from 0.14391\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1429 - accuracy: 0.9418 - val_loss: 0.1440 - val_accuracy: 0.9441\n",
      "Epoch 250/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1462 - accuracy: 0.9380\n",
      "Epoch 00250: val_loss did not improve from 0.14391\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1419 - accuracy: 0.9387 - val_loss: 0.1447 - val_accuracy: 0.9441\n",
      "Epoch 251/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1431 - accuracy: 0.9380\n",
      "Epoch 00251: val_loss did not improve from 0.14391\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1416 - accuracy: 0.9403 - val_loss: 0.1443 - val_accuracy: 0.9441\n",
      "Epoch 252/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1316 - accuracy: 0.9440\n",
      "Epoch 00252: val_loss improved from 0.14391 to 0.14234, saving model to ./model\\252-0.1423.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1412 - accuracy: 0.9403 - val_loss: 0.1423 - val_accuracy: 0.9441\n",
      "Epoch 253/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1269 - accuracy: 0.9500\n",
      "Epoch 00253: val_loss improved from 0.14234 to 0.14230, saving model to ./model\\253-0.1423.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1402 - accuracy: 0.9418 - val_loss: 0.1423 - val_accuracy: 0.9441\n",
      "Epoch 254/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1465 - accuracy: 0.9380\n",
      "Epoch 00254: val_loss improved from 0.14230 to 0.14195, saving model to ./model\\254-0.1419.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1433 - accuracy: 0.9372 - val_loss: 0.1419 - val_accuracy: 0.9410\n",
      "Epoch 255/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1376 - accuracy: 0.9460\n",
      "Epoch 00255: val_loss did not improve from 0.14195\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1407 - accuracy: 0.9418 - val_loss: 0.1441 - val_accuracy: 0.9472\n",
      "Epoch 256/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1424 - accuracy: 0.9420\n",
      "Epoch 00256: val_loss did not improve from 0.14195\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1400 - accuracy: 0.9403 - val_loss: 0.1451 - val_accuracy: 0.9472\n",
      "Epoch 257/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1505 - accuracy: 0.9340\n",
      "Epoch 00257: val_loss improved from 0.14195 to 0.14183, saving model to ./model\\257-0.1418.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1400 - accuracy: 0.9403 - val_loss: 0.1418 - val_accuracy: 0.9472\n",
      "Epoch 258/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1358 - accuracy: 0.9440\n",
      "Epoch 00258: val_loss improved from 0.14183 to 0.13995, saving model to ./model\\258-0.1400.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1380 - accuracy: 0.9418 - val_loss: 0.1400 - val_accuracy: 0.9441\n",
      "Epoch 259/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1436 - accuracy: 0.9380\n",
      "Epoch 00259: val_loss improved from 0.13995 to 0.13901, saving model to ./model\\259-0.1390.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1395 - accuracy: 0.9418 - val_loss: 0.1390 - val_accuracy: 0.9441\n",
      "Epoch 260/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1382 - accuracy: 0.9400\n",
      "Epoch 00260: val_loss improved from 0.13901 to 0.13859, saving model to ./model\\260-0.1386.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1389 - accuracy: 0.9387 - val_loss: 0.1386 - val_accuracy: 0.9472\n",
      "Epoch 261/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1438 - accuracy: 0.9360\n",
      "Epoch 00261: val_loss did not improve from 0.13859\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1367 - accuracy: 0.9418 - val_loss: 0.1386 - val_accuracy: 0.9503\n",
      "Epoch 262/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1365 - accuracy: 0.9440\n",
      "Epoch 00262: val_loss improved from 0.13859 to 0.13775, saving model to ./model\\262-0.1378.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1369 - accuracy: 0.9403 - val_loss: 0.1378 - val_accuracy: 0.9503\n",
      "Epoch 263/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1303 - accuracy: 0.9380\n",
      "Epoch 00263: val_loss improved from 0.13775 to 0.13655, saving model to ./model\\263-0.1366.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1364 - accuracy: 0.9372 - val_loss: 0.1366 - val_accuracy: 0.9472\n",
      "Epoch 264/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1353 - accuracy: 0.9360\n",
      "Epoch 00264: val_loss improved from 0.13655 to 0.13603, saving model to ./model\\264-0.1360.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1352 - accuracy: 0.9387 - val_loss: 0.1360 - val_accuracy: 0.9503\n",
      "Epoch 265/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1444 - accuracy: 0.9320\n",
      "Epoch 00265: val_loss did not improve from 0.13603\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1349 - accuracy: 0.9387 - val_loss: 0.1366 - val_accuracy: 0.9503\n",
      "Epoch 266/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1452 - accuracy: 0.9340\n",
      "Epoch 00266: val_loss did not improve from 0.13603\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1343 - accuracy: 0.9418 - val_loss: 0.1380 - val_accuracy: 0.9472\n",
      "Epoch 267/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1265 - accuracy: 0.9440\n",
      "Epoch 00267: val_loss improved from 0.13603 to 0.13489, saving model to ./model\\267-0.1349.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1354 - accuracy: 0.9403 - val_loss: 0.1349 - val_accuracy: 0.9503\n",
      "Epoch 268/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1383 - accuracy: 0.9420\n",
      "Epoch 00268: val_loss improved from 0.13489 to 0.13329, saving model to ./model\\268-0.1333.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1329 - accuracy: 0.9418 - val_loss: 0.1333 - val_accuracy: 0.9503\n",
      "Epoch 269/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1385 - accuracy: 0.9380\n",
      "Epoch 00269: val_loss improved from 0.13329 to 0.13217, saving model to ./model\\269-0.1322.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1338 - accuracy: 0.9403 - val_loss: 0.1322 - val_accuracy: 0.9503\n",
      "Epoch 270/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1270 - accuracy: 0.9440\n",
      "Epoch 00270: val_loss did not improve from 0.13217\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1319 - accuracy: 0.9418 - val_loss: 0.1328 - val_accuracy: 0.9472\n",
      "Epoch 271/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1286 - accuracy: 0.9460\n",
      "Epoch 00271: val_loss did not improve from 0.13217\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1326 - accuracy: 0.9433 - val_loss: 0.1341 - val_accuracy: 0.9472\n",
      "Epoch 272/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1253 - accuracy: 0.9500\n",
      "Epoch 00272: val_loss improved from 0.13217 to 0.12908, saving model to ./model\\272-0.1291.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1327 - accuracy: 0.9403 - val_loss: 0.1291 - val_accuracy: 0.9503\n",
      "Epoch 273/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1231 - accuracy: 0.9500\n",
      "Epoch 00273: val_loss did not improve from 0.12908\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1292 - accuracy: 0.9449 - val_loss: 0.1304 - val_accuracy: 0.9503\n",
      "Epoch 274/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1314 - accuracy: 0.9440\n",
      "Epoch 00274: val_loss improved from 0.12908 to 0.12749, saving model to ./model\\274-0.1275.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1358 - accuracy: 0.9418 - val_loss: 0.1275 - val_accuracy: 0.9503\n",
      "Epoch 275/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1218 - accuracy: 0.9460\n",
      "Epoch 00275: val_loss did not improve from 0.12749\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1312 - accuracy: 0.9403 - val_loss: 0.1295 - val_accuracy: 0.9472\n",
      "Epoch 276/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1392 - accuracy: 0.9360\n",
      "Epoch 00276: val_loss did not improve from 0.12749\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1315 - accuracy: 0.9403 - val_loss: 0.1328 - val_accuracy: 0.9503\n",
      "Epoch 277/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1327 - accuracy: 0.9420\n",
      "Epoch 00277: val_loss improved from 0.12749 to 0.12626, saving model to ./model\\277-0.1263.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1343 - accuracy: 0.9418 - val_loss: 0.1263 - val_accuracy: 0.9503\n",
      "Epoch 278/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1437 - accuracy: 0.9360\n",
      "Epoch 00278: val_loss improved from 0.12626 to 0.12569, saving model to ./model\\278-0.1257.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1293 - accuracy: 0.9433 - val_loss: 0.1257 - val_accuracy: 0.9503\n",
      "Epoch 279/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1389 - accuracy: 0.9380\n",
      "Epoch 00279: val_loss improved from 0.12569 to 0.12396, saving model to ./model\\279-0.1240.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1317 - accuracy: 0.9418 - val_loss: 0.1240 - val_accuracy: 0.9472\n",
      "Epoch 280/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1344 - accuracy: 0.9420\n",
      "Epoch 00280: val_loss did not improve from 0.12396\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1280 - accuracy: 0.9418 - val_loss: 0.1265 - val_accuracy: 0.9503\n",
      "Epoch 281/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1262 - accuracy: 0.9440\n",
      "Epoch 00281: val_loss did not improve from 0.12396\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1302 - accuracy: 0.9433 - val_loss: 0.1262 - val_accuracy: 0.9503\n",
      "Epoch 282/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1442 - accuracy: 0.9320\n",
      "Epoch 00282: val_loss improved from 0.12396 to 0.12312, saving model to ./model\\282-0.1231.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1305 - accuracy: 0.9403 - val_loss: 0.1231 - val_accuracy: 0.9503\n",
      "Epoch 283/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1313 - accuracy: 0.9380\n",
      "Epoch 00283: val_loss did not improve from 0.12312\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1266 - accuracy: 0.9403 - val_loss: 0.1236 - val_accuracy: 0.9503\n",
      "Epoch 284/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1228 - accuracy: 0.9420\n",
      "Epoch 00284: val_loss did not improve from 0.12312\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1261 - accuracy: 0.9418 - val_loss: 0.1256 - val_accuracy: 0.9503\n",
      "Epoch 285/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1326 - accuracy: 0.9380\n",
      "Epoch 00285: val_loss did not improve from 0.12312\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1271 - accuracy: 0.9433 - val_loss: 0.1252 - val_accuracy: 0.9503\n",
      "Epoch 286/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1256 - accuracy: 0.9440\n",
      "Epoch 00286: val_loss did not improve from 0.12312\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1262 - accuracy: 0.9418 - val_loss: 0.1234 - val_accuracy: 0.9503\n",
      "Epoch 287/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1210 - accuracy: 0.9460\n",
      "Epoch 00287: val_loss did not improve from 0.12312\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1249 - accuracy: 0.9403 - val_loss: 0.1232 - val_accuracy: 0.9503\n",
      "Epoch 288/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1287 - accuracy: 0.9400\n",
      "Epoch 00288: val_loss did not improve from 0.12312\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1256 - accuracy: 0.9418 - val_loss: 0.1233 - val_accuracy: 0.9503\n",
      "Epoch 289/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1221 - accuracy: 0.9440\n",
      "Epoch 00289: val_loss did not improve from 0.12312\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1242 - accuracy: 0.9464 - val_loss: 0.1242 - val_accuracy: 0.9503\n",
      "Epoch 290/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1322 - accuracy: 0.9420\n",
      "Epoch 00290: val_loss did not improve from 0.12312\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1241 - accuracy: 0.9464 - val_loss: 0.1238 - val_accuracy: 0.9503\n",
      "Epoch 291/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1300 - accuracy: 0.9460\n",
      "Epoch 00291: val_loss improved from 0.12312 to 0.12224, saving model to ./model\\291-0.1222.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1240 - accuracy: 0.9464 - val_loss: 0.1222 - val_accuracy: 0.9503\n",
      "Epoch 292/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1160 - accuracy: 0.9480\n",
      "Epoch 00292: val_loss improved from 0.12224 to 0.12116, saving model to ./model\\292-0.1212.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1230 - accuracy: 0.9464 - val_loss: 0.1212 - val_accuracy: 0.9503\n",
      "Epoch 293/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1144 - accuracy: 0.9540\n",
      "Epoch 00293: val_loss improved from 0.12116 to 0.12037, saving model to ./model\\293-0.1204.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1226 - accuracy: 0.9495 - val_loss: 0.1204 - val_accuracy: 0.9534\n",
      "Epoch 294/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1252 - accuracy: 0.9440\n",
      "Epoch 00294: val_loss improved from 0.12037 to 0.12012, saving model to ./model\\294-0.1201.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1230 - accuracy: 0.9479 - val_loss: 0.1201 - val_accuracy: 0.9503\n",
      "Epoch 295/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1140 - accuracy: 0.9540\n",
      "Epoch 00295: val_loss did not improve from 0.12012\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1235 - accuracy: 0.9449 - val_loss: 0.1207 - val_accuracy: 0.9503\n",
      "Epoch 296/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1152 - accuracy: 0.9540\n",
      "Epoch 00296: val_loss improved from 0.12012 to 0.11912, saving model to ./model\\296-0.1191.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1214 - accuracy: 0.9464 - val_loss: 0.1191 - val_accuracy: 0.9534\n",
      "Epoch 297/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1207 - accuracy: 0.9480\n",
      "Epoch 00297: val_loss did not improve from 0.11912\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1221 - accuracy: 0.9464 - val_loss: 0.1196 - val_accuracy: 0.9534\n",
      "Epoch 298/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1227 - accuracy: 0.9460\n",
      "Epoch 00298: val_loss did not improve from 0.11912\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1229 - accuracy: 0.9449 - val_loss: 0.1193 - val_accuracy: 0.9503\n",
      "Epoch 299/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1230 - accuracy: 0.9420\n",
      "Epoch 00299: val_loss did not improve from 0.11912\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1204 - accuracy: 0.9464 - val_loss: 0.1247 - val_accuracy: 0.9503\n",
      "Epoch 300/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1285 - accuracy: 0.9380\n",
      "Epoch 00300: val_loss did not improve from 0.11912\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1242 - accuracy: 0.9433 - val_loss: 0.1208 - val_accuracy: 0.9503\n",
      "Epoch 301/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1119 - accuracy: 0.9540\n",
      "Epoch 00301: val_loss did not improve from 0.11912\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.9464 - val_loss: 0.1208 - val_accuracy: 0.9534\n",
      "Epoch 302/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1184 - accuracy: 0.9540\n",
      "Epoch 00302: val_loss improved from 0.11912 to 0.11867, saving model to ./model\\302-0.1187.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1249 - accuracy: 0.9525 - val_loss: 0.1187 - val_accuracy: 0.9534\n",
      "Epoch 303/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1197 - accuracy: 0.9480\n",
      "Epoch 00303: val_loss did not improve from 0.11867\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1204 - accuracy: 0.9449 - val_loss: 0.1238 - val_accuracy: 0.9503\n",
      "Epoch 304/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1290 - accuracy: 0.9380\n",
      "Epoch 00304: val_loss did not improve from 0.11867\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1221 - accuracy: 0.9433 - val_loss: 0.1225 - val_accuracy: 0.9503\n",
      "Epoch 305/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1255 - accuracy: 0.9400\n",
      "Epoch 00305: val_loss improved from 0.11867 to 0.11774, saving model to ./model\\305-0.1177.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1208 - accuracy: 0.9433 - val_loss: 0.1177 - val_accuracy: 0.9472\n",
      "Epoch 306/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1230 - accuracy: 0.9480\n",
      "Epoch 00306: val_loss improved from 0.11774 to 0.11740, saving model to ./model\\306-0.1174.hdf5\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1177 - accuracy: 0.9510 - val_loss: 0.1174 - val_accuracy: 0.9534\n",
      "Epoch 307/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1164 - accuracy: 0.9560\n",
      "Epoch 00307: val_loss did not improve from 0.11740\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1181 - accuracy: 0.9525 - val_loss: 0.1178 - val_accuracy: 0.9503\n",
      "Epoch 308/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1170 - accuracy: 0.9460\n",
      "Epoch 00308: val_loss did not improve from 0.11740\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1165 - accuracy: 0.9479 - val_loss: 0.1209 - val_accuracy: 0.9472\n",
      "Epoch 309/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1160 - accuracy: 0.9480\n",
      "Epoch 00309: val_loss did not improve from 0.11740\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1187 - accuracy: 0.9449 - val_loss: 0.1185 - val_accuracy: 0.9472\n",
      "Epoch 310/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1181 - accuracy: 0.9440\n",
      "Epoch 00310: val_loss improved from 0.11740 to 0.11613, saving model to ./model\\310-0.1161.hdf5\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1175 - accuracy: 0.9479 - val_loss: 0.1161 - val_accuracy: 0.9534\n",
      "Epoch 311/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1169 - accuracy: 0.9540\n",
      "Epoch 00311: val_loss did not improve from 0.11613\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1169 - accuracy: 0.9525 - val_loss: 0.1165 - val_accuracy: 0.9503\n",
      "Epoch 312/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1153 - accuracy: 0.9500\n",
      "Epoch 00312: val_loss did not improve from 0.11613\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1152 - accuracy: 0.9479 - val_loss: 0.1199 - val_accuracy: 0.9472\n",
      "Epoch 313/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1252 - accuracy: 0.9420\n",
      "Epoch 00313: val_loss did not improve from 0.11613\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1166 - accuracy: 0.9449 - val_loss: 0.1187 - val_accuracy: 0.9472\n",
      "Epoch 314/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1170 - accuracy: 0.9420\n",
      "Epoch 00314: val_loss did not improve from 0.11613\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1163 - accuracy: 0.9449 - val_loss: 0.1164 - val_accuracy: 0.9472\n",
      "Epoch 315/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1216 - accuracy: 0.9460\n",
      "Epoch 00315: val_loss did not improve from 0.11613\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1140 - accuracy: 0.9479 - val_loss: 0.1163 - val_accuracy: 0.9472\n",
      "Epoch 316/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1069 - accuracy: 0.9560\n",
      "Epoch 00316: val_loss improved from 0.11613 to 0.11464, saving model to ./model\\316-0.1146.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1138 - accuracy: 0.9479 - val_loss: 0.1146 - val_accuracy: 0.9472\n",
      "Epoch 317/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1049 - accuracy: 0.9540\n",
      "Epoch 00317: val_loss improved from 0.11464 to 0.11294, saving model to ./model\\317-0.1129.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1136 - accuracy: 0.9495 - val_loss: 0.1129 - val_accuracy: 0.9503\n",
      "Epoch 318/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1056 - accuracy: 0.9560\n",
      "Epoch 00318: val_loss improved from 0.11294 to 0.11261, saving model to ./model\\318-0.1126.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1131 - accuracy: 0.9510 - val_loss: 0.1126 - val_accuracy: 0.9503\n",
      "Epoch 319/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1092 - accuracy: 0.9480\n",
      "Epoch 00319: val_loss improved from 0.11261 to 0.11212, saving model to ./model\\319-0.1121.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1124 - accuracy: 0.9510 - val_loss: 0.1121 - val_accuracy: 0.9534\n",
      "Epoch 320/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1152 - accuracy: 0.9500\n",
      "Epoch 00320: val_loss improved from 0.11212 to 0.11190, saving model to ./model\\320-0.1119.hdf5\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1123 - accuracy: 0.9510 - val_loss: 0.1119 - val_accuracy: 0.9534\n",
      "Epoch 321/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1130 - accuracy: 0.9520\n",
      "Epoch 00321: val_loss improved from 0.11190 to 0.11179, saving model to ./model\\321-0.1118.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1122 - accuracy: 0.9510 - val_loss: 0.1118 - val_accuracy: 0.9534\n",
      "Epoch 322/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1157 - accuracy: 0.9460\n",
      "Epoch 00322: val_loss improved from 0.11179 to 0.11152, saving model to ./model\\322-0.1115.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1118 - accuracy: 0.9525 - val_loss: 0.1115 - val_accuracy: 0.9534\n",
      "Epoch 323/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1083 - accuracy: 0.9540\n",
      "Epoch 00323: val_loss did not improve from 0.11152\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1112 - accuracy: 0.9525 - val_loss: 0.1117 - val_accuracy: 0.9472\n",
      "Epoch 324/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1042 - accuracy: 0.9520\n",
      "Epoch 00324: val_loss improved from 0.11152 to 0.11096, saving model to ./model\\324-0.1110.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1109 - accuracy: 0.9495 - val_loss: 0.1110 - val_accuracy: 0.9472\n",
      "Epoch 325/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1072 - accuracy: 0.9520\n",
      "Epoch 00325: val_loss improved from 0.11096 to 0.10968, saving model to ./model\\325-0.1097.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1106 - accuracy: 0.9510 - val_loss: 0.1097 - val_accuracy: 0.9534\n",
      "Epoch 326/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1093 - accuracy: 0.9540\n",
      "Epoch 00326: val_loss did not improve from 0.10968\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1110 - accuracy: 0.9541 - val_loss: 0.1097 - val_accuracy: 0.9534\n",
      "Epoch 327/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1160 - accuracy: 0.9520\n",
      "Epoch 00327: val_loss did not improve from 0.10968\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.9541 - val_loss: 0.1135 - val_accuracy: 0.9472\n",
      "Epoch 328/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1160 - accuracy: 0.9440\n",
      "Epoch 00328: val_loss did not improve from 0.10968\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1107 - accuracy: 0.9464 - val_loss: 0.1154 - val_accuracy: 0.9472\n",
      "Epoch 329/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1099 - accuracy: 0.9420\n",
      "Epoch 00329: val_loss did not improve from 0.10968\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1105 - accuracy: 0.9449 - val_loss: 0.1097 - val_accuracy: 0.9534\n",
      "Epoch 330/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1150 - accuracy: 0.9520\n",
      "Epoch 00330: val_loss improved from 0.10968 to 0.10927, saving model to ./model\\330-0.1093.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1105 - accuracy: 0.9587 - val_loss: 0.1093 - val_accuracy: 0.9565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1063 - accuracy: 0.9660\n",
      "Epoch 00331: val_loss did not improve from 0.10927\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1110 - accuracy: 0.9556 - val_loss: 0.1105 - val_accuracy: 0.9503\n",
      "Epoch 332/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1121 - accuracy: 0.9500\n",
      "Epoch 00332: val_loss did not improve from 0.10927\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1082 - accuracy: 0.9495 - val_loss: 0.1110 - val_accuracy: 0.9472\n",
      "Epoch 333/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1065 - accuracy: 0.9520\n",
      "Epoch 00333: val_loss improved from 0.10927 to 0.10915, saving model to ./model\\333-0.1091.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1085 - accuracy: 0.9479 - val_loss: 0.1091 - val_accuracy: 0.9534\n",
      "Epoch 334/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1036 - accuracy: 0.9520\n",
      "Epoch 00334: val_loss improved from 0.10915 to 0.10698, saving model to ./model\\334-0.1070.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1069 - accuracy: 0.9525 - val_loss: 0.1070 - val_accuracy: 0.9565\n",
      "Epoch 335/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1104 - accuracy: 0.9560\n",
      "Epoch 00335: val_loss improved from 0.10698 to 0.10661, saving model to ./model\\335-0.1066.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1090 - accuracy: 0.9617 - val_loss: 0.1066 - val_accuracy: 0.9534\n",
      "Epoch 336/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1080 - accuracy: 0.9520\n",
      "Epoch 00336: val_loss did not improve from 0.10661\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1064 - accuracy: 0.9541 - val_loss: 0.1123 - val_accuracy: 0.9503\n",
      "Epoch 337/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1124 - accuracy: 0.9420\n",
      "Epoch 00337: val_loss did not improve from 0.10661\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1104 - accuracy: 0.9449 - val_loss: 0.1093 - val_accuracy: 0.9472\n",
      "Epoch 338/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1000 - accuracy: 0.9520\n",
      "Epoch 00338: val_loss improved from 0.10661 to 0.10388, saving model to ./model\\338-0.1039.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1071 - accuracy: 0.9479 - val_loss: 0.1039 - val_accuracy: 0.9534\n",
      "Epoch 339/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1107 - accuracy: 0.9620\n",
      "Epoch 00339: val_loss did not improve from 0.10388\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1087 - accuracy: 0.9602 - val_loss: 0.1042 - val_accuracy: 0.9534\n",
      "Epoch 340/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1008 - accuracy: 0.9680\n",
      "Epoch 00340: val_loss did not improve from 0.10388\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1096 - accuracy: 0.9602 - val_loss: 0.1068 - val_accuracy: 0.9534\n",
      "Epoch 341/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1142 - accuracy: 0.9440\n",
      "Epoch 00341: val_loss did not improve from 0.10388\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1054 - accuracy: 0.9510 - val_loss: 0.1063 - val_accuracy: 0.9534\n",
      "Epoch 342/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1141 - accuracy: 0.9500\n",
      "Epoch 00342: val_loss did not improve from 0.10388\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.9541 - val_loss: 0.1051 - val_accuracy: 0.9534\n",
      "Epoch 343/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1164 - accuracy: 0.9480\n",
      "Epoch 00343: val_loss did not improve from 0.10388\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.9556 - val_loss: 0.1057 - val_accuracy: 0.9534\n",
      "Epoch 344/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1132 - accuracy: 0.9480\n",
      "Epoch 00344: val_loss did not improve from 0.10388\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.9525 - val_loss: 0.1078 - val_accuracy: 0.9472\n",
      "Epoch 345/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1108 - accuracy: 0.9460\n",
      "Epoch 00345: val_loss did not improve from 0.10388\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.9495 - val_loss: 0.1070 - val_accuracy: 0.9503\n",
      "Epoch 346/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0974 - accuracy: 0.9540\n",
      "Epoch 00346: val_loss did not improve from 0.10388\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.9525 - val_loss: 0.1065 - val_accuracy: 0.9534\n",
      "Epoch 347/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1077 - accuracy: 0.9540\n",
      "Epoch 00347: val_loss did not improve from 0.10388\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1031 - accuracy: 0.9541 - val_loss: 0.1063 - val_accuracy: 0.9534\n",
      "Epoch 348/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1057 - accuracy: 0.9560\n",
      "Epoch 00348: val_loss did not improve from 0.10388\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1023 - accuracy: 0.9541 - val_loss: 0.1060 - val_accuracy: 0.9534\n",
      "Epoch 349/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1012 - accuracy: 0.9700\n",
      "Epoch 00349: val_loss did not improve from 0.10388\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1034 - accuracy: 0.9694 - val_loss: 0.1061 - val_accuracy: 0.9534\n",
      "Epoch 350/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1029 - accuracy: 0.9580\n",
      "Epoch 00350: val_loss did not improve from 0.10388\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1018 - accuracy: 0.9602 - val_loss: 0.1101 - val_accuracy: 0.9503\n",
      "Epoch 351/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1010 - accuracy: 0.9500\n",
      "Epoch 00351: val_loss did not improve from 0.10388\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1040 - accuracy: 0.9510 - val_loss: 0.1094 - val_accuracy: 0.9503\n",
      "Epoch 352/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1107 - accuracy: 0.9440\n",
      "Epoch 00352: val_loss did not improve from 0.10388\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1033 - accuracy: 0.9495 - val_loss: 0.1043 - val_accuracy: 0.9534\n",
      "Epoch 353/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0970 - accuracy: 0.9660\n",
      "Epoch 00353: val_loss improved from 0.10388 to 0.10344, saving model to ./model\\353-0.1034.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1011 - accuracy: 0.9617 - val_loss: 0.1034 - val_accuracy: 0.9534\n",
      "Epoch 354/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1141 - accuracy: 0.9540\n",
      "Epoch 00354: val_loss did not improve from 0.10344\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1010 - accuracy: 0.9632 - val_loss: 0.1073 - val_accuracy: 0.9534\n",
      "Epoch 355/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1026 - accuracy: 0.9480\n",
      "Epoch 00355: val_loss did not improve from 0.10344\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1020 - accuracy: 0.9495 - val_loss: 0.1145 - val_accuracy: 0.9534\n",
      "Epoch 356/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1072 - accuracy: 0.9460\n",
      "Epoch 00356: val_loss did not improve from 0.10344\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1075 - accuracy: 0.9449 - val_loss: 0.1042 - val_accuracy: 0.9534\n",
      "Epoch 357/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1093 - accuracy: 0.9480\n",
      "Epoch 00357: val_loss improved from 0.10344 to 0.10216, saving model to ./model\\357-0.1022.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1007 - accuracy: 0.9556 - val_loss: 0.1022 - val_accuracy: 0.9534\n",
      "Epoch 358/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1095 - accuracy: 0.9620\n",
      "Epoch 00358: val_loss improved from 0.10216 to 0.10072, saving model to ./model\\358-0.1007.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1049 - accuracy: 0.9678 - val_loss: 0.1007 - val_accuracy: 0.9534\n",
      "Epoch 359/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0923 - accuracy: 0.9620\n",
      "Epoch 00359: val_loss did not improve from 0.10072\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1006 - accuracy: 0.9541 - val_loss: 0.1069 - val_accuracy: 0.9503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1080 - accuracy: 0.9440\n",
      "Epoch 00360: val_loss did not improve from 0.10072\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1026 - accuracy: 0.9479 - val_loss: 0.1008 - val_accuracy: 0.9534\n",
      "Epoch 361/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1062 - accuracy: 0.9500\n",
      "Epoch 00361: val_loss improved from 0.10072 to 0.09870, saving model to ./model\\361-0.0987.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1002 - accuracy: 0.9556 - val_loss: 0.0987 - val_accuracy: 0.9534\n",
      "Epoch 362/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0844 - accuracy: 0.9760\n",
      "Epoch 00362: val_loss did not improve from 0.09870\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0996 - accuracy: 0.9648 - val_loss: 0.0997 - val_accuracy: 0.9534\n",
      "Epoch 363/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1066 - accuracy: 0.9520\n",
      "Epoch 00363: val_loss did not improve from 0.09870\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0981 - accuracy: 0.9602 - val_loss: 0.1017 - val_accuracy: 0.9534\n",
      "Epoch 364/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1005 - accuracy: 0.9540\n",
      "Epoch 00364: val_loss did not improve from 0.09870\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0976 - accuracy: 0.9541 - val_loss: 0.1058 - val_accuracy: 0.9534\n",
      "Epoch 365/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0964 - accuracy: 0.9560\n",
      "Epoch 00365: val_loss did not improve from 0.09870\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0998 - accuracy: 0.9495 - val_loss: 0.1031 - val_accuracy: 0.9534\n",
      "Epoch 366/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0936 - accuracy: 0.9600\n",
      "Epoch 00366: val_loss did not improve from 0.09870\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0961 - accuracy: 0.9617 - val_loss: 0.1024 - val_accuracy: 0.9565\n",
      "Epoch 367/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1117 - accuracy: 0.9580\n",
      "Epoch 00367: val_loss did not improve from 0.09870\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.9648 - val_loss: 0.1016 - val_accuracy: 0.9534\n",
      "Epoch 368/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0871 - accuracy: 0.9720\n",
      "Epoch 00368: val_loss did not improve from 0.09870\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0984 - accuracy: 0.9617 - val_loss: 0.1098 - val_accuracy: 0.9534\n",
      "Epoch 369/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0969 - accuracy: 0.9500\n",
      "Epoch 00369: val_loss did not improve from 0.09870\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1009 - accuracy: 0.9495 - val_loss: 0.1035 - val_accuracy: 0.9534\n",
      "Epoch 370/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0918 - accuracy: 0.9520\n",
      "Epoch 00370: val_loss did not improve from 0.09870\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0968 - accuracy: 0.9541 - val_loss: 0.0990 - val_accuracy: 0.9565\n",
      "Epoch 371/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0945 - accuracy: 0.9680\n",
      "Epoch 00371: val_loss improved from 0.09870 to 0.09785, saving model to ./model\\371-0.0979.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0984 - accuracy: 0.9678 - val_loss: 0.0979 - val_accuracy: 0.9565\n",
      "Epoch 372/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1057 - accuracy: 0.9660\n",
      "Epoch 00372: val_loss did not improve from 0.09785\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0960 - accuracy: 0.9694 - val_loss: 0.0991 - val_accuracy: 0.9534\n",
      "Epoch 373/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0888 - accuracy: 0.9560\n",
      "Epoch 00373: val_loss did not improve from 0.09785\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0958 - accuracy: 0.9571 - val_loss: 0.0997 - val_accuracy: 0.9534\n",
      "Epoch 374/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0922 - accuracy: 0.9600\n",
      "Epoch 00374: val_loss improved from 0.09785 to 0.09608, saving model to ./model\\374-0.0961.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0964 - accuracy: 0.9556 - val_loss: 0.0961 - val_accuracy: 0.9565\n",
      "Epoch 375/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0930 - accuracy: 0.9720\n",
      "Epoch 00375: val_loss improved from 0.09608 to 0.09544, saving model to ./model\\375-0.0954.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0947 - accuracy: 0.9694 - val_loss: 0.0954 - val_accuracy: 0.9565\n",
      "Epoch 376/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1040 - accuracy: 0.9620\n",
      "Epoch 00376: val_loss did not improve from 0.09544\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9678 - val_loss: 0.0988 - val_accuracy: 0.9534\n",
      "Epoch 377/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1029 - accuracy: 0.9500\n",
      "Epoch 00377: val_loss did not improve from 0.09544\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0948 - accuracy: 0.9541 - val_loss: 0.1024 - val_accuracy: 0.9565\n",
      "Epoch 378/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0933 - accuracy: 0.9560\n",
      "Epoch 00378: val_loss did not improve from 0.09544\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0967 - accuracy: 0.9541 - val_loss: 0.0984 - val_accuracy: 0.9534\n",
      "Epoch 379/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0898 - accuracy: 0.9560\n",
      "Epoch 00379: val_loss did not improve from 0.09544\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0939 - accuracy: 0.9587 - val_loss: 0.0964 - val_accuracy: 0.9565\n",
      "Epoch 380/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0977 - accuracy: 0.9680\n",
      "Epoch 00380: val_loss did not improve from 0.09544\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0946 - accuracy: 0.9678 - val_loss: 0.0968 - val_accuracy: 0.9565\n",
      "Epoch 381/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0888 - accuracy: 0.9700\n",
      "Epoch 00381: val_loss did not improve from 0.09544\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0946 - accuracy: 0.9678 - val_loss: 0.0967 - val_accuracy: 0.9565\n",
      "Epoch 382/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0957 - accuracy: 0.9680\n",
      "Epoch 00382: val_loss did not improve from 0.09544\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0940 - accuracy: 0.9694 - val_loss: 0.0975 - val_accuracy: 0.9534\n",
      "Epoch 383/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0928 - accuracy: 0.9660\n",
      "Epoch 00383: val_loss did not improve from 0.09544\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0931 - accuracy: 0.9648 - val_loss: 0.1009 - val_accuracy: 0.9596\n",
      "Epoch 384/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0886 - accuracy: 0.9600\n",
      "Epoch 00384: val_loss did not improve from 0.09544\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0940 - accuracy: 0.9525 - val_loss: 0.0956 - val_accuracy: 0.9534\n",
      "Epoch 385/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0797 - accuracy: 0.9760\n",
      "Epoch 00385: val_loss improved from 0.09544 to 0.09410, saving model to ./model\\385-0.0941.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0913 - accuracy: 0.9678 - val_loss: 0.0941 - val_accuracy: 0.9627\n",
      "Epoch 386/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1039 - accuracy: 0.9620\n",
      "Epoch 00386: val_loss improved from 0.09410 to 0.09340, saving model to ./model\\386-0.0934.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0972 - accuracy: 0.9663 - val_loss: 0.0934 - val_accuracy: 0.9565\n",
      "Epoch 387/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0912 - accuracy: 0.9660\n",
      "Epoch 00387: val_loss did not improve from 0.09340\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0955 - accuracy: 0.9663 - val_loss: 0.0969 - val_accuracy: 0.9596\n",
      "Epoch 388/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0937 - accuracy: 0.9540\n",
      "Epoch 00388: val_loss did not improve from 0.09340\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0925 - accuracy: 0.9571 - val_loss: 0.0974 - val_accuracy: 0.9596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0868 - accuracy: 0.9600\n",
      "Epoch 00389: val_loss did not improve from 0.09340\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0919 - accuracy: 0.9571 - val_loss: 0.0940 - val_accuracy: 0.9565\n",
      "Epoch 390/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0822 - accuracy: 0.9760\n",
      "Epoch 00390: val_loss did not improve from 0.09340\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0912 - accuracy: 0.9709 - val_loss: 0.0939 - val_accuracy: 0.9596\n",
      "Epoch 391/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0798 - accuracy: 0.9760\n",
      "Epoch 00391: val_loss did not improve from 0.09340\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0915 - accuracy: 0.9694 - val_loss: 0.0973 - val_accuracy: 0.9565\n",
      "Epoch 392/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0871 - accuracy: 0.9700\n",
      "Epoch 00392: val_loss did not improve from 0.09340\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0921 - accuracy: 0.9648 - val_loss: 0.0987 - val_accuracy: 0.9565\n",
      "Epoch 393/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0986 - accuracy: 0.9660\n",
      "Epoch 00393: val_loss did not improve from 0.09340\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0911 - accuracy: 0.9678 - val_loss: 0.0941 - val_accuracy: 0.9596\n",
      "Epoch 394/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0901 - accuracy: 0.9680\n",
      "Epoch 00394: val_loss improved from 0.09340 to 0.09319, saving model to ./model\\394-0.0932.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0908 - accuracy: 0.9694 - val_loss: 0.0932 - val_accuracy: 0.9596\n",
      "Epoch 395/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0936 - accuracy: 0.9640\n",
      "Epoch 00395: val_loss did not improve from 0.09319\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0910 - accuracy: 0.9694 - val_loss: 0.0944 - val_accuracy: 0.9565\n",
      "Epoch 396/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0932 - accuracy: 0.9680\n",
      "Epoch 00396: val_loss did not improve from 0.09319\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0892 - accuracy: 0.9678 - val_loss: 0.0948 - val_accuracy: 0.9565\n",
      "Epoch 397/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0883 - accuracy: 0.9640\n",
      "Epoch 00397: val_loss improved from 0.09319 to 0.09085, saving model to ./model\\397-0.0909.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0894 - accuracy: 0.9632 - val_loss: 0.0909 - val_accuracy: 0.9565\n",
      "Epoch 398/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0820 - accuracy: 0.9760\n",
      "Epoch 00398: val_loss improved from 0.09085 to 0.08914, saving model to ./model\\398-0.0891.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0885 - accuracy: 0.9724 - val_loss: 0.0891 - val_accuracy: 0.9627\n",
      "Epoch 399/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0963 - accuracy: 0.9640\n",
      "Epoch 00399: val_loss did not improve from 0.08914\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0906 - accuracy: 0.9678 - val_loss: 0.0904 - val_accuracy: 0.9565\n",
      "Epoch 400/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0908 - accuracy: 0.9680\n",
      "Epoch 00400: val_loss did not improve from 0.08914\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0875 - accuracy: 0.9678 - val_loss: 0.0988 - val_accuracy: 0.9627\n",
      "Epoch 401/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.1006 - accuracy: 0.9500\n",
      "Epoch 00401: val_loss did not improve from 0.08914\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0931 - accuracy: 0.9541 - val_loss: 0.0965 - val_accuracy: 0.9596\n",
      "Epoch 402/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0954 - accuracy: 0.9540\n",
      "Epoch 00402: val_loss did not improve from 0.08914\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0905 - accuracy: 0.9587 - val_loss: 0.0900 - val_accuracy: 0.9596\n",
      "Epoch 403/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0878 - accuracy: 0.9700\n",
      "Epoch 00403: val_loss did not improve from 0.08914\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0872 - accuracy: 0.9709 - val_loss: 0.0896 - val_accuracy: 0.9689\n",
      "Epoch 404/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0880 - accuracy: 0.9680\n",
      "Epoch 00404: val_loss did not improve from 0.08914\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0907 - accuracy: 0.9663 - val_loss: 0.0895 - val_accuracy: 0.9596\n",
      "Epoch 405/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0875 - accuracy: 0.9680\n",
      "Epoch 00405: val_loss did not improve from 0.08914\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0871 - accuracy: 0.9663 - val_loss: 0.0946 - val_accuracy: 0.9596\n",
      "Epoch 406/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0877 - accuracy: 0.9620\n",
      "Epoch 00406: val_loss did not improve from 0.08914\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0881 - accuracy: 0.9632 - val_loss: 0.0914 - val_accuracy: 0.9565\n",
      "Epoch 407/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0934 - accuracy: 0.9640\n",
      "Epoch 00407: val_loss did not improve from 0.08914\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0883 - accuracy: 0.9663 - val_loss: 0.0896 - val_accuracy: 0.9565\n",
      "Epoch 408/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0805 - accuracy: 0.9760\n",
      "Epoch 00408: val_loss did not improve from 0.08914\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0864 - accuracy: 0.9694 - val_loss: 0.0909 - val_accuracy: 0.9565\n",
      "Epoch 409/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0861 - accuracy: 0.9700\n",
      "Epoch 00409: val_loss improved from 0.08914 to 0.08863, saving model to ./model\\409-0.0886.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0858 - accuracy: 0.9678 - val_loss: 0.0886 - val_accuracy: 0.9565\n",
      "Epoch 410/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0904 - accuracy: 0.9680\n",
      "Epoch 00410: val_loss improved from 0.08863 to 0.08821, saving model to ./model\\410-0.0882.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0871 - accuracy: 0.9709 - val_loss: 0.0882 - val_accuracy: 0.9596\n",
      "Epoch 411/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0865 - accuracy: 0.9700\n",
      "Epoch 00411: val_loss did not improve from 0.08821\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0873 - accuracy: 0.9724 - val_loss: 0.0922 - val_accuracy: 0.9627\n",
      "Epoch 412/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0978 - accuracy: 0.9540\n",
      "Epoch 00412: val_loss did not improve from 0.08821\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0859 - accuracy: 0.9632 - val_loss: 0.0987 - val_accuracy: 0.9596\n",
      "Epoch 413/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0813 - accuracy: 0.9580\n",
      "Epoch 00413: val_loss did not improve from 0.08821\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0907 - accuracy: 0.9510 - val_loss: 0.0945 - val_accuracy: 0.9627\n",
      "Epoch 414/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0923 - accuracy: 0.9560\n",
      "Epoch 00414: val_loss did not improve from 0.08821\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0881 - accuracy: 0.9602 - val_loss: 0.0885 - val_accuracy: 0.9658\n",
      "Epoch 415/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0765 - accuracy: 0.9720\n",
      "Epoch 00415: val_loss did not improve from 0.08821\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0867 - accuracy: 0.9694 - val_loss: 0.0890 - val_accuracy: 0.9596\n",
      "Epoch 416/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0798 - accuracy: 0.9700\n",
      "Epoch 00416: val_loss did not improve from 0.08821\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9709 - val_loss: 0.0938 - val_accuracy: 0.9627\n",
      "Epoch 417/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0884 - accuracy: 0.9640\n",
      "Epoch 00417: val_loss did not improve from 0.08821\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0860 - accuracy: 0.9632 - val_loss: 0.0973 - val_accuracy: 0.9596\n",
      "Epoch 418/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0724 - accuracy: 0.9660\n",
      "Epoch 00418: val_loss did not improve from 0.08821\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0869 - accuracy: 0.9617 - val_loss: 0.0890 - val_accuracy: 0.9565\n",
      "Epoch 419/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0809 - accuracy: 0.9700\n",
      "Epoch 00419: val_loss did not improve from 0.08821\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0831 - accuracy: 0.9724 - val_loss: 0.0883 - val_accuracy: 0.9658\n",
      "Epoch 420/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0838 - accuracy: 0.9700\n",
      "Epoch 00420: val_loss improved from 0.08821 to 0.08796, saving model to ./model\\420-0.0880.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0899 - accuracy: 0.9648 - val_loss: 0.0880 - val_accuracy: 0.9565\n",
      "Epoch 421/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0799 - accuracy: 0.9760\n",
      "Epoch 00421: val_loss did not improve from 0.08796\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9709 - val_loss: 0.0953 - val_accuracy: 0.9596\n",
      "Epoch 422/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0965 - accuracy: 0.9580\n",
      "Epoch 00422: val_loss did not improve from 0.08796\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0863 - accuracy: 0.9632 - val_loss: 0.0893 - val_accuracy: 0.9565\n",
      "Epoch 423/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0880 - accuracy: 0.9700\n",
      "Epoch 00423: val_loss improved from 0.08796 to 0.08628, saving model to ./model\\423-0.0863.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0826 - accuracy: 0.9709 - val_loss: 0.0863 - val_accuracy: 0.9720\n",
      "Epoch 424/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0886 - accuracy: 0.9700\n",
      "Epoch 00424: val_loss did not improve from 0.08628\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0847 - accuracy: 0.9709 - val_loss: 0.0869 - val_accuracy: 0.9658\n",
      "Epoch 425/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0778 - accuracy: 0.9720\n",
      "Epoch 00425: val_loss did not improve from 0.08628\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0839 - accuracy: 0.9678 - val_loss: 0.0893 - val_accuracy: 0.9596\n",
      "Epoch 426/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0856 - accuracy: 0.9680\n",
      "Epoch 00426: val_loss improved from 0.08628 to 0.08614, saving model to ./model\\426-0.0861.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0825 - accuracy: 0.9694 - val_loss: 0.0861 - val_accuracy: 0.9658\n",
      "Epoch 427/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0784 - accuracy: 0.9700\n",
      "Epoch 00427: val_loss did not improve from 0.08614\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0820 - accuracy: 0.9709 - val_loss: 0.0864 - val_accuracy: 0.9596\n",
      "Epoch 428/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0737 - accuracy: 0.9760\n",
      "Epoch 00428: val_loss did not improve from 0.08614\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0819 - accuracy: 0.9694 - val_loss: 0.0873 - val_accuracy: 0.9596\n",
      "Epoch 429/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0812 - accuracy: 0.9680\n",
      "Epoch 00429: val_loss improved from 0.08614 to 0.08536, saving model to ./model\\429-0.0854.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0817 - accuracy: 0.9694 - val_loss: 0.0854 - val_accuracy: 0.9658\n",
      "Epoch 430/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0767 - accuracy: 0.9720\n",
      "Epoch 00430: val_loss did not improve from 0.08536\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0813 - accuracy: 0.9724 - val_loss: 0.0854 - val_accuracy: 0.9658\n",
      "Epoch 431/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0880 - accuracy: 0.9680\n",
      "Epoch 00431: val_loss did not improve from 0.08536\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0813 - accuracy: 0.9709 - val_loss: 0.0875 - val_accuracy: 0.9596\n",
      "Epoch 432/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0859 - accuracy: 0.9680\n",
      "Epoch 00432: val_loss did not improve from 0.08536\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9709 - val_loss: 0.0920 - val_accuracy: 0.9627\n",
      "Epoch 433/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0925 - accuracy: 0.9580\n",
      "Epoch 00433: val_loss did not improve from 0.08536\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0832 - accuracy: 0.9663 - val_loss: 0.0887 - val_accuracy: 0.9596\n",
      "Epoch 434/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0852 - accuracy: 0.9660\n",
      "Epoch 00434: val_loss improved from 0.08536 to 0.08531, saving model to ./model\\434-0.0853.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0818 - accuracy: 0.9694 - val_loss: 0.0853 - val_accuracy: 0.9627\n",
      "Epoch 435/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0863 - accuracy: 0.9680\n",
      "Epoch 00435: val_loss did not improve from 0.08531\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0801 - accuracy: 0.9724 - val_loss: 0.0854 - val_accuracy: 0.9596\n",
      "Epoch 436/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0766 - accuracy: 0.9780\n",
      "Epoch 00436: val_loss improved from 0.08531 to 0.08287, saving model to ./model\\436-0.0829.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0805 - accuracy: 0.9724 - val_loss: 0.0829 - val_accuracy: 0.9627\n",
      "Epoch 437/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0809 - accuracy: 0.9740\n",
      "Epoch 00437: val_loss improved from 0.08287 to 0.08190, saving model to ./model\\437-0.0819.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0806 - accuracy: 0.9724 - val_loss: 0.0819 - val_accuracy: 0.9658\n",
      "Epoch 438/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0858 - accuracy: 0.9640\n",
      "Epoch 00438: val_loss did not improve from 0.08190\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0804 - accuracy: 0.9694 - val_loss: 0.0875 - val_accuracy: 0.9627\n",
      "Epoch 439/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0801 - accuracy: 0.9660\n",
      "Epoch 00439: val_loss did not improve from 0.08190\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0811 - accuracy: 0.9678 - val_loss: 0.0931 - val_accuracy: 0.9596\n",
      "Epoch 440/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0851 - accuracy: 0.9620\n",
      "Epoch 00440: val_loss did not improve from 0.08190\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9648 - val_loss: 0.0845 - val_accuracy: 0.9627\n",
      "Epoch 441/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0710 - accuracy: 0.9740\n",
      "Epoch 00441: val_loss improved from 0.08190 to 0.08092, saving model to ./model\\441-0.0809.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0787 - accuracy: 0.9709 - val_loss: 0.0809 - val_accuracy: 0.9720\n",
      "Epoch 442/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0779 - accuracy: 0.9700\n",
      "Epoch 00442: val_loss improved from 0.08092 to 0.08003, saving model to ./model\\442-0.0800.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0816 - accuracy: 0.9709 - val_loss: 0.0800 - val_accuracy: 0.9720\n",
      "Epoch 443/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0767 - accuracy: 0.9720\n",
      "Epoch 00443: val_loss did not improve from 0.08003\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9694 - val_loss: 0.0853 - val_accuracy: 0.9627\n",
      "Epoch 444/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0837 - accuracy: 0.9640\n",
      "Epoch 00444: val_loss did not improve from 0.08003\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0798 - accuracy: 0.9678 - val_loss: 0.0877 - val_accuracy: 0.9627\n",
      "Epoch 445/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0759 - accuracy: 0.9680\n",
      "Epoch 00445: val_loss did not improve from 0.08003\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0809 - accuracy: 0.9648 - val_loss: 0.0809 - val_accuracy: 0.9658\n",
      "Epoch 446/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0857 - accuracy: 0.9700\n",
      "Epoch 00446: val_loss improved from 0.08003 to 0.07945, saving model to ./model\\446-0.0795.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0790 - accuracy: 0.9740 - val_loss: 0.0795 - val_accuracy: 0.9720\n",
      "Epoch 447/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0855 - accuracy: 0.9700\n",
      "Epoch 00447: val_loss did not improve from 0.07945\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0800 - accuracy: 0.9724 - val_loss: 0.0825 - val_accuracy: 0.9658\n",
      "Epoch 448/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0827 - accuracy: 0.9680\n",
      "Epoch 00448: val_loss did not improve from 0.07945\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0779 - accuracy: 0.9709 - val_loss: 0.0848 - val_accuracy: 0.9627\n",
      "Epoch 449/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0733 - accuracy: 0.9700\n",
      "Epoch 00449: val_loss did not improve from 0.07945\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0780 - accuracy: 0.9694 - val_loss: 0.0809 - val_accuracy: 0.9658\n",
      "Epoch 450/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0838 - accuracy: 0.9720\n",
      "Epoch 00450: val_loss did not improve from 0.07945\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0781 - accuracy: 0.9740 - val_loss: 0.0797 - val_accuracy: 0.9658\n",
      "Epoch 451/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0796 - accuracy: 0.9700\n",
      "Epoch 00451: val_loss did not improve from 0.07945\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0772 - accuracy: 0.9724 - val_loss: 0.0845 - val_accuracy: 0.9627\n",
      "Epoch 452/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0799 - accuracy: 0.9700\n",
      "Epoch 00452: val_loss did not improve from 0.07945\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9678 - val_loss: 0.0826 - val_accuracy: 0.9658\n",
      "Epoch 453/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0779 - accuracy: 0.9720\n",
      "Epoch 00453: val_loss improved from 0.07945 to 0.07750, saving model to ./model\\453-0.0775.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0770 - accuracy: 0.9709 - val_loss: 0.0775 - val_accuracy: 0.9720\n",
      "Epoch 454/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0794 - accuracy: 0.9680\n",
      "Epoch 00454: val_loss did not improve from 0.07750\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0811 - accuracy: 0.9694 - val_loss: 0.0794 - val_accuracy: 0.9658\n",
      "Epoch 455/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0745 - accuracy: 0.9720\n",
      "Epoch 00455: val_loss did not improve from 0.07750\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0757 - accuracy: 0.9724 - val_loss: 0.0938 - val_accuracy: 0.9596\n",
      "Epoch 456/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0903 - accuracy: 0.9580\n",
      "Epoch 00456: val_loss did not improve from 0.07750\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0857 - accuracy: 0.9617 - val_loss: 0.0889 - val_accuracy: 0.9596\n",
      "Epoch 457/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0908 - accuracy: 0.9580\n",
      "Epoch 00457: val_loss did not improve from 0.07750\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0825 - accuracy: 0.9663 - val_loss: 0.0781 - val_accuracy: 0.9720\n",
      "Epoch 458/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0790 - accuracy: 0.9720\n",
      "Epoch 00458: val_loss improved from 0.07750 to 0.07720, saving model to ./model\\458-0.0772.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0763 - accuracy: 0.9709 - val_loss: 0.0772 - val_accuracy: 0.9720\n",
      "Epoch 459/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0756 - accuracy: 0.9720\n",
      "Epoch 00459: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0764 - accuracy: 0.9709 - val_loss: 0.0804 - val_accuracy: 0.9720\n",
      "Epoch 460/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0821 - accuracy: 0.9700\n",
      "Epoch 00460: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0761 - accuracy: 0.9694 - val_loss: 0.0836 - val_accuracy: 0.9596\n",
      "Epoch 461/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0809 - accuracy: 0.9660\n",
      "Epoch 00461: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0769 - accuracy: 0.9694 - val_loss: 0.0785 - val_accuracy: 0.9658\n",
      "Epoch 462/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0770 - accuracy: 0.9700\n",
      "Epoch 00462: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0760 - accuracy: 0.9694 - val_loss: 0.0774 - val_accuracy: 0.9720\n",
      "Epoch 463/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0774 - accuracy: 0.9740\n",
      "Epoch 00463: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0757 - accuracy: 0.9709 - val_loss: 0.0832 - val_accuracy: 0.9658\n",
      "Epoch 464/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0818 - accuracy: 0.9660\n",
      "Epoch 00464: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0753 - accuracy: 0.9709 - val_loss: 0.0890 - val_accuracy: 0.9596\n",
      "Epoch 465/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0757 - accuracy: 0.9660\n",
      "Epoch 00465: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0779 - accuracy: 0.9663 - val_loss: 0.0834 - val_accuracy: 0.9658\n",
      "Epoch 466/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0785 - accuracy: 0.9720\n",
      "Epoch 00466: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0745 - accuracy: 0.9724 - val_loss: 0.0804 - val_accuracy: 0.9689\n",
      "Epoch 467/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0761 - accuracy: 0.9740\n",
      "Epoch 00467: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0758 - accuracy: 0.9709 - val_loss: 0.0820 - val_accuracy: 0.9627\n",
      "Epoch 468/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0785 - accuracy: 0.9720\n",
      "Epoch 00468: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.9740 - val_loss: 0.0889 - val_accuracy: 0.9627\n",
      "Epoch 469/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0747 - accuracy: 0.9700\n",
      "Epoch 00469: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0775 - accuracy: 0.9663 - val_loss: 0.0853 - val_accuracy: 0.9627\n",
      "Epoch 470/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0788 - accuracy: 0.9700\n",
      "Epoch 00470: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0751 - accuracy: 0.9709 - val_loss: 0.0795 - val_accuracy: 0.9689\n",
      "Epoch 471/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0821 - accuracy: 0.9640\n",
      "Epoch 00471: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0766 - accuracy: 0.9694 - val_loss: 0.0810 - val_accuracy: 0.9627\n",
      "Epoch 472/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0789 - accuracy: 0.9720\n",
      "Epoch 00472: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0739 - accuracy: 0.9740 - val_loss: 0.0866 - val_accuracy: 0.9627\n",
      "Epoch 473/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0813 - accuracy: 0.9640\n",
      "Epoch 00473: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0756 - accuracy: 0.9694 - val_loss: 0.0848 - val_accuracy: 0.9627\n",
      "Epoch 474/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0806 - accuracy: 0.9680\n",
      "Epoch 00474: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0741 - accuracy: 0.9694 - val_loss: 0.0818 - val_accuracy: 0.9658\n",
      "Epoch 475/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0698 - accuracy: 0.9740\n",
      "Epoch 00475: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0726 - accuracy: 0.9740 - val_loss: 0.0777 - val_accuracy: 0.9689\n",
      "Epoch 476/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0732 - accuracy: 0.9700\n",
      "Epoch 00476: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0744 - accuracy: 0.9709 - val_loss: 0.0776 - val_accuracy: 0.9689\n",
      "Epoch 477/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0667 - accuracy: 0.9780\n",
      "Epoch 00477: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.9724 - val_loss: 0.0853 - val_accuracy: 0.9627\n",
      "Epoch 478/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0720 - accuracy: 0.9680\n",
      "Epoch 00478: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0757 - accuracy: 0.9694 - val_loss: 0.0846 - val_accuracy: 0.9627\n",
      "Epoch 479/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0635 - accuracy: 0.9760\n",
      "Epoch 00479: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0713 - accuracy: 0.9755 - val_loss: 0.0788 - val_accuracy: 0.9658\n",
      "Epoch 480/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0808 - accuracy: 0.9680\n",
      "Epoch 00480: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0795 - accuracy: 0.9709 - val_loss: 0.0785 - val_accuracy: 0.9720\n",
      "Epoch 481/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0793 - accuracy: 0.9660\n",
      "Epoch 00481: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0709 - accuracy: 0.9724 - val_loss: 0.0953 - val_accuracy: 0.9596\n",
      "Epoch 482/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0788 - accuracy: 0.9620\n",
      "Epoch 00482: val_loss did not improve from 0.07720\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0822 - accuracy: 0.9648 - val_loss: 0.0941 - val_accuracy: 0.9596\n",
      "Epoch 483/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0695 - accuracy: 0.9700\n",
      "Epoch 00483: val_loss improved from 0.07720 to 0.07548, saving model to ./model\\483-0.0755.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0776 - accuracy: 0.9648 - val_loss: 0.0755 - val_accuracy: 0.9689\n",
      "Epoch 484/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0671 - accuracy: 0.9760\n",
      "Epoch 00484: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0790 - accuracy: 0.9709 - val_loss: 0.0756 - val_accuracy: 0.9689\n",
      "Epoch 485/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0753 - accuracy: 0.9740\n",
      "Epoch 00485: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0759 - accuracy: 0.9740 - val_loss: 0.0898 - val_accuracy: 0.9596\n",
      "Epoch 486/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0785 - accuracy: 0.9700\n",
      "Epoch 00486: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0796 - accuracy: 0.9678 - val_loss: 0.0999 - val_accuracy: 0.9596\n",
      "Epoch 487/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0990 - accuracy: 0.9520\n",
      "Epoch 00487: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0863 - accuracy: 0.9617 - val_loss: 0.0804 - val_accuracy: 0.9689\n",
      "Epoch 488/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0661 - accuracy: 0.9800\n",
      "Epoch 00488: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0701 - accuracy: 0.9770 - val_loss: 0.0760 - val_accuracy: 0.9689\n",
      "Epoch 489/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0674 - accuracy: 0.9760\n",
      "Epoch 00489: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0767 - accuracy: 0.9709 - val_loss: 0.0761 - val_accuracy: 0.9689\n",
      "Epoch 490/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0728 - accuracy: 0.9720\n",
      "Epoch 00490: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0709 - accuracy: 0.9740 - val_loss: 0.0862 - val_accuracy: 0.9658\n",
      "Epoch 491/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0754 - accuracy: 0.9720\n",
      "Epoch 00491: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0737 - accuracy: 0.9709 - val_loss: 0.0906 - val_accuracy: 0.9627\n",
      "Epoch 492/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0818 - accuracy: 0.9660\n",
      "Epoch 00492: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0754 - accuracy: 0.9678 - val_loss: 0.0795 - val_accuracy: 0.9689\n",
      "Epoch 493/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0731 - accuracy: 0.9720\n",
      "Epoch 00493: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0712 - accuracy: 0.9724 - val_loss: 0.0775 - val_accuracy: 0.9658\n",
      "Epoch 494/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0693 - accuracy: 0.9760\n",
      "Epoch 00494: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0734 - accuracy: 0.9740 - val_loss: 0.0792 - val_accuracy: 0.9720\n",
      "Epoch 495/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0704 - accuracy: 0.9720\n",
      "Epoch 00495: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0690 - accuracy: 0.9740 - val_loss: 0.0816 - val_accuracy: 0.9689\n",
      "Epoch 496/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0751 - accuracy: 0.9720\n",
      "Epoch 00496: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0694 - accuracy: 0.9740 - val_loss: 0.0829 - val_accuracy: 0.9689\n",
      "Epoch 497/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0684 - accuracy: 0.9740\n",
      "Epoch 00497: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0699 - accuracy: 0.9740 - val_loss: 0.0793 - val_accuracy: 0.9720\n",
      "Epoch 498/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0703 - accuracy: 0.9740\n",
      "Epoch 00498: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0691 - accuracy: 0.9709 - val_loss: 0.0769 - val_accuracy: 0.9720\n",
      "Epoch 499/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0695 - accuracy: 0.9680\n",
      "Epoch 00499: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0690 - accuracy: 0.9709 - val_loss: 0.0792 - val_accuracy: 0.9720\n",
      "Epoch 500/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0729 - accuracy: 0.9740\n",
      "Epoch 00500: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0689 - accuracy: 0.9740 - val_loss: 0.0810 - val_accuracy: 0.9689\n",
      "Epoch 501/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0761 - accuracy: 0.9720\n",
      "Epoch 00501: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0689 - accuracy: 0.9740 - val_loss: 0.0772 - val_accuracy: 0.9720\n",
      "Epoch 502/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0624 - accuracy: 0.9780\n",
      "Epoch 00502: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0682 - accuracy: 0.9740 - val_loss: 0.0776 - val_accuracy: 0.9720\n",
      "Epoch 503/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0655 - accuracy: 0.9740\n",
      "Epoch 00503: val_loss did not improve from 0.07548\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.9740 - val_loss: 0.0790 - val_accuracy: 0.9689\n",
      "Epoch 504/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0726 - accuracy: 0.9740\n",
      "Epoch 00504: val_loss improved from 0.07548 to 0.07480, saving model to ./model\\504-0.0748.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0679 - accuracy: 0.9770 - val_loss: 0.0748 - val_accuracy: 0.9752\n",
      "Epoch 505/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0655 - accuracy: 0.9760\n",
      "Epoch 00505: val_loss improved from 0.07480 to 0.07435, saving model to ./model\\505-0.0743.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0682 - accuracy: 0.9740 - val_loss: 0.0743 - val_accuracy: 0.9720\n",
      "Epoch 506/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0665 - accuracy: 0.9760\n",
      "Epoch 00506: val_loss did not improve from 0.07435\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0674 - accuracy: 0.9740 - val_loss: 0.0782 - val_accuracy: 0.9689\n",
      "Epoch 507/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0685 - accuracy: 0.9760\n",
      "Epoch 00507: val_loss did not improve from 0.07435\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0681 - accuracy: 0.9770 - val_loss: 0.0747 - val_accuracy: 0.9720\n",
      "Epoch 508/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0757 - accuracy: 0.9680\n",
      "Epoch 00508: val_loss improved from 0.07435 to 0.07158, saving model to ./model\\508-0.0716.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0671 - accuracy: 0.9740 - val_loss: 0.0716 - val_accuracy: 0.9689\n",
      "Epoch 509/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0679 - accuracy: 0.9700\n",
      "Epoch 00509: val_loss did not improve from 0.07158\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0681 - accuracy: 0.9724 - val_loss: 0.0727 - val_accuracy: 0.9720\n",
      "Epoch 510/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0558 - accuracy: 0.9800\n",
      "Epoch 00510: val_loss did not improve from 0.07158\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0671 - accuracy: 0.9740 - val_loss: 0.0739 - val_accuracy: 0.9720\n",
      "Epoch 511/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0649 - accuracy: 0.9720\n",
      "Epoch 00511: val_loss did not improve from 0.07158\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0662 - accuracy: 0.9740 - val_loss: 0.0726 - val_accuracy: 0.9720\n",
      "Epoch 512/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0701 - accuracy: 0.9740\n",
      "Epoch 00512: val_loss did not improve from 0.07158\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0665 - accuracy: 0.9755 - val_loss: 0.0737 - val_accuracy: 0.9720\n",
      "Epoch 513/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0665 - accuracy: 0.9760\n",
      "Epoch 00513: val_loss did not improve from 0.07158\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0661 - accuracy: 0.9770 - val_loss: 0.0781 - val_accuracy: 0.9689\n",
      "Epoch 514/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0624 - accuracy: 0.9760\n",
      "Epoch 00514: val_loss did not improve from 0.07158\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0662 - accuracy: 0.9770 - val_loss: 0.0797 - val_accuracy: 0.9689\n",
      "Epoch 515/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0709 - accuracy: 0.9740\n",
      "Epoch 00515: val_loss did not improve from 0.07158\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0662 - accuracy: 0.9786 - val_loss: 0.0758 - val_accuracy: 0.9720\n",
      "Epoch 516/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0651 - accuracy: 0.9780\n",
      "Epoch 00516: val_loss did not improve from 0.07158\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0653 - accuracy: 0.9770 - val_loss: 0.0741 - val_accuracy: 0.9720\n",
      "Epoch 517/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0628 - accuracy: 0.9740\n",
      "Epoch 00517: val_loss did not improve from 0.07158\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0660 - accuracy: 0.9724 - val_loss: 0.0758 - val_accuracy: 0.9720\n",
      "Epoch 518/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0695 - accuracy: 0.9720\n",
      "Epoch 00518: val_loss did not improve from 0.07158\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0655 - accuracy: 0.9755 - val_loss: 0.0778 - val_accuracy: 0.9720\n",
      "Epoch 519/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0698 - accuracy: 0.9740\n",
      "Epoch 00519: val_loss did not improve from 0.07158\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0654 - accuracy: 0.9770 - val_loss: 0.0750 - val_accuracy: 0.9720\n",
      "Epoch 520/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0690 - accuracy: 0.9720\n",
      "Epoch 00520: val_loss did not improve from 0.07158\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.9755 - val_loss: 0.0740 - val_accuracy: 0.9720\n",
      "Epoch 521/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0636 - accuracy: 0.9760\n",
      "Epoch 00521: val_loss did not improve from 0.07158\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0647 - accuracy: 0.9740 - val_loss: 0.0740 - val_accuracy: 0.9720\n",
      "Epoch 522/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0610 - accuracy: 0.9740\n",
      "Epoch 00522: val_loss did not improve from 0.07158\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0643 - accuracy: 0.9755 - val_loss: 0.0732 - val_accuracy: 0.9720\n",
      "Epoch 523/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0595 - accuracy: 0.9760\n",
      "Epoch 00523: val_loss did not improve from 0.07158\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0641 - accuracy: 0.9755 - val_loss: 0.0753 - val_accuracy: 0.9720\n",
      "Epoch 524/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0636 - accuracy: 0.9780\n",
      "Epoch 00524: val_loss did not improve from 0.07158\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0648 - accuracy: 0.9770 - val_loss: 0.0743 - val_accuracy: 0.9720\n",
      "Epoch 525/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0570 - accuracy: 0.9780\n",
      "Epoch 00525: val_loss improved from 0.07158 to 0.06968, saving model to ./model\\525-0.0697.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0632 - accuracy: 0.9755 - val_loss: 0.0697 - val_accuracy: 0.9720\n",
      "Epoch 526/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0679 - accuracy: 0.9780\n",
      "Epoch 00526: val_loss did not improve from 0.06968\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0672 - accuracy: 0.9770 - val_loss: 0.0714 - val_accuracy: 0.9752\n",
      "Epoch 527/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0639 - accuracy: 0.9740\n",
      "Epoch 00527: val_loss did not improve from 0.06968\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0628 - accuracy: 0.9770 - val_loss: 0.0836 - val_accuracy: 0.9689\n",
      "Epoch 528/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0763 - accuracy: 0.9700\n",
      "Epoch 00528: val_loss did not improve from 0.06968\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0689 - accuracy: 0.9709 - val_loss: 0.0823 - val_accuracy: 0.9689\n",
      "Epoch 529/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0707 - accuracy: 0.9720\n",
      "Epoch 00529: val_loss did not improve from 0.06968\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0664 - accuracy: 0.9755 - val_loss: 0.0715 - val_accuracy: 0.9752\n",
      "Epoch 530/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0653 - accuracy: 0.9740\n",
      "Epoch 00530: val_loss did not improve from 0.06968\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0636 - accuracy: 0.9770 - val_loss: 0.0707 - val_accuracy: 0.9689\n",
      "Epoch 531/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0631 - accuracy: 0.9780\n",
      "Epoch 00531: val_loss did not improve from 0.06968\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0686 - accuracy: 0.9740 - val_loss: 0.0731 - val_accuracy: 0.9752\n",
      "Epoch 532/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0625 - accuracy: 0.9760\n",
      "Epoch 00532: val_loss did not improve from 0.06968\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0630 - accuracy: 0.9770 - val_loss: 0.0799 - val_accuracy: 0.9689\n",
      "Epoch 533/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0619 - accuracy: 0.9780\n",
      "Epoch 00533: val_loss did not improve from 0.06968\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0647 - accuracy: 0.9770 - val_loss: 0.0738 - val_accuracy: 0.9752\n",
      "Epoch 534/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0685 - accuracy: 0.9740\n",
      "Epoch 00534: val_loss did not improve from 0.06968\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0640 - accuracy: 0.9770 - val_loss: 0.0716 - val_accuracy: 0.9658\n",
      "Epoch 535/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0668 - accuracy: 0.9760\n",
      "Epoch 00535: val_loss did not improve from 0.06968\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0645 - accuracy: 0.9770 - val_loss: 0.0783 - val_accuracy: 0.9720\n",
      "Epoch 536/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0600 - accuracy: 0.9780\n",
      "Epoch 00536: val_loss did not improve from 0.06968\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0667 - accuracy: 0.9770 - val_loss: 0.0812 - val_accuracy: 0.9658\n",
      "Epoch 537/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0590 - accuracy: 0.9780\n",
      "Epoch 00537: val_loss did not improve from 0.06968\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0646 - accuracy: 0.9770 - val_loss: 0.0707 - val_accuracy: 0.9689\n",
      "Epoch 538/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0664 - accuracy: 0.9740\n",
      "Epoch 00538: val_loss did not improve from 0.06968\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0665 - accuracy: 0.9740 - val_loss: 0.0706 - val_accuracy: 0.9752\n",
      "Epoch 539/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0667 - accuracy: 0.9700\n",
      "Epoch 00539: val_loss did not improve from 0.06968\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0630 - accuracy: 0.9740 - val_loss: 0.0821 - val_accuracy: 0.9689\n",
      "Epoch 540/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0596 - accuracy: 0.9740\n",
      "Epoch 00540: val_loss did not improve from 0.06968\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0673 - accuracy: 0.9724 - val_loss: 0.0741 - val_accuracy: 0.9720\n",
      "Epoch 541/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0597 - accuracy: 0.9780\n",
      "Epoch 00541: val_loss improved from 0.06968 to 0.06804, saving model to ./model\\541-0.0680.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0620 - accuracy: 0.9801 - val_loss: 0.0680 - val_accuracy: 0.9689\n",
      "Epoch 542/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0604 - accuracy: 0.9780\n",
      "Epoch 00542: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0660 - accuracy: 0.9755 - val_loss: 0.0689 - val_accuracy: 0.9752\n",
      "Epoch 543/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0663 - accuracy: 0.9740\n",
      "Epoch 00543: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0628 - accuracy: 0.9755 - val_loss: 0.0735 - val_accuracy: 0.9720\n",
      "Epoch 544/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0698 - accuracy: 0.9720\n",
      "Epoch 00544: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0616 - accuracy: 0.9770 - val_loss: 0.0743 - val_accuracy: 0.9720\n",
      "Epoch 545/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0616 - accuracy: 0.9780\n",
      "Epoch 00545: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0616 - accuracy: 0.9770 - val_loss: 0.0703 - val_accuracy: 0.9720\n",
      "Epoch 546/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0486 - accuracy: 0.9820\n",
      "Epoch 00546: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 0.9770 - val_loss: 0.0681 - val_accuracy: 0.9752\n",
      "Epoch 547/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0575 - accuracy: 0.9780\n",
      "Epoch 00547: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0629 - accuracy: 0.9755 - val_loss: 0.0685 - val_accuracy: 0.9752\n",
      "Epoch 548/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0610 - accuracy: 0.9760\n",
      "Epoch 00548: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.9755 - val_loss: 0.0682 - val_accuracy: 0.9752\n",
      "Epoch 549/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0577 - accuracy: 0.9760\n",
      "Epoch 00549: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0608 - accuracy: 0.9755 - val_loss: 0.0710 - val_accuracy: 0.9720\n",
      "Epoch 550/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0588 - accuracy: 0.9800\n",
      "Epoch 00550: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0600 - accuracy: 0.9786 - val_loss: 0.0719 - val_accuracy: 0.9720\n",
      "Epoch 551/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0598 - accuracy: 0.9800\n",
      "Epoch 00551: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0599 - accuracy: 0.9801 - val_loss: 0.0706 - val_accuracy: 0.9752\n",
      "Epoch 552/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0614 - accuracy: 0.9740\n",
      "Epoch 00552: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0595 - accuracy: 0.9770 - val_loss: 0.0702 - val_accuracy: 0.9752\n",
      "Epoch 553/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0596 - accuracy: 0.9740\n",
      "Epoch 00553: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0597 - accuracy: 0.9755 - val_loss: 0.0702 - val_accuracy: 0.9752\n",
      "Epoch 554/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0657 - accuracy: 0.9680\n",
      "Epoch 00554: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0599 - accuracy: 0.9740 - val_loss: 0.0709 - val_accuracy: 0.9752\n",
      "Epoch 555/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0597 - accuracy: 0.9760\n",
      "Epoch 00555: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0592 - accuracy: 0.9770 - val_loss: 0.0699 - val_accuracy: 0.9752\n",
      "Epoch 556/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0518 - accuracy: 0.9760\n",
      "Epoch 00556: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0592 - accuracy: 0.9770 - val_loss: 0.0701 - val_accuracy: 0.9720\n",
      "Epoch 557/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0546 - accuracy: 0.9800\n",
      "Epoch 00557: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0589 - accuracy: 0.9786 - val_loss: 0.0685 - val_accuracy: 0.9752\n",
      "Epoch 558/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0560 - accuracy: 0.9820\n",
      "Epoch 00558: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0591 - accuracy: 0.9786 - val_loss: 0.0685 - val_accuracy: 0.9752\n",
      "Epoch 559/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0569 - accuracy: 0.9780\n",
      "Epoch 00559: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0586 - accuracy: 0.9786 - val_loss: 0.0740 - val_accuracy: 0.9720\n",
      "Epoch 560/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0687 - accuracy: 0.9760\n",
      "Epoch 00560: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0594 - accuracy: 0.9816 - val_loss: 0.0788 - val_accuracy: 0.9658\n",
      "Epoch 561/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0692 - accuracy: 0.9740\n",
      "Epoch 00561: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0622 - accuracy: 0.9786 - val_loss: 0.0729 - val_accuracy: 0.9720\n",
      "Epoch 562/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0619 - accuracy: 0.9760\n",
      "Epoch 00562: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0594 - accuracy: 0.9801 - val_loss: 0.0702 - val_accuracy: 0.9752\n",
      "Epoch 563/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0494 - accuracy: 0.9840\n",
      "Epoch 00563: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0584 - accuracy: 0.9801 - val_loss: 0.0705 - val_accuracy: 0.9752\n",
      "Epoch 564/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0554 - accuracy: 0.9800\n",
      "Epoch 00564: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0580 - accuracy: 0.9786 - val_loss: 0.0695 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0598 - accuracy: 0.9800\n",
      "Epoch 00565: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0580 - accuracy: 0.9801 - val_loss: 0.0709 - val_accuracy: 0.9720\n",
      "Epoch 566/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0515 - accuracy: 0.9880\n",
      "Epoch 00566: val_loss did not improve from 0.06804\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0581 - accuracy: 0.9832 - val_loss: 0.0721 - val_accuracy: 0.9720\n",
      "Epoch 567/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0576 - accuracy: 0.9840\n",
      "Epoch 00567: val_loss improved from 0.06804 to 0.06760, saving model to ./model\\567-0.0676.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0579 - accuracy: 0.9832 - val_loss: 0.0676 - val_accuracy: 0.9752\n",
      "Epoch 568/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0583 - accuracy: 0.9800\n",
      "Epoch 00568: val_loss did not improve from 0.06760\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0583 - accuracy: 0.9786 - val_loss: 0.0678 - val_accuracy: 0.9752\n",
      "Epoch 569/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0561 - accuracy: 0.9800\n",
      "Epoch 00569: val_loss did not improve from 0.06760\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0569 - accuracy: 0.9801 - val_loss: 0.0735 - val_accuracy: 0.9689\n",
      "Epoch 570/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0542 - accuracy: 0.9820\n",
      "Epoch 00570: val_loss did not improve from 0.06760\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0590 - accuracy: 0.9801 - val_loss: 0.0697 - val_accuracy: 0.9720\n",
      "Epoch 571/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0663 - accuracy: 0.9760\n",
      "Epoch 00571: val_loss improved from 0.06760 to 0.06612, saving model to ./model\\571-0.0661.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0590 - accuracy: 0.9786 - val_loss: 0.0661 - val_accuracy: 0.9752\n",
      "Epoch 572/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0653 - accuracy: 0.9760\n",
      "Epoch 00572: val_loss did not improve from 0.06612\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0578 - accuracy: 0.9801 - val_loss: 0.0697 - val_accuracy: 0.9720\n",
      "Epoch 573/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0528 - accuracy: 0.9820\n",
      "Epoch 00573: val_loss did not improve from 0.06612\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0572 - accuracy: 0.9801 - val_loss: 0.0699 - val_accuracy: 0.9720\n",
      "Epoch 574/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0585 - accuracy: 0.9840\n",
      "Epoch 00574: val_loss improved from 0.06612 to 0.06611, saving model to ./model\\574-0.0661.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0567 - accuracy: 0.9832 - val_loss: 0.0661 - val_accuracy: 0.9752\n",
      "Epoch 575/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0593 - accuracy: 0.9760\n",
      "Epoch 00575: val_loss did not improve from 0.06611\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0573 - accuracy: 0.9801 - val_loss: 0.0661 - val_accuracy: 0.9752\n",
      "Epoch 576/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0610 - accuracy: 0.9760\n",
      "Epoch 00576: val_loss did not improve from 0.06611\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0567 - accuracy: 0.9801 - val_loss: 0.0705 - val_accuracy: 0.9720\n",
      "Epoch 577/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0599 - accuracy: 0.9820\n",
      "Epoch 00577: val_loss did not improve from 0.06611\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0575 - accuracy: 0.9832 - val_loss: 0.0720 - val_accuracy: 0.9720\n",
      "Epoch 578/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0541 - accuracy: 0.9840\n",
      "Epoch 00578: val_loss did not improve from 0.06611\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0576 - accuracy: 0.9801 - val_loss: 0.0664 - val_accuracy: 0.9752\n",
      "Epoch 579/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0588 - accuracy: 0.9800\n",
      "Epoch 00579: val_loss did not improve from 0.06611\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0567 - accuracy: 0.9816 - val_loss: 0.0661 - val_accuracy: 0.9752\n",
      "Epoch 580/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0611 - accuracy: 0.9800\n",
      "Epoch 00580: val_loss did not improve from 0.06611\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0564 - accuracy: 0.9801 - val_loss: 0.0701 - val_accuracy: 0.9720\n",
      "Epoch 581/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0528 - accuracy: 0.9820\n",
      "Epoch 00581: val_loss did not improve from 0.06611\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0564 - accuracy: 0.9801 - val_loss: 0.0684 - val_accuracy: 0.9752\n",
      "Epoch 582/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0573 - accuracy: 0.9800\n",
      "Epoch 00582: val_loss did not improve from 0.06611\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0556 - accuracy: 0.9816 - val_loss: 0.0662 - val_accuracy: 0.9752\n",
      "Epoch 583/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0585 - accuracy: 0.9820\n",
      "Epoch 00583: val_loss did not improve from 0.06611\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0564 - accuracy: 0.9801 - val_loss: 0.0703 - val_accuracy: 0.9720\n",
      "Epoch 584/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0596 - accuracy: 0.9780\n",
      "Epoch 00584: val_loss did not improve from 0.06611\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0559 - accuracy: 0.9786 - val_loss: 0.0760 - val_accuracy: 0.9658\n",
      "Epoch 585/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0611 - accuracy: 0.9800\n",
      "Epoch 00585: val_loss did not improve from 0.06611\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0585 - accuracy: 0.9801 - val_loss: 0.0678 - val_accuracy: 0.9752\n",
      "Epoch 586/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0528 - accuracy: 0.9840\n",
      "Epoch 00586: val_loss improved from 0.06611 to 0.06456, saving model to ./model\\586-0.0646.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0566 - accuracy: 0.9816 - val_loss: 0.0646 - val_accuracy: 0.9783\n",
      "Epoch 587/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0566 - accuracy: 0.9780\n",
      "Epoch 00587: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0558 - accuracy: 0.9770 - val_loss: 0.0697 - val_accuracy: 0.9720\n",
      "Epoch 588/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0570 - accuracy: 0.9840\n",
      "Epoch 00588: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0556 - accuracy: 0.9832 - val_loss: 0.0743 - val_accuracy: 0.9689\n",
      "Epoch 589/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0632 - accuracy: 0.9780\n",
      "Epoch 00589: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0577 - accuracy: 0.9801 - val_loss: 0.0676 - val_accuracy: 0.9752\n",
      "Epoch 590/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0578 - accuracy: 0.9800\n",
      "Epoch 00590: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0551 - accuracy: 0.9801 - val_loss: 0.0650 - val_accuracy: 0.9783\n",
      "Epoch 591/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0537 - accuracy: 0.9820\n",
      "Epoch 00591: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0556 - accuracy: 0.9801 - val_loss: 0.0680 - val_accuracy: 0.9752\n",
      "Epoch 592/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0569 - accuracy: 0.9820\n",
      "Epoch 00592: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0539 - accuracy: 0.9816 - val_loss: 0.0725 - val_accuracy: 0.9720\n",
      "Epoch 593/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0510 - accuracy: 0.9840\n",
      "Epoch 00593: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0560 - accuracy: 0.9816 - val_loss: 0.0694 - val_accuracy: 0.9720\n",
      "Epoch 594/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0584 - accuracy: 0.9800\n",
      "Epoch 00594: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0556 - accuracy: 0.9786 - val_loss: 0.0667 - val_accuracy: 0.9752\n",
      "Epoch 595/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0559 - accuracy: 0.9800\n",
      "Epoch 00595: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0541 - accuracy: 0.9816 - val_loss: 0.0682 - val_accuracy: 0.9752\n",
      "Epoch 596/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0466 - accuracy: 0.9860\n",
      "Epoch 00596: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0537 - accuracy: 0.9816 - val_loss: 0.0656 - val_accuracy: 0.9752\n",
      "Epoch 597/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0468 - accuracy: 0.9860\n",
      "Epoch 00597: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0544 - accuracy: 0.9801 - val_loss: 0.0651 - val_accuracy: 0.9752\n",
      "Epoch 598/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0530 - accuracy: 0.9820\n",
      "Epoch 00598: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0538 - accuracy: 0.9801 - val_loss: 0.0702 - val_accuracy: 0.9720\n",
      "Epoch 599/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0451 - accuracy: 0.9880\n",
      "Epoch 00599: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0573 - accuracy: 0.9816 - val_loss: 0.0665 - val_accuracy: 0.9752\n",
      "Epoch 600/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0490 - accuracy: 0.9820\n",
      "Epoch 00600: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0579 - accuracy: 0.9770 - val_loss: 0.0648 - val_accuracy: 0.9752\n",
      "Epoch 601/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0609 - accuracy: 0.9760\n",
      "Epoch 00601: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0548 - accuracy: 0.9816 - val_loss: 0.0757 - val_accuracy: 0.9658\n",
      "Epoch 602/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0528 - accuracy: 0.9840\n",
      "Epoch 00602: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0575 - accuracy: 0.9801 - val_loss: 0.0741 - val_accuracy: 0.9689\n",
      "Epoch 603/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0597 - accuracy: 0.9800\n",
      "Epoch 00603: val_loss did not improve from 0.06456\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0562 - accuracy: 0.9816 - val_loss: 0.0659 - val_accuracy: 0.9752\n",
      "Epoch 604/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0480 - accuracy: 0.9840\n",
      "Epoch 00604: val_loss improved from 0.06456 to 0.06441, saving model to ./model\\604-0.0644.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0539 - accuracy: 0.9832 - val_loss: 0.0644 - val_accuracy: 0.9752\n",
      "Epoch 605/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0457 - accuracy: 0.9880\n",
      "Epoch 00605: val_loss did not improve from 0.06441\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9816 - val_loss: 0.0647 - val_accuracy: 0.9752\n",
      "Epoch 606/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0496 - accuracy: 0.9820\n",
      "Epoch 00606: val_loss did not improve from 0.06441\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0528 - accuracy: 0.9816 - val_loss: 0.0679 - val_accuracy: 0.9720\n",
      "Epoch 607/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0534 - accuracy: 0.9820\n",
      "Epoch 00607: val_loss did not improve from 0.06441\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9816 - val_loss: 0.0684 - val_accuracy: 0.9720\n",
      "Epoch 608/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0509 - accuracy: 0.9860\n",
      "Epoch 00608: val_loss did not improve from 0.06441\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0527 - accuracy: 0.9832 - val_loss: 0.0645 - val_accuracy: 0.9752\n",
      "Epoch 609/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0538 - accuracy: 0.9820\n",
      "Epoch 00609: val_loss improved from 0.06441 to 0.06428, saving model to ./model\\609-0.0643.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0523 - accuracy: 0.9816 - val_loss: 0.0643 - val_accuracy: 0.9783\n",
      "Epoch 610/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0564 - accuracy: 0.9780\n",
      "Epoch 00610: val_loss did not improve from 0.06428\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0523 - accuracy: 0.9816 - val_loss: 0.0662 - val_accuracy: 0.9752\n",
      "Epoch 611/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0542 - accuracy: 0.9820\n",
      "Epoch 00611: val_loss did not improve from 0.06428\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0524 - accuracy: 0.9832 - val_loss: 0.0658 - val_accuracy: 0.9752\n",
      "Epoch 612/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0564 - accuracy: 0.9820\n",
      "Epoch 00612: val_loss improved from 0.06428 to 0.06350, saving model to ./model\\612-0.0635.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0524 - accuracy: 0.9832 - val_loss: 0.0635 - val_accuracy: 0.9783\n",
      "Epoch 613/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0495 - accuracy: 0.9840\n",
      "Epoch 00613: val_loss did not improve from 0.06350\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0518 - accuracy: 0.9832 - val_loss: 0.0646 - val_accuracy: 0.9752\n",
      "Epoch 614/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0568 - accuracy: 0.9820\n",
      "Epoch 00614: val_loss did not improve from 0.06350\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9832 - val_loss: 0.0641 - val_accuracy: 0.9752\n",
      "Epoch 615/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0544 - accuracy: 0.9780\n",
      "Epoch 00615: val_loss did not improve from 0.06350\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0517 - accuracy: 0.9816 - val_loss: 0.0642 - val_accuracy: 0.9752\n",
      "Epoch 616/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0524 - accuracy: 0.9800\n",
      "Epoch 00616: val_loss did not improve from 0.06350\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9816 - val_loss: 0.0661 - val_accuracy: 0.9752\n",
      "Epoch 617/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0534 - accuracy: 0.9840\n",
      "Epoch 00617: val_loss did not improve from 0.06350\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0515 - accuracy: 0.9832 - val_loss: 0.0648 - val_accuracy: 0.9783\n",
      "Epoch 618/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0558 - accuracy: 0.9780\n",
      "Epoch 00618: val_loss did not improve from 0.06350\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0517 - accuracy: 0.9816 - val_loss: 0.0640 - val_accuracy: 0.9783\n",
      "Epoch 619/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0518 - accuracy: 0.9860\n",
      "Epoch 00619: val_loss did not improve from 0.06350\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0522 - accuracy: 0.9847 - val_loss: 0.0668 - val_accuracy: 0.9752\n",
      "Epoch 620/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0459 - accuracy: 0.9860\n",
      "Epoch 00620: val_loss did not improve from 0.06350\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0516 - accuracy: 0.9832 - val_loss: 0.0678 - val_accuracy: 0.9720\n",
      "Epoch 621/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0607 - accuracy: 0.9800\n",
      "Epoch 00621: val_loss did not improve from 0.06350\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0520 - accuracy: 0.9847 - val_loss: 0.0680 - val_accuracy: 0.9720\n",
      "Epoch 622/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0569 - accuracy: 0.9820\n",
      "Epoch 00622: val_loss did not improve from 0.06350\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0519 - accuracy: 0.9847 - val_loss: 0.0662 - val_accuracy: 0.9720\n",
      "Epoch 623/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0556 - accuracy: 0.9780\n",
      "Epoch 00623: val_loss did not improve from 0.06350\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0512 - accuracy: 0.9832 - val_loss: 0.0637 - val_accuracy: 0.9783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 624/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0478 - accuracy: 0.9820\n",
      "Epoch 00624: val_loss improved from 0.06350 to 0.06262, saving model to ./model\\624-0.0626.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0505 - accuracy: 0.9832 - val_loss: 0.0626 - val_accuracy: 0.9783\n",
      "Epoch 625/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0438 - accuracy: 0.9820\n",
      "Epoch 00625: val_loss did not improve from 0.06262\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0506 - accuracy: 0.9816 - val_loss: 0.0629 - val_accuracy: 0.9783\n",
      "Epoch 626/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0424 - accuracy: 0.9880\n",
      "Epoch 00626: val_loss improved from 0.06262 to 0.06201, saving model to ./model\\626-0.0620.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0521 - accuracy: 0.9832 - val_loss: 0.0620 - val_accuracy: 0.9783\n",
      "Epoch 627/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0511 - accuracy: 0.9800\n",
      "Epoch 00627: val_loss improved from 0.06201 to 0.06014, saving model to ./model\\627-0.0601.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0500 - accuracy: 0.9816 - val_loss: 0.0601 - val_accuracy: 0.9752\n",
      "Epoch 628/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0500 - accuracy: 0.9840\n",
      "Epoch 00628: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0533 - accuracy: 0.9816 - val_loss: 0.0642 - val_accuracy: 0.9783\n",
      "Epoch 629/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0482 - accuracy: 0.9860\n",
      "Epoch 00629: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0513 - accuracy: 0.9816 - val_loss: 0.0722 - val_accuracy: 0.9658\n",
      "Epoch 630/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0570 - accuracy: 0.9820\n",
      "Epoch 00630: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0529 - accuracy: 0.9816 - val_loss: 0.0637 - val_accuracy: 0.9752\n",
      "Epoch 631/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0555 - accuracy: 0.9760\n",
      "Epoch 00631: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9816 - val_loss: 0.0619 - val_accuracy: 0.9783\n",
      "Epoch 632/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0481 - accuracy: 0.9840\n",
      "Epoch 00632: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0514 - accuracy: 0.9816 - val_loss: 0.0660 - val_accuracy: 0.9720\n",
      "Epoch 633/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0513 - accuracy: 0.9820\n",
      "Epoch 00633: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9832 - val_loss: 0.0668 - val_accuracy: 0.9720\n",
      "Epoch 634/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0472 - accuracy: 0.9840\n",
      "Epoch 00634: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0493 - accuracy: 0.9832 - val_loss: 0.0626 - val_accuracy: 0.9783\n",
      "Epoch 635/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0495 - accuracy: 0.9820\n",
      "Epoch 00635: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0513 - accuracy: 0.9832 - val_loss: 0.0630 - val_accuracy: 0.9752\n",
      "Epoch 636/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0549 - accuracy: 0.9820\n",
      "Epoch 00636: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 0.9847 - val_loss: 0.0691 - val_accuracy: 0.9689\n",
      "Epoch 637/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0530 - accuracy: 0.9860\n",
      "Epoch 00637: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9847 - val_loss: 0.0704 - val_accuracy: 0.9689\n",
      "Epoch 638/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0541 - accuracy: 0.9840\n",
      "Epoch 00638: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9862 - val_loss: 0.0642 - val_accuracy: 0.9752\n",
      "Epoch 639/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0555 - accuracy: 0.9780\n",
      "Epoch 00639: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0495 - accuracy: 0.9816 - val_loss: 0.0629 - val_accuracy: 0.9752\n",
      "Epoch 640/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0492 - accuracy: 0.9860\n",
      "Epoch 00640: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9832 - val_loss: 0.0633 - val_accuracy: 0.9783\n",
      "Epoch 641/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0493 - accuracy: 0.9820\n",
      "Epoch 00641: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0486 - accuracy: 0.9816 - val_loss: 0.0613 - val_accuracy: 0.9783\n",
      "Epoch 642/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0531 - accuracy: 0.9780\n",
      "Epoch 00642: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0489 - accuracy: 0.9816 - val_loss: 0.0620 - val_accuracy: 0.9783\n",
      "Epoch 643/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0542 - accuracy: 0.9800\n",
      "Epoch 00643: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0487 - accuracy: 0.9832 - val_loss: 0.0631 - val_accuracy: 0.9783\n",
      "Epoch 644/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0503 - accuracy: 0.9820\n",
      "Epoch 00644: val_loss did not improve from 0.06014\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0495 - accuracy: 0.9832 - val_loss: 0.0614 - val_accuracy: 0.9783\n",
      "Epoch 645/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0519 - accuracy: 0.9800\n",
      "Epoch 00645: val_loss improved from 0.06014 to 0.05895, saving model to ./model\\645-0.0589.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0481 - accuracy: 0.9832 - val_loss: 0.0589 - val_accuracy: 0.9752\n",
      "Epoch 646/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0472 - accuracy: 0.9840\n",
      "Epoch 00646: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0515 - accuracy: 0.9816 - val_loss: 0.0653 - val_accuracy: 0.9720\n",
      "Epoch 647/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0451 - accuracy: 0.9920\n",
      "Epoch 00647: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0512 - accuracy: 0.9847 - val_loss: 0.0791 - val_accuracy: 0.9658\n",
      "Epoch 648/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0431 - accuracy: 0.9820\n",
      "Epoch 00648: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0570 - accuracy: 0.9786 - val_loss: 0.0606 - val_accuracy: 0.9783\n",
      "Epoch 649/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0509 - accuracy: 0.9840\n",
      "Epoch 00649: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0556 - accuracy: 0.9801 - val_loss: 0.0605 - val_accuracy: 0.9783\n",
      "Epoch 650/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0542 - accuracy: 0.9820\n",
      "Epoch 00650: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0573 - accuracy: 0.9801 - val_loss: 0.0694 - val_accuracy: 0.9689\n",
      "Epoch 651/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0470 - accuracy: 0.9900\n",
      "Epoch 00651: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0542 - accuracy: 0.9816 - val_loss: 0.0702 - val_accuracy: 0.9658\n",
      "Epoch 652/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0485 - accuracy: 0.9860\n",
      "Epoch 00652: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0502 - accuracy: 0.9816 - val_loss: 0.0597 - val_accuracy: 0.9752\n",
      "Epoch 653/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0531 - accuracy: 0.9800\n",
      "Epoch 00653: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 0.9832 - val_loss: 0.0607 - val_accuracy: 0.9752\n",
      "Epoch 654/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0393 - accuracy: 0.9860\n",
      "Epoch 00654: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0510 - accuracy: 0.9801 - val_loss: 0.0661 - val_accuracy: 0.9720\n",
      "Epoch 655/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0368 - accuracy: 0.9920\n",
      "Epoch 00655: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0478 - accuracy: 0.9862 - val_loss: 0.0615 - val_accuracy: 0.9783\n",
      "Epoch 656/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0512 - accuracy: 0.9840\n",
      "Epoch 00656: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0493 - accuracy: 0.9832 - val_loss: 0.0612 - val_accuracy: 0.9752\n",
      "Epoch 657/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0448 - accuracy: 0.9840\n",
      "Epoch 00657: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0489 - accuracy: 0.9847 - val_loss: 0.0664 - val_accuracy: 0.9720\n",
      "Epoch 658/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0471 - accuracy: 0.9860\n",
      "Epoch 00658: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0480 - accuracy: 0.9847 - val_loss: 0.0624 - val_accuracy: 0.9783\n",
      "Epoch 659/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0479 - accuracy: 0.9820\n",
      "Epoch 00659: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0468 - accuracy: 0.9832 - val_loss: 0.0590 - val_accuracy: 0.9752\n",
      "Epoch 660/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0434 - accuracy: 0.9840\n",
      "Epoch 00660: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0495 - accuracy: 0.9801 - val_loss: 0.0616 - val_accuracy: 0.9783\n",
      "Epoch 661/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0474 - accuracy: 0.9840\n",
      "Epoch 00661: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0462 - accuracy: 0.9847 - val_loss: 0.0710 - val_accuracy: 0.9689\n",
      "Epoch 662/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0572 - accuracy: 0.9740\n",
      "Epoch 00662: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0519 - accuracy: 0.9801 - val_loss: 0.0688 - val_accuracy: 0.9720\n",
      "Epoch 663/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0536 - accuracy: 0.9820\n",
      "Epoch 00663: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0501 - accuracy: 0.9847 - val_loss: 0.0609 - val_accuracy: 0.9783\n",
      "Epoch 664/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0493 - accuracy: 0.9800\n",
      "Epoch 00664: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0484 - accuracy: 0.9832 - val_loss: 0.0599 - val_accuracy: 0.9783\n",
      "Epoch 665/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0445 - accuracy: 0.9820\n",
      "Epoch 00665: val_loss did not improve from 0.05895\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0480 - accuracy: 0.9816 - val_loss: 0.0622 - val_accuracy: 0.9783\n",
      "Epoch 666/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0506 - accuracy: 0.9820\n",
      "Epoch 00666: val_loss improved from 0.05895 to 0.05876, saving model to ./model\\666-0.0588.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0463 - accuracy: 0.9832 - val_loss: 0.0588 - val_accuracy: 0.9783\n",
      "Epoch 667/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0448 - accuracy: 0.9860\n",
      "Epoch 00667: val_loss did not improve from 0.05876\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0488 - accuracy: 0.9816 - val_loss: 0.0617 - val_accuracy: 0.9752\n",
      "Epoch 668/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0511 - accuracy: 0.9800\n",
      "Epoch 00668: val_loss did not improve from 0.05876\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0466 - accuracy: 0.9832 - val_loss: 0.0721 - val_accuracy: 0.9689\n",
      "Epoch 669/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0447 - accuracy: 0.9840\n",
      "Epoch 00669: val_loss did not improve from 0.05876\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0517 - accuracy: 0.9801 - val_loss: 0.0625 - val_accuracy: 0.9783\n",
      "Epoch 670/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0480 - accuracy: 0.9860\n",
      "Epoch 00670: val_loss improved from 0.05876 to 0.05814, saving model to ./model\\670-0.0581.hdf5\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0496 - accuracy: 0.9832 - val_loss: 0.0581 - val_accuracy: 0.9752\n",
      "Epoch 671/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0417 - accuracy: 0.9880\n",
      "Epoch 00671: val_loss did not improve from 0.05814\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0486 - accuracy: 0.9816 - val_loss: 0.0619 - val_accuracy: 0.9783\n",
      "Epoch 672/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0490 - accuracy: 0.9860\n",
      "Epoch 00672: val_loss did not improve from 0.05814\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0457 - accuracy: 0.9862 - val_loss: 0.0658 - val_accuracy: 0.9720\n",
      "Epoch 673/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0515 - accuracy: 0.9840\n",
      "Epoch 00673: val_loss did not improve from 0.05814\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0475 - accuracy: 0.9862 - val_loss: 0.0625 - val_accuracy: 0.9752\n",
      "Epoch 674/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0370 - accuracy: 0.9920\n",
      "Epoch 00674: val_loss improved from 0.05814 to 0.05794, saving model to ./model\\674-0.0579.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0452 - accuracy: 0.9862 - val_loss: 0.0579 - val_accuracy: 0.9752\n",
      "Epoch 675/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0534 - accuracy: 0.9800\n",
      "Epoch 00675: val_loss did not improve from 0.05794\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0498 - accuracy: 0.9832 - val_loss: 0.0586 - val_accuracy: 0.9752\n",
      "Epoch 676/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0520 - accuracy: 0.9780\n",
      "Epoch 00676: val_loss did not improve from 0.05794\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0462 - accuracy: 0.9832 - val_loss: 0.0677 - val_accuracy: 0.9720\n",
      "Epoch 677/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0408 - accuracy: 0.9820\n",
      "Epoch 00677: val_loss did not improve from 0.05794\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0501 - accuracy: 0.9816 - val_loss: 0.0658 - val_accuracy: 0.9720\n",
      "Epoch 678/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0469 - accuracy: 0.9880\n",
      "Epoch 00678: val_loss improved from 0.05794 to 0.05687, saving model to ./model\\678-0.0569.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0465 - accuracy: 0.9862 - val_loss: 0.0569 - val_accuracy: 0.9752\n",
      "Epoch 679/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0498 - accuracy: 0.9820\n",
      "Epoch 00679: val_loss improved from 0.05687 to 0.05668, saving model to ./model\\679-0.0567.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0497 - accuracy: 0.9832 - val_loss: 0.0567 - val_accuracy: 0.9752\n",
      "Epoch 680/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0461 - accuracy: 0.9860\n",
      "Epoch 00680: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0510 - accuracy: 0.9816 - val_loss: 0.0600 - val_accuracy: 0.9783\n",
      "Epoch 681/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0430 - accuracy: 0.9880\n",
      "Epoch 00681: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0453 - accuracy: 0.9832 - val_loss: 0.0617 - val_accuracy: 0.9752\n",
      "Epoch 682/3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0445 - accuracy: 0.9860\n",
      "Epoch 00682: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0455 - accuracy: 0.9832 - val_loss: 0.0596 - val_accuracy: 0.9783\n",
      "Epoch 683/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0465 - accuracy: 0.9840\n",
      "Epoch 00683: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0454 - accuracy: 0.9832 - val_loss: 0.0597 - val_accuracy: 0.9752\n",
      "Epoch 684/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0436 - accuracy: 0.9840\n",
      "Epoch 00684: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0447 - accuracy: 0.9832 - val_loss: 0.0630 - val_accuracy: 0.9752\n",
      "Epoch 685/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0416 - accuracy: 0.9880\n",
      "Epoch 00685: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0454 - accuracy: 0.9862 - val_loss: 0.0608 - val_accuracy: 0.9752\n",
      "Epoch 686/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0454 - accuracy: 0.9840\n",
      "Epoch 00686: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0453 - accuracy: 0.9847 - val_loss: 0.0589 - val_accuracy: 0.9783\n",
      "Epoch 687/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0372 - accuracy: 0.9920\n",
      "Epoch 00687: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0448 - accuracy: 0.9877 - val_loss: 0.0620 - val_accuracy: 0.9752\n",
      "Epoch 688/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0417 - accuracy: 0.9880\n",
      "Epoch 00688: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0447 - accuracy: 0.9862 - val_loss: 0.0636 - val_accuracy: 0.9752\n",
      "Epoch 689/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0473 - accuracy: 0.9820\n",
      "Epoch 00689: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0450 - accuracy: 0.9847 - val_loss: 0.0603 - val_accuracy: 0.9752\n",
      "Epoch 690/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0457 - accuracy: 0.9880\n",
      "Epoch 00690: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 0.9862 - val_loss: 0.0585 - val_accuracy: 0.9752\n",
      "Epoch 691/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0491 - accuracy: 0.9840\n",
      "Epoch 00691: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0456 - accuracy: 0.9847 - val_loss: 0.0602 - val_accuracy: 0.9752\n",
      "Epoch 692/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0516 - accuracy: 0.9840\n",
      "Epoch 00692: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0447 - accuracy: 0.9877 - val_loss: 0.0664 - val_accuracy: 0.9720\n",
      "Epoch 693/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0496 - accuracy: 0.9880\n",
      "Epoch 00693: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0469 - accuracy: 0.9877 - val_loss: 0.0629 - val_accuracy: 0.9752\n",
      "Epoch 694/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0426 - accuracy: 0.9920\n",
      "Epoch 00694: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0440 - accuracy: 0.9908 - val_loss: 0.0573 - val_accuracy: 0.9752\n",
      "Epoch 695/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0494 - accuracy: 0.9840\n",
      "Epoch 00695: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0461 - accuracy: 0.9862 - val_loss: 0.0569 - val_accuracy: 0.9752\n",
      "Epoch 696/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0428 - accuracy: 0.9860\n",
      "Epoch 00696: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0457 - accuracy: 0.9862 - val_loss: 0.0606 - val_accuracy: 0.9783\n",
      "Epoch 697/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0427 - accuracy: 0.9840\n",
      "Epoch 00697: val_loss did not improve from 0.05668\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0448 - accuracy: 0.9847 - val_loss: 0.0595 - val_accuracy: 0.9783\n",
      "Epoch 698/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0442 - accuracy: 0.9820\n",
      "Epoch 00698: val_loss improved from 0.05668 to 0.05555, saving model to ./model\\698-0.0555.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0442 - accuracy: 0.9847 - val_loss: 0.0555 - val_accuracy: 0.9783\n",
      "Epoch 699/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0488 - accuracy: 0.9780\n",
      "Epoch 00699: val_loss improved from 0.05555 to 0.05522, saving model to ./model\\699-0.0552.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0463 - accuracy: 0.9816 - val_loss: 0.0552 - val_accuracy: 0.9783\n",
      "Epoch 700/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0478 - accuracy: 0.9820\n",
      "Epoch 00700: val_loss did not improve from 0.05522\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 0.9832 - val_loss: 0.0615 - val_accuracy: 0.9720\n",
      "Epoch 701/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0505 - accuracy: 0.9840\n",
      "Epoch 00701: val_loss did not improve from 0.05522\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0462 - accuracy: 0.9862 - val_loss: 0.0639 - val_accuracy: 0.9720\n",
      "Epoch 702/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0437 - accuracy: 0.9900\n",
      "Epoch 00702: val_loss improved from 0.05522 to 0.05472, saving model to ./model\\702-0.0547.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0467 - accuracy: 0.9862 - val_loss: 0.0547 - val_accuracy: 0.9814\n",
      "Epoch 703/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0460 - accuracy: 0.9860\n",
      "Epoch 00703: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9847 - val_loss: 0.0549 - val_accuracy: 0.9783\n",
      "Epoch 704/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0430 - accuracy: 0.9840\n",
      "Epoch 00704: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0495 - accuracy: 0.9832 - val_loss: 0.0568 - val_accuracy: 0.9783\n",
      "Epoch 705/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0468 - accuracy: 0.9840\n",
      "Epoch 00705: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0430 - accuracy: 0.9847 - val_loss: 0.0594 - val_accuracy: 0.9752\n",
      "Epoch 706/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0385 - accuracy: 0.9900\n",
      "Epoch 00706: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0434 - accuracy: 0.9847 - val_loss: 0.0580 - val_accuracy: 0.9752\n",
      "Epoch 707/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0403 - accuracy: 0.9880\n",
      "Epoch 00707: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0425 - accuracy: 0.9862 - val_loss: 0.0560 - val_accuracy: 0.9752\n",
      "Epoch 708/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0498 - accuracy: 0.9820\n",
      "Epoch 00708: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0441 - accuracy: 0.9847 - val_loss: 0.0575 - val_accuracy: 0.9752\n",
      "Epoch 709/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0415 - accuracy: 0.9880\n",
      "Epoch 00709: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0432 - accuracy: 0.9877 - val_loss: 0.0636 - val_accuracy: 0.9752\n",
      "Epoch 710/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0430 - accuracy: 0.9880\n",
      "Epoch 00710: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0449 - accuracy: 0.9862 - val_loss: 0.0659 - val_accuracy: 0.9720\n",
      "Epoch 711/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0442 - accuracy: 0.9880\n",
      "Epoch 00711: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 0.9862 - val_loss: 0.0572 - val_accuracy: 0.9720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 712/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0395 - accuracy: 0.9880\n",
      "Epoch 00712: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0452 - accuracy: 0.9862 - val_loss: 0.0564 - val_accuracy: 0.9720\n",
      "Epoch 713/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0510 - accuracy: 0.9840\n",
      "Epoch 00713: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0467 - accuracy: 0.9862 - val_loss: 0.0613 - val_accuracy: 0.9752\n",
      "Epoch 714/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0397 - accuracy: 0.9880\n",
      "Epoch 00714: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0446 - accuracy: 0.9862 - val_loss: 0.0654 - val_accuracy: 0.9720\n",
      "Epoch 715/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0429 - accuracy: 0.9840\n",
      "Epoch 00715: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0445 - accuracy: 0.9862 - val_loss: 0.0560 - val_accuracy: 0.9752\n",
      "Epoch 716/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0441 - accuracy: 0.9880\n",
      "Epoch 00716: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0437 - accuracy: 0.9893 - val_loss: 0.0561 - val_accuracy: 0.9783\n",
      "Epoch 717/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0471 - accuracy: 0.9840\n",
      "Epoch 00717: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0475 - accuracy: 0.9847 - val_loss: 0.0584 - val_accuracy: 0.9752\n",
      "Epoch 718/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0394 - accuracy: 0.9880\n",
      "Epoch 00718: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9877 - val_loss: 0.0608 - val_accuracy: 0.9752\n",
      "Epoch 719/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0367 - accuracy: 0.9920\n",
      "Epoch 00719: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0429 - accuracy: 0.9847 - val_loss: 0.0576 - val_accuracy: 0.9752\n",
      "Epoch 720/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0341 - accuracy: 0.9900\n",
      "Epoch 00720: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0418 - accuracy: 0.9862 - val_loss: 0.0558 - val_accuracy: 0.9752\n",
      "Epoch 721/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0425 - accuracy: 0.9840\n",
      "Epoch 00721: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0447 - accuracy: 0.9847 - val_loss: 0.0562 - val_accuracy: 0.9752\n",
      "Epoch 722/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0447 - accuracy: 0.9840\n",
      "Epoch 00722: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0426 - accuracy: 0.9862 - val_loss: 0.0580 - val_accuracy: 0.9752\n",
      "Epoch 723/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0429 - accuracy: 0.9840\n",
      "Epoch 00723: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0417 - accuracy: 0.9847 - val_loss: 0.0616 - val_accuracy: 0.9752\n",
      "Epoch 724/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0470 - accuracy: 0.9840\n",
      "Epoch 00724: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 0.9877 - val_loss: 0.0651 - val_accuracy: 0.9720\n",
      "Epoch 725/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0384 - accuracy: 0.9920\n",
      "Epoch 00725: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 0.9893 - val_loss: 0.0583 - val_accuracy: 0.9752\n",
      "Epoch 726/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0433 - accuracy: 0.9860\n",
      "Epoch 00726: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.9862 - val_loss: 0.0557 - val_accuracy: 0.9720\n",
      "Epoch 727/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0421 - accuracy: 0.9880\n",
      "Epoch 00727: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0441 - accuracy: 0.9893 - val_loss: 0.0601 - val_accuracy: 0.9752\n",
      "Epoch 728/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0404 - accuracy: 0.9900\n",
      "Epoch 00728: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0417 - accuracy: 0.9877 - val_loss: 0.0603 - val_accuracy: 0.9752\n",
      "Epoch 729/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0455 - accuracy: 0.9840\n",
      "Epoch 00729: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0417 - accuracy: 0.9877 - val_loss: 0.0575 - val_accuracy: 0.9752\n",
      "Epoch 730/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0456 - accuracy: 0.9860\n",
      "Epoch 00730: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0411 - accuracy: 0.9862 - val_loss: 0.0587 - val_accuracy: 0.9752\n",
      "Epoch 731/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0374 - accuracy: 0.9860\n",
      "Epoch 00731: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0414 - accuracy: 0.9862 - val_loss: 0.0595 - val_accuracy: 0.9752\n",
      "Epoch 732/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0419 - accuracy: 0.9860\n",
      "Epoch 00732: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0414 - accuracy: 0.9862 - val_loss: 0.0570 - val_accuracy: 0.9752\n",
      "Epoch 733/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0379 - accuracy: 0.9880\n",
      "Epoch 00733: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0412 - accuracy: 0.9877 - val_loss: 0.0557 - val_accuracy: 0.9752\n",
      "Epoch 734/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0363 - accuracy: 0.9860\n",
      "Epoch 00734: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9847 - val_loss: 0.0552 - val_accuracy: 0.9783\n",
      "Epoch 735/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0463 - accuracy: 0.9820\n",
      "Epoch 00735: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0423 - accuracy: 0.9832 - val_loss: 0.0572 - val_accuracy: 0.9752\n",
      "Epoch 736/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0465 - accuracy: 0.9820\n",
      "Epoch 00736: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0405 - accuracy: 0.9862 - val_loss: 0.0623 - val_accuracy: 0.9720\n",
      "Epoch 737/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0454 - accuracy: 0.9880\n",
      "Epoch 00737: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0420 - accuracy: 0.9893 - val_loss: 0.0629 - val_accuracy: 0.9720\n",
      "Epoch 738/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0438 - accuracy: 0.9900\n",
      "Epoch 00738: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9893 - val_loss: 0.0571 - val_accuracy: 0.9752\n",
      "Epoch 739/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0412 - accuracy: 0.9840\n",
      "Epoch 00739: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0418 - accuracy: 0.9862 - val_loss: 0.0559 - val_accuracy: 0.9752\n",
      "Epoch 740/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0472 - accuracy: 0.9800\n",
      "Epoch 00740: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0413 - accuracy: 0.9847 - val_loss: 0.0604 - val_accuracy: 0.9752\n",
      "Epoch 741/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0415 - accuracy: 0.9900\n",
      "Epoch 00741: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0420 - accuracy: 0.9893 - val_loss: 0.0600 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0378 - accuracy: 0.9900\n",
      "Epoch 00742: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0410 - accuracy: 0.9877 - val_loss: 0.0555 - val_accuracy: 0.9720\n",
      "Epoch 743/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0364 - accuracy: 0.9900\n",
      "Epoch 00743: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0419 - accuracy: 0.9862 - val_loss: 0.0572 - val_accuracy: 0.9752\n",
      "Epoch 744/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0389 - accuracy: 0.9860\n",
      "Epoch 00744: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0396 - accuracy: 0.9877 - val_loss: 0.0676 - val_accuracy: 0.9720\n",
      "Epoch 745/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0462 - accuracy: 0.9840\n",
      "Epoch 00745: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0443 - accuracy: 0.9847 - val_loss: 0.0665 - val_accuracy: 0.9752\n",
      "Epoch 746/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0421 - accuracy: 0.9900\n",
      "Epoch 00746: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0426 - accuracy: 0.9877 - val_loss: 0.0584 - val_accuracy: 0.9720\n",
      "Epoch 747/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0432 - accuracy: 0.9840\n",
      "Epoch 00747: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0432 - accuracy: 0.9847 - val_loss: 0.0587 - val_accuracy: 0.9720\n",
      "Epoch 748/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0445 - accuracy: 0.9840\n",
      "Epoch 00748: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0398 - accuracy: 0.9877 - val_loss: 0.0684 - val_accuracy: 0.9720\n",
      "Epoch 749/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0443 - accuracy: 0.9880\n",
      "Epoch 00749: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 0.9862 - val_loss: 0.0671 - val_accuracy: 0.9689\n",
      "Epoch 750/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0390 - accuracy: 0.9900\n",
      "Epoch 00750: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0418 - accuracy: 0.9893 - val_loss: 0.0568 - val_accuracy: 0.9720\n",
      "Epoch 751/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0448 - accuracy: 0.9860\n",
      "Epoch 00751: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0444 - accuracy: 0.9847 - val_loss: 0.0564 - val_accuracy: 0.9752\n",
      "Epoch 752/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0429 - accuracy: 0.9840\n",
      "Epoch 00752: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0461 - accuracy: 0.9816 - val_loss: 0.0606 - val_accuracy: 0.9752\n",
      "Epoch 753/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0451 - accuracy: 0.9860\n",
      "Epoch 00753: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0403 - accuracy: 0.9877 - val_loss: 0.0610 - val_accuracy: 0.9752\n",
      "Epoch 754/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0384 - accuracy: 0.9920\n",
      "Epoch 00754: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 0.9893 - val_loss: 0.0569 - val_accuracy: 0.9752\n",
      "Epoch 755/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0430 - accuracy: 0.9880\n",
      "Epoch 00755: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0406 - accuracy: 0.9877 - val_loss: 0.0572 - val_accuracy: 0.9752\n",
      "Epoch 756/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0413 - accuracy: 0.9880\n",
      "Epoch 00756: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0397 - accuracy: 0.9877 - val_loss: 0.0616 - val_accuracy: 0.9752\n",
      "Epoch 757/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0388 - accuracy: 0.9920\n",
      "Epoch 00757: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0409 - accuracy: 0.9862 - val_loss: 0.0590 - val_accuracy: 0.9752\n",
      "Epoch 758/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0442 - accuracy: 0.9840\n",
      "Epoch 00758: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 0.9877 - val_loss: 0.0553 - val_accuracy: 0.9720\n",
      "Epoch 759/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0389 - accuracy: 0.9880\n",
      "Epoch 00759: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0408 - accuracy: 0.9862 - val_loss: 0.0562 - val_accuracy: 0.9720\n",
      "Epoch 760/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0371 - accuracy: 0.9880\n",
      "Epoch 00760: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0402 - accuracy: 0.9877 - val_loss: 0.0560 - val_accuracy: 0.9720\n",
      "Epoch 761/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0421 - accuracy: 0.9880\n",
      "Epoch 00761: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0400 - accuracy: 0.9893 - val_loss: 0.0571 - val_accuracy: 0.9752\n",
      "Epoch 762/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0393 - accuracy: 0.9880\n",
      "Epoch 00762: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0391 - accuracy: 0.9877 - val_loss: 0.0617 - val_accuracy: 0.9752\n",
      "Epoch 763/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0378 - accuracy: 0.9880\n",
      "Epoch 00763: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0400 - accuracy: 0.9877 - val_loss: 0.0583 - val_accuracy: 0.9752\n",
      "Epoch 764/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0350 - accuracy: 0.9920\n",
      "Epoch 00764: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0385 - accuracy: 0.9893 - val_loss: 0.0551 - val_accuracy: 0.9752\n",
      "Epoch 765/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0439 - accuracy: 0.9840\n",
      "Epoch 00765: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0416 - accuracy: 0.9862 - val_loss: 0.0559 - val_accuracy: 0.9720\n",
      "Epoch 766/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0378 - accuracy: 0.9860\n",
      "Epoch 00766: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0383 - accuracy: 0.9877 - val_loss: 0.0646 - val_accuracy: 0.9720\n",
      "Epoch 767/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0393 - accuracy: 0.9920\n",
      "Epoch 00767: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0422 - accuracy: 0.9893 - val_loss: 0.0637 - val_accuracy: 0.9720\n",
      "Epoch 768/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0411 - accuracy: 0.9920\n",
      "Epoch 00768: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0396 - accuracy: 0.9908 - val_loss: 0.0557 - val_accuracy: 0.9752\n",
      "Epoch 769/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0413 - accuracy: 0.9840\n",
      "Epoch 00769: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0418 - accuracy: 0.9862 - val_loss: 0.0561 - val_accuracy: 0.9720\n",
      "Epoch 770/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0342 - accuracy: 0.9900\n",
      "Epoch 00770: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0415 - accuracy: 0.9877 - val_loss: 0.0613 - val_accuracy: 0.9752\n",
      "Epoch 771/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0350 - accuracy: 0.9920\n",
      "Epoch 00771: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0390 - accuracy: 0.9877 - val_loss: 0.0603 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 772/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0337 - accuracy: 0.9880\n",
      "Epoch 00772: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0382 - accuracy: 0.9877 - val_loss: 0.0588 - val_accuracy: 0.9752\n",
      "Epoch 773/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0247 - accuracy: 0.9960\n",
      "Epoch 00773: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0378 - accuracy: 0.9877 - val_loss: 0.0583 - val_accuracy: 0.9752\n",
      "Epoch 774/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0399 - accuracy: 0.9860\n",
      "Epoch 00774: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0375 - accuracy: 0.9877 - val_loss: 0.0605 - val_accuracy: 0.9752\n",
      "Epoch 775/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0362 - accuracy: 0.9920\n",
      "Epoch 00775: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0370 - accuracy: 0.9908 - val_loss: 0.0608 - val_accuracy: 0.9752\n",
      "Epoch 776/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0396 - accuracy: 0.9900\n",
      "Epoch 00776: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 0.9893 - val_loss: 0.0609 - val_accuracy: 0.9752\n",
      "Epoch 777/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0393 - accuracy: 0.9900\n",
      "Epoch 00777: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 0.9908 - val_loss: 0.0625 - val_accuracy: 0.9752\n",
      "Epoch 778/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0408 - accuracy: 0.9880\n",
      "Epoch 00778: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9908 - val_loss: 0.0616 - val_accuracy: 0.9752\n",
      "Epoch 779/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0390 - accuracy: 0.9920\n",
      "Epoch 00779: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0370 - accuracy: 0.9923 - val_loss: 0.0586 - val_accuracy: 0.9783\n",
      "Epoch 780/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0320 - accuracy: 0.9880\n",
      "Epoch 00780: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0363 - accuracy: 0.9877 - val_loss: 0.0558 - val_accuracy: 0.9783\n",
      "Epoch 781/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0347 - accuracy: 0.9920\n",
      "Epoch 00781: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0378 - accuracy: 0.9923 - val_loss: 0.0551 - val_accuracy: 0.9783\n",
      "Epoch 782/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0427 - accuracy: 0.9900\n",
      "Epoch 00782: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0373 - accuracy: 0.9923 - val_loss: 0.0582 - val_accuracy: 0.9783\n",
      "Epoch 783/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0361 - accuracy: 0.9900\n",
      "Epoch 00783: val_loss did not improve from 0.05472\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0361 - accuracy: 0.9908 - val_loss: 0.0600 - val_accuracy: 0.9783\n",
      "Epoch 784/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0289 - accuracy: 0.9940\n",
      "Epoch 00784: val_loss improved from 0.05472 to 0.05470, saving model to ./model\\784-0.0547.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0369 - accuracy: 0.9908 - val_loss: 0.0547 - val_accuracy: 0.9783\n",
      "Epoch 785/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0361 - accuracy: 0.9860\n",
      "Epoch 00785: val_loss improved from 0.05470 to 0.05449, saving model to ./model\\785-0.0545.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0370 - accuracy: 0.9862 - val_loss: 0.0545 - val_accuracy: 0.9783\n",
      "Epoch 786/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0417 - accuracy: 0.9860\n",
      "Epoch 00786: val_loss did not improve from 0.05449\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9893 - val_loss: 0.0620 - val_accuracy: 0.9752\n",
      "Epoch 787/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0396 - accuracy: 0.9940\n",
      "Epoch 00787: val_loss did not improve from 0.05449\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9908 - val_loss: 0.0553 - val_accuracy: 0.9783\n",
      "Epoch 788/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0331 - accuracy: 0.9920\n",
      "Epoch 00788: val_loss improved from 0.05449 to 0.05213, saving model to ./model\\788-0.0521.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0350 - accuracy: 0.9908 - val_loss: 0.0521 - val_accuracy: 0.9783\n",
      "Epoch 789/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0407 - accuracy: 0.9900\n",
      "Epoch 00789: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0413 - accuracy: 0.9877 - val_loss: 0.0556 - val_accuracy: 0.9783\n",
      "Epoch 790/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0261 - accuracy: 0.9960\n",
      "Epoch 00790: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0399 - accuracy: 0.9893 - val_loss: 0.0627 - val_accuracy: 0.9720\n",
      "Epoch 791/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0340 - accuracy: 0.9920\n",
      "Epoch 00791: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0365 - accuracy: 0.9908 - val_loss: 0.0537 - val_accuracy: 0.9783\n",
      "Epoch 792/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0429 - accuracy: 0.9840\n",
      "Epoch 00792: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0428 - accuracy: 0.9862 - val_loss: 0.0540 - val_accuracy: 0.9752\n",
      "Epoch 793/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0376 - accuracy: 0.9900\n",
      "Epoch 00793: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0361 - accuracy: 0.9893 - val_loss: 0.0705 - val_accuracy: 0.9689\n",
      "Epoch 794/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0456 - accuracy: 0.9820\n",
      "Epoch 00794: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0425 - accuracy: 0.9832 - val_loss: 0.0613 - val_accuracy: 0.9752\n",
      "Epoch 795/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0360 - accuracy: 0.9920\n",
      "Epoch 00795: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0357 - accuracy: 0.9908 - val_loss: 0.0536 - val_accuracy: 0.9783\n",
      "Epoch 796/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0471 - accuracy: 0.9840\n",
      "Epoch 00796: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0414 - accuracy: 0.9877 - val_loss: 0.0544 - val_accuracy: 0.9783\n",
      "Epoch 797/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0400 - accuracy: 0.9860\n",
      "Epoch 00797: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0349 - accuracy: 0.9877 - val_loss: 0.0690 - val_accuracy: 0.9689\n",
      "Epoch 798/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0325 - accuracy: 0.9880\n",
      "Epoch 00798: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0426 - accuracy: 0.9847 - val_loss: 0.0555 - val_accuracy: 0.9783\n",
      "Epoch 799/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0311 - accuracy: 0.9920\n",
      "Epoch 00799: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9923 - val_loss: 0.0554 - val_accuracy: 0.9720\n",
      "Epoch 800/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0491 - accuracy: 0.9820\n",
      "Epoch 00800: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0467 - accuracy: 0.9832 - val_loss: 0.0568 - val_accuracy: 0.9783\n",
      "Epoch 801/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0342 - accuracy: 0.9920\n",
      "Epoch 00801: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0373 - accuracy: 0.9877 - val_loss: 0.0704 - val_accuracy: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 802/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0376 - accuracy: 0.9900\n",
      "Epoch 00802: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0415 - accuracy: 0.9908 - val_loss: 0.0532 - val_accuracy: 0.9752\n",
      "Epoch 803/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0377 - accuracy: 0.9900\n",
      "Epoch 00803: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0412 - accuracy: 0.9862 - val_loss: 0.0544 - val_accuracy: 0.9783\n",
      "Epoch 804/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0422 - accuracy: 0.9900\n",
      "Epoch 00804: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0445 - accuracy: 0.9893 - val_loss: 0.0631 - val_accuracy: 0.9720\n",
      "Epoch 805/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0370 - accuracy: 0.9900\n",
      "Epoch 00805: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0391 - accuracy: 0.9877 - val_loss: 0.0618 - val_accuracy: 0.9752\n",
      "Epoch 806/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0400 - accuracy: 0.9880\n",
      "Epoch 00806: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0376 - accuracy: 0.9877 - val_loss: 0.0527 - val_accuracy: 0.9752\n",
      "Epoch 807/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0378 - accuracy: 0.9880\n",
      "Epoch 00807: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0360 - accuracy: 0.9893 - val_loss: 0.0533 - val_accuracy: 0.9783\n",
      "Epoch 808/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0365 - accuracy: 0.9920\n",
      "Epoch 00808: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0344 - accuracy: 0.9923 - val_loss: 0.0595 - val_accuracy: 0.9752\n",
      "Epoch 809/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0377 - accuracy: 0.9900\n",
      "Epoch 00809: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0359 - accuracy: 0.9908 - val_loss: 0.0595 - val_accuracy: 0.9752\n",
      "Epoch 810/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0375 - accuracy: 0.9920\n",
      "Epoch 00810: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0352 - accuracy: 0.9908 - val_loss: 0.0528 - val_accuracy: 0.9783\n",
      "Epoch 811/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0380 - accuracy: 0.9900\n",
      "Epoch 00811: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0353 - accuracy: 0.9908 - val_loss: 0.0525 - val_accuracy: 0.9783\n",
      "Epoch 812/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0391 - accuracy: 0.9880\n",
      "Epoch 00812: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9908 - val_loss: 0.0568 - val_accuracy: 0.9783\n",
      "Epoch 813/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0310 - accuracy: 0.9920\n",
      "Epoch 00813: val_loss did not improve from 0.05213\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0355 - accuracy: 0.9893 - val_loss: 0.0536 - val_accuracy: 0.9783\n",
      "Epoch 814/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0321 - accuracy: 0.9880\n",
      "Epoch 00814: val_loss improved from 0.05213 to 0.05189, saving model to ./model\\814-0.0519.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0340 - accuracy: 0.9893 - val_loss: 0.0519 - val_accuracy: 0.9783\n",
      "Epoch 815/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0400 - accuracy: 0.9900\n",
      "Epoch 00815: val_loss did not improve from 0.05189\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0379 - accuracy: 0.9908 - val_loss: 0.0544 - val_accuracy: 0.9783\n",
      "Epoch 816/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0335 - accuracy: 0.9900\n",
      "Epoch 00816: val_loss did not improve from 0.05189\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0344 - accuracy: 0.9893 - val_loss: 0.0626 - val_accuracy: 0.9720\n",
      "Epoch 817/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0443 - accuracy: 0.9900\n",
      "Epoch 00817: val_loss did not improve from 0.05189\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0386 - accuracy: 0.9908 - val_loss: 0.0546 - val_accuracy: 0.9783\n",
      "Epoch 818/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0324 - accuracy: 0.9900\n",
      "Epoch 00818: val_loss improved from 0.05189 to 0.05138, saving model to ./model\\818-0.0514.hdf5\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0335 - accuracy: 0.9893 - val_loss: 0.0514 - val_accuracy: 0.9783\n",
      "Epoch 819/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0359 - accuracy: 0.9900\n",
      "Epoch 00819: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 0.9908 - val_loss: 0.0532 - val_accuracy: 0.9783\n",
      "Epoch 820/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0345 - accuracy: 0.9900\n",
      "Epoch 00820: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 0.9877 - val_loss: 0.0577 - val_accuracy: 0.9783\n",
      "Epoch 821/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0256 - accuracy: 0.9940\n",
      "Epoch 00821: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9893 - val_loss: 0.0529 - val_accuracy: 0.9783\n",
      "Epoch 822/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0389 - accuracy: 0.9920\n",
      "Epoch 00822: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0346 - accuracy: 0.9908 - val_loss: 0.0529 - val_accuracy: 0.9783\n",
      "Epoch 823/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0344 - accuracy: 0.9880\n",
      "Epoch 00823: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0341 - accuracy: 0.9893 - val_loss: 0.0586 - val_accuracy: 0.9752\n",
      "Epoch 824/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0399 - accuracy: 0.9880\n",
      "Epoch 00824: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0346 - accuracy: 0.9908 - val_loss: 0.0591 - val_accuracy: 0.9752\n",
      "Epoch 825/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0304 - accuracy: 0.9900\n",
      "Epoch 00825: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0342 - accuracy: 0.9908 - val_loss: 0.0535 - val_accuracy: 0.9783\n",
      "Epoch 826/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0347 - accuracy: 0.9920\n",
      "Epoch 00826: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0345 - accuracy: 0.9923 - val_loss: 0.0536 - val_accuracy: 0.9783\n",
      "Epoch 827/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0300 - accuracy: 0.9960\n",
      "Epoch 00827: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0333 - accuracy: 0.9923 - val_loss: 0.0597 - val_accuracy: 0.9752\n",
      "Epoch 828/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0304 - accuracy: 0.9940\n",
      "Epoch 00828: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0362 - accuracy: 0.9908 - val_loss: 0.0543 - val_accuracy: 0.9783\n",
      "Epoch 829/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0380 - accuracy: 0.9860\n",
      "Epoch 00829: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 0.9877 - val_loss: 0.0520 - val_accuracy: 0.9814\n",
      "Epoch 830/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0370 - accuracy: 0.9880\n",
      "Epoch 00830: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0402 - accuracy: 0.9893 - val_loss: 0.0528 - val_accuracy: 0.9783\n",
      "Epoch 831/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0316 - accuracy: 0.9920\n",
      "Epoch 00831: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0334 - accuracy: 0.9923 - val_loss: 0.0598 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 832/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0267 - accuracy: 0.9940\n",
      "Epoch 00832: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0377 - accuracy: 0.9908 - val_loss: 0.0581 - val_accuracy: 0.9783\n",
      "Epoch 833/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0377 - accuracy: 0.9900\n",
      "Epoch 00833: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0349 - accuracy: 0.9908 - val_loss: 0.0516 - val_accuracy: 0.9783\n",
      "Epoch 834/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0373 - accuracy: 0.9880\n",
      "Epoch 00834: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0375 - accuracy: 0.9908 - val_loss: 0.0532 - val_accuracy: 0.9783\n",
      "Epoch 835/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0298 - accuracy: 0.9920\n",
      "Epoch 00835: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9908 - val_loss: 0.0644 - val_accuracy: 0.9720\n",
      "Epoch 836/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0324 - accuracy: 0.9920\n",
      "Epoch 00836: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0381 - accuracy: 0.9908 - val_loss: 0.0551 - val_accuracy: 0.9783\n",
      "Epoch 837/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0332 - accuracy: 0.9900\n",
      "Epoch 00837: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 0.9893 - val_loss: 0.0516 - val_accuracy: 0.9783\n",
      "Epoch 838/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0363 - accuracy: 0.9900\n",
      "Epoch 00838: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9908 - val_loss: 0.0545 - val_accuracy: 0.9783\n",
      "Epoch 839/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0335 - accuracy: 0.9880\n",
      "Epoch 00839: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0330 - accuracy: 0.9893 - val_loss: 0.0626 - val_accuracy: 0.9720\n",
      "Epoch 840/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0396 - accuracy: 0.9900\n",
      "Epoch 00840: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 0.9908 - val_loss: 0.0545 - val_accuracy: 0.9783\n",
      "Epoch 841/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0317 - accuracy: 0.9900\n",
      "Epoch 00841: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0325 - accuracy: 0.9923 - val_loss: 0.0517 - val_accuracy: 0.9783\n",
      "Epoch 842/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0317 - accuracy: 0.9940\n",
      "Epoch 00842: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0367 - accuracy: 0.9908 - val_loss: 0.0590 - val_accuracy: 0.9783\n",
      "Epoch 843/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0374 - accuracy: 0.9900\n",
      "Epoch 00843: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0364 - accuracy: 0.9893 - val_loss: 0.0754 - val_accuracy: 0.9689\n",
      "Epoch 844/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0531 - accuracy: 0.9780\n",
      "Epoch 00844: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0467 - accuracy: 0.9832 - val_loss: 0.0557 - val_accuracy: 0.9783\n",
      "Epoch 845/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0326 - accuracy: 0.9920\n",
      "Epoch 00845: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0337 - accuracy: 0.9893 - val_loss: 0.0526 - val_accuracy: 0.9752\n",
      "Epoch 846/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0341 - accuracy: 0.9920\n",
      "Epoch 00846: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0381 - accuracy: 0.9908 - val_loss: 0.0592 - val_accuracy: 0.9783\n",
      "Epoch 847/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0379 - accuracy: 0.9920\n",
      "Epoch 00847: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9908 - val_loss: 0.0762 - val_accuracy: 0.9689\n",
      "Epoch 848/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0405 - accuracy: 0.9840\n",
      "Epoch 00848: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0459 - accuracy: 0.9816 - val_loss: 0.0514 - val_accuracy: 0.9752\n",
      "Epoch 849/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0318 - accuracy: 0.9920\n",
      "Epoch 00849: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0347 - accuracy: 0.9893 - val_loss: 0.0614 - val_accuracy: 0.9720\n",
      "Epoch 850/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0597 - accuracy: 0.9760\n",
      "Epoch 00850: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0570 - accuracy: 0.9770 - val_loss: 0.0579 - val_accuracy: 0.9783\n",
      "Epoch 851/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0299 - accuracy: 0.9920\n",
      "Epoch 00851: val_loss did not improve from 0.05138\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0412 - accuracy: 0.9877 - val_loss: 0.0741 - val_accuracy: 0.9689\n",
      "Epoch 852/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0452 - accuracy: 0.9760\n",
      "Epoch 00852: val_loss improved from 0.05138 to 0.05023, saving model to ./model\\852-0.0502.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0454 - accuracy: 0.9786 - val_loss: 0.0502 - val_accuracy: 0.9783\n",
      "Epoch 853/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0327 - accuracy: 0.9880\n",
      "Epoch 00853: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9862 - val_loss: 0.0531 - val_accuracy: 0.9752\n",
      "Epoch 854/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0452 - accuracy: 0.9840\n",
      "Epoch 00854: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.9862 - val_loss: 0.0559 - val_accuracy: 0.9783\n",
      "Epoch 855/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0364 - accuracy: 0.9880\n",
      "Epoch 00855: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 0.9893 - val_loss: 0.0667 - val_accuracy: 0.9720\n",
      "Epoch 856/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0415 - accuracy: 0.9860\n",
      "Epoch 00856: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0394 - accuracy: 0.9877 - val_loss: 0.0538 - val_accuracy: 0.9783\n",
      "Epoch 857/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0321 - accuracy: 0.9940\n",
      "Epoch 00857: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9939 - val_loss: 0.0509 - val_accuracy: 0.9783\n",
      "Epoch 858/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0427 - accuracy: 0.9860\n",
      "Epoch 00858: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0370 - accuracy: 0.9893 - val_loss: 0.0530 - val_accuracy: 0.9783\n",
      "Epoch 859/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0275 - accuracy: 0.9920\n",
      "Epoch 00859: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 0.0572 - val_accuracy: 0.9783\n",
      "Epoch 860/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0256 - accuracy: 0.9940\n",
      "Epoch 00860: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.9893 - val_loss: 0.0513 - val_accuracy: 0.9783\n",
      "Epoch 861/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0335 - accuracy: 0.9900\n",
      "Epoch 00861: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0353 - accuracy: 0.9908 - val_loss: 0.0523 - val_accuracy: 0.9783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 862/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0369 - accuracy: 0.9900\n",
      "Epoch 00862: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0365 - accuracy: 0.9893 - val_loss: 0.0599 - val_accuracy: 0.9783\n",
      "Epoch 863/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0369 - accuracy: 0.9880\n",
      "Epoch 00863: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0340 - accuracy: 0.9908 - val_loss: 0.0722 - val_accuracy: 0.9689\n",
      "Epoch 864/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0472 - accuracy: 0.9840\n",
      "Epoch 00864: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0425 - accuracy: 0.9847 - val_loss: 0.0564 - val_accuracy: 0.9783\n",
      "Epoch 865/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0311 - accuracy: 0.9900\n",
      "Epoch 00865: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9877 - val_loss: 0.0517 - val_accuracy: 0.9783\n",
      "Epoch 866/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0391 - accuracy: 0.9900\n",
      "Epoch 00866: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9923 - val_loss: 0.0543 - val_accuracy: 0.9783\n",
      "Epoch 867/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0348 - accuracy: 0.9860\n",
      "Epoch 00867: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0317 - accuracy: 0.9877 - val_loss: 0.0569 - val_accuracy: 0.9783\n",
      "Epoch 868/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0256 - accuracy: 0.9900\n",
      "Epoch 00868: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0319 - accuracy: 0.9877 - val_loss: 0.0546 - val_accuracy: 0.9783\n",
      "Epoch 869/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0314 - accuracy: 0.9940\n",
      "Epoch 00869: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.9939 - val_loss: 0.0537 - val_accuracy: 0.9752\n",
      "Epoch 870/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0341 - accuracy: 0.9900\n",
      "Epoch 00870: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0324 - accuracy: 0.9893 - val_loss: 0.0557 - val_accuracy: 0.9783\n",
      "Epoch 871/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0230 - accuracy: 0.9920\n",
      "Epoch 00871: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0323 - accuracy: 0.9893 - val_loss: 0.0531 - val_accuracy: 0.9752\n",
      "Epoch 872/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0318 - accuracy: 0.9920\n",
      "Epoch 00872: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0323 - accuracy: 0.9908 - val_loss: 0.0532 - val_accuracy: 0.9783\n",
      "Epoch 873/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0383 - accuracy: 0.9920\n",
      "Epoch 00873: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0363 - accuracy: 0.9908 - val_loss: 0.0570 - val_accuracy: 0.9783\n",
      "Epoch 874/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0248 - accuracy: 0.9920\n",
      "Epoch 00874: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0343 - accuracy: 0.9908 - val_loss: 0.0667 - val_accuracy: 0.9720\n",
      "Epoch 875/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0320 - accuracy: 0.9960\n",
      "Epoch 00875: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0350 - accuracy: 0.9908 - val_loss: 0.0541 - val_accuracy: 0.9752\n",
      "Epoch 876/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0357 - accuracy: 0.9880\n",
      "Epoch 00876: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0337 - accuracy: 0.9893 - val_loss: 0.0564 - val_accuracy: 0.9752\n",
      "Epoch 877/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0476 - accuracy: 0.9860\n",
      "Epoch 00877: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0432 - accuracy: 0.9862 - val_loss: 0.0583 - val_accuracy: 0.9783\n",
      "Epoch 878/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0297 - accuracy: 0.9900\n",
      "Epoch 00878: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9908 - val_loss: 0.0727 - val_accuracy: 0.9689\n",
      "Epoch 879/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0336 - accuracy: 0.9860\n",
      "Epoch 00879: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0414 - accuracy: 0.9832 - val_loss: 0.0560 - val_accuracy: 0.9783\n",
      "Epoch 880/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0323 - accuracy: 0.9900\n",
      "Epoch 00880: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0324 - accuracy: 0.9908 - val_loss: 0.0537 - val_accuracy: 0.9783\n",
      "Epoch 881/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0438 - accuracy: 0.9860\n",
      "Epoch 00881: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0405 - accuracy: 0.9877 - val_loss: 0.0540 - val_accuracy: 0.9783\n",
      "Epoch 882/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0323 - accuracy: 0.9940\n",
      "Epoch 00882: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0303 - accuracy: 0.9939 - val_loss: 0.0678 - val_accuracy: 0.9689\n",
      "Epoch 883/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0417 - accuracy: 0.9860\n",
      "Epoch 00883: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0397 - accuracy: 0.9862 - val_loss: 0.0592 - val_accuracy: 0.9783\n",
      "Epoch 884/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0285 - accuracy: 0.9920\n",
      "Epoch 00884: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9923 - val_loss: 0.0512 - val_accuracy: 0.9752\n",
      "Epoch 885/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0382 - accuracy: 0.9920\n",
      "Epoch 00885: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0370 - accuracy: 0.9908 - val_loss: 0.0513 - val_accuracy: 0.9752\n",
      "Epoch 886/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0397 - accuracy: 0.9900\n",
      "Epoch 00886: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0361 - accuracy: 0.9908 - val_loss: 0.0562 - val_accuracy: 0.9783\n",
      "Epoch 887/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0307 - accuracy: 0.9900\n",
      "Epoch 00887: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9908 - val_loss: 0.0651 - val_accuracy: 0.9752\n",
      "Epoch 888/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0322 - accuracy: 0.9920\n",
      "Epoch 00888: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0376 - accuracy: 0.9893 - val_loss: 0.0542 - val_accuracy: 0.9783\n",
      "Epoch 889/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0307 - accuracy: 0.9900\n",
      "Epoch 00889: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0317 - accuracy: 0.9908 - val_loss: 0.0520 - val_accuracy: 0.9814\n",
      "Epoch 890/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0303 - accuracy: 0.9940\n",
      "Epoch 00890: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0354 - accuracy: 0.9908 - val_loss: 0.0561 - val_accuracy: 0.9783\n",
      "Epoch 891/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0195 - accuracy: 0.9940\n",
      "Epoch 00891: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9877 - val_loss: 0.0630 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 892/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0400 - accuracy: 0.9900\n",
      "Epoch 00892: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9908 - val_loss: 0.0507 - val_accuracy: 0.9814\n",
      "Epoch 893/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0354 - accuracy: 0.9920\n",
      "Epoch 00893: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0349 - accuracy: 0.9908 - val_loss: 0.0506 - val_accuracy: 0.9814\n",
      "Epoch 894/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0394 - accuracy: 0.9900\n",
      "Epoch 00894: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9908 - val_loss: 0.0591 - val_accuracy: 0.9783\n",
      "Epoch 895/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0396 - accuracy: 0.9880\n",
      "Epoch 00895: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0337 - accuracy: 0.9908 - val_loss: 0.0706 - val_accuracy: 0.9689\n",
      "Epoch 896/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0372 - accuracy: 0.9840\n",
      "Epoch 00896: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0426 - accuracy: 0.9832 - val_loss: 0.0523 - val_accuracy: 0.9783\n",
      "Epoch 897/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0285 - accuracy: 0.9880\n",
      "Epoch 00897: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0298 - accuracy: 0.9893 - val_loss: 0.0540 - val_accuracy: 0.9752\n",
      "Epoch 898/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0427 - accuracy: 0.9840\n",
      "Epoch 00898: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0474 - accuracy: 0.9832 - val_loss: 0.0518 - val_accuracy: 0.9783\n",
      "Epoch 899/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0315 - accuracy: 0.9900\n",
      "Epoch 00899: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0315 - accuracy: 0.9877 - val_loss: 0.0827 - val_accuracy: 0.9689\n",
      "Epoch 900/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0593 - accuracy: 0.9760\n",
      "Epoch 00900: val_loss did not improve from 0.05023\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0562 - accuracy: 0.9740 - val_loss: 0.0614 - val_accuracy: 0.9752\n",
      "Epoch 901/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0398 - accuracy: 0.9900\n",
      "Epoch 00901: val_loss improved from 0.05023 to 0.05023, saving model to ./model\\901-0.0502.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0385 - accuracy: 0.9893 - val_loss: 0.0502 - val_accuracy: 0.9783\n",
      "Epoch 902/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0389 - accuracy: 0.9900\n",
      "Epoch 00902: val_loss improved from 0.05023 to 0.04954, saving model to ./model\\902-0.0495.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0379 - accuracy: 0.9908 - val_loss: 0.0495 - val_accuracy: 0.9783\n",
      "Epoch 903/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0295 - accuracy: 0.9900\n",
      "Epoch 00903: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.9893 - val_loss: 0.0603 - val_accuracy: 0.9752\n",
      "Epoch 904/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0332 - accuracy: 0.9900\n",
      "Epoch 00904: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0360 - accuracy: 0.9908 - val_loss: 0.0584 - val_accuracy: 0.9752\n",
      "Epoch 905/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0382 - accuracy: 0.9900\n",
      "Epoch 00905: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0346 - accuracy: 0.9908 - val_loss: 0.0501 - val_accuracy: 0.9752\n",
      "Epoch 906/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0279 - accuracy: 0.9920\n",
      "Epoch 00906: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0304 - accuracy: 0.9923 - val_loss: 0.0497 - val_accuracy: 0.9814\n",
      "Epoch 907/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0307 - accuracy: 0.9940\n",
      "Epoch 00907: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0344 - accuracy: 0.9908 - val_loss: 0.0515 - val_accuracy: 0.9814\n",
      "Epoch 908/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0335 - accuracy: 0.9900\n",
      "Epoch 00908: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.9923 - val_loss: 0.0654 - val_accuracy: 0.9689\n",
      "Epoch 909/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0425 - accuracy: 0.9880\n",
      "Epoch 00909: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0378 - accuracy: 0.9893 - val_loss: 0.0625 - val_accuracy: 0.9720\n",
      "Epoch 910/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0287 - accuracy: 0.9940\n",
      "Epoch 00910: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0324 - accuracy: 0.9908 - val_loss: 0.0518 - val_accuracy: 0.9783\n",
      "Epoch 911/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0394 - accuracy: 0.9880\n",
      "Epoch 00911: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0337 - accuracy: 0.9908 - val_loss: 0.0559 - val_accuracy: 0.9752\n",
      "Epoch 912/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0393 - accuracy: 0.9900\n",
      "Epoch 00912: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0414 - accuracy: 0.9893 - val_loss: 0.0572 - val_accuracy: 0.9783\n",
      "Epoch 913/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0335 - accuracy: 0.9880\n",
      "Epoch 00913: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9877 - val_loss: 0.0779 - val_accuracy: 0.9689\n",
      "Epoch 914/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0513 - accuracy: 0.9800\n",
      "Epoch 00914: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0470 - accuracy: 0.9816 - val_loss: 0.0575 - val_accuracy: 0.9783\n",
      "Epoch 915/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0306 - accuracy: 0.9920\n",
      "Epoch 00915: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9893 - val_loss: 0.0514 - val_accuracy: 0.9814\n",
      "Epoch 916/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0372 - accuracy: 0.9880\n",
      "Epoch 00916: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0347 - accuracy: 0.9893 - val_loss: 0.0526 - val_accuracy: 0.9814\n",
      "Epoch 917/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0265 - accuracy: 0.9900\n",
      "Epoch 00917: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9893 - val_loss: 0.0575 - val_accuracy: 0.9783\n",
      "Epoch 918/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0253 - accuracy: 0.9920\n",
      "Epoch 00918: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0317 - accuracy: 0.9908 - val_loss: 0.0515 - val_accuracy: 0.9752\n",
      "Epoch 919/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0275 - accuracy: 0.9960\n",
      "Epoch 00919: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0302 - accuracy: 0.9954 - val_loss: 0.0518 - val_accuracy: 0.9783\n",
      "Epoch 920/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0386 - accuracy: 0.9900\n",
      "Epoch 00920: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0363 - accuracy: 0.9908 - val_loss: 0.0532 - val_accuracy: 0.9783\n",
      "Epoch 921/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0278 - accuracy: 0.9920\n",
      "Epoch 00921: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0330 - accuracy: 0.9893 - val_loss: 0.0629 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 922/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0404 - accuracy: 0.9860\n",
      "Epoch 00922: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 0.9877 - val_loss: 0.0542 - val_accuracy: 0.9783\n",
      "Epoch 923/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0278 - accuracy: 0.9920\n",
      "Epoch 00923: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 0.9923 - val_loss: 0.0517 - val_accuracy: 0.9783\n",
      "Epoch 924/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0335 - accuracy: 0.9860\n",
      "Epoch 00924: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0309 - accuracy: 0.9893 - val_loss: 0.0521 - val_accuracy: 0.9783\n",
      "Epoch 925/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0330 - accuracy: 0.9860\n",
      "Epoch 00925: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0302 - accuracy: 0.9893 - val_loss: 0.0556 - val_accuracy: 0.9783\n",
      "Epoch 926/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0317 - accuracy: 0.9900\n",
      "Epoch 00926: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0305 - accuracy: 0.9908 - val_loss: 0.0570 - val_accuracy: 0.9783\n",
      "Epoch 927/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0229 - accuracy: 0.9940\n",
      "Epoch 00927: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 0.9893 - val_loss: 0.0518 - val_accuracy: 0.9814\n",
      "Epoch 928/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0279 - accuracy: 0.9900\n",
      "Epoch 00928: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.9893 - val_loss: 0.0527 - val_accuracy: 0.9783\n",
      "Epoch 929/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0400 - accuracy: 0.9860\n",
      "Epoch 00929: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0365 - accuracy: 0.9877 - val_loss: 0.0554 - val_accuracy: 0.9783\n",
      "Epoch 930/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0329 - accuracy: 0.9880\n",
      "Epoch 00930: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0309 - accuracy: 0.9893 - val_loss: 0.0650 - val_accuracy: 0.9720\n",
      "Epoch 931/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0378 - accuracy: 0.9900\n",
      "Epoch 00931: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0352 - accuracy: 0.9893 - val_loss: 0.0539 - val_accuracy: 0.9783\n",
      "Epoch 932/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0317 - accuracy: 0.9900\n",
      "Epoch 00932: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0304 - accuracy: 0.9893 - val_loss: 0.0505 - val_accuracy: 0.9814\n",
      "Epoch 933/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0325 - accuracy: 0.9920\n",
      "Epoch 00933: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9908 - val_loss: 0.0521 - val_accuracy: 0.9783\n",
      "Epoch 934/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0250 - accuracy: 0.9940\n",
      "Epoch 00934: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0311 - accuracy: 0.9923 - val_loss: 0.0607 - val_accuracy: 0.9752\n",
      "Epoch 935/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0406 - accuracy: 0.9880\n",
      "Epoch 00935: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9908 - val_loss: 0.0536 - val_accuracy: 0.9783\n",
      "Epoch 936/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0329 - accuracy: 0.9900\n",
      "Epoch 00936: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0298 - accuracy: 0.9923 - val_loss: 0.0503 - val_accuracy: 0.9752\n",
      "Epoch 937/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0293 - accuracy: 0.9960\n",
      "Epoch 00937: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9923 - val_loss: 0.0503 - val_accuracy: 0.9752\n",
      "Epoch 938/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0250 - accuracy: 0.9940\n",
      "Epoch 00938: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 0.9923 - val_loss: 0.0517 - val_accuracy: 0.9783\n",
      "Epoch 939/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0223 - accuracy: 0.9940\n",
      "Epoch 00939: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 0.0503 - val_accuracy: 0.9814\n",
      "Epoch 940/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0291 - accuracy: 0.9900\n",
      "Epoch 00940: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0303 - accuracy: 0.9908 - val_loss: 0.0504 - val_accuracy: 0.9814\n",
      "Epoch 941/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0303 - accuracy: 0.9920\n",
      "Epoch 00941: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0310 - accuracy: 0.9923 - val_loss: 0.0533 - val_accuracy: 0.9783\n",
      "Epoch 942/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0319 - accuracy: 0.9900\n",
      "Epoch 00942: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0534 - val_accuracy: 0.9783\n",
      "Epoch 943/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0273 - accuracy: 0.9900\n",
      "Epoch 00943: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 0.0511 - val_accuracy: 0.9783\n",
      "Epoch 944/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0313 - accuracy: 0.9920\n",
      "Epoch 00944: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0296 - accuracy: 0.9923 - val_loss: 0.0506 - val_accuracy: 0.9783\n",
      "Epoch 945/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0324 - accuracy: 0.9940\n",
      "Epoch 00945: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 0.9939 - val_loss: 0.0529 - val_accuracy: 0.9783\n",
      "Epoch 946/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0261 - accuracy: 0.9960\n",
      "Epoch 00946: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 0.0560 - val_accuracy: 0.9783\n",
      "Epoch 947/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0338 - accuracy: 0.9880\n",
      "Epoch 00947: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.9908 - val_loss: 0.0520 - val_accuracy: 0.9814\n",
      "Epoch 948/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0259 - accuracy: 0.9940\n",
      "Epoch 00948: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9954 - val_loss: 0.0496 - val_accuracy: 0.9814\n",
      "Epoch 949/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0309 - accuracy: 0.9900\n",
      "Epoch 00949: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0298 - accuracy: 0.9923 - val_loss: 0.0504 - val_accuracy: 0.9814\n",
      "Epoch 950/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0320 - accuracy: 0.9940\n",
      "Epoch 00950: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0289 - accuracy: 0.9939 - val_loss: 0.0532 - val_accuracy: 0.9783\n",
      "Epoch 951/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0350 - accuracy: 0.9860\n",
      "Epoch 00951: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 0.9893 - val_loss: 0.0515 - val_accuracy: 0.9783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0338 - accuracy: 0.9860\n",
      "Epoch 00952: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.9893 - val_loss: 0.0496 - val_accuracy: 0.9783\n",
      "Epoch 953/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0320 - accuracy: 0.9920\n",
      "Epoch 00953: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.9923 - val_loss: 0.0505 - val_accuracy: 0.9783\n",
      "Epoch 954/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0330 - accuracy: 0.9920\n",
      "Epoch 00954: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0289 - accuracy: 0.9923 - val_loss: 0.0527 - val_accuracy: 0.9783\n",
      "Epoch 955/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0324 - accuracy: 0.9860\n",
      "Epoch 00955: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 0.0510 - val_accuracy: 0.9783\n",
      "Epoch 956/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0290 - accuracy: 0.9900\n",
      "Epoch 00956: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0503 - val_accuracy: 0.9783\n",
      "Epoch 957/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0313 - accuracy: 0.9920\n",
      "Epoch 00957: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0284 - accuracy: 0.9939 - val_loss: 0.0506 - val_accuracy: 0.9783\n",
      "Epoch 958/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0338 - accuracy: 0.9900\n",
      "Epoch 00958: val_loss did not improve from 0.04954\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0282 - accuracy: 0.9923 - val_loss: 0.0500 - val_accuracy: 0.9814\n",
      "Epoch 959/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0253 - accuracy: 0.9960\n",
      "Epoch 00959: val_loss improved from 0.04954 to 0.04916, saving model to ./model\\959-0.0492.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0287 - accuracy: 0.9939 - val_loss: 0.0492 - val_accuracy: 0.9845\n",
      "Epoch 960/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0255 - accuracy: 0.9940\n",
      "Epoch 00960: val_loss improved from 0.04916 to 0.04848, saving model to ./model\\960-0.0485.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0287 - accuracy: 0.9939 - val_loss: 0.0485 - val_accuracy: 0.9814\n",
      "Epoch 961/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0362 - accuracy: 0.9880\n",
      "Epoch 00961: val_loss improved from 0.04848 to 0.04846, saving model to ./model\\961-0.0485.hdf5\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0311 - accuracy: 0.9908 - val_loss: 0.0485 - val_accuracy: 0.9814\n",
      "Epoch 962/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0307 - accuracy: 0.9900\n",
      "Epoch 00962: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0297 - accuracy: 0.9923 - val_loss: 0.0506 - val_accuracy: 0.9783\n",
      "Epoch 963/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0277 - accuracy: 0.9940\n",
      "Epoch 00963: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9939 - val_loss: 0.0522 - val_accuracy: 0.9783\n",
      "Epoch 964/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0318 - accuracy: 0.9880\n",
      "Epoch 00964: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 0.0504 - val_accuracy: 0.9783\n",
      "Epoch 965/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0251 - accuracy: 0.9940\n",
      "Epoch 00965: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 0.0525 - val_accuracy: 0.9783\n",
      "Epoch 966/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0250 - accuracy: 0.9920\n",
      "Epoch 00966: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0302 - accuracy: 0.9908 - val_loss: 0.0549 - val_accuracy: 0.9783\n",
      "Epoch 967/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0248 - accuracy: 0.9920\n",
      "Epoch 00967: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 0.0494 - val_accuracy: 0.9814\n",
      "Epoch 968/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0278 - accuracy: 0.9940\n",
      "Epoch 00968: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0315 - accuracy: 0.9908 - val_loss: 0.0498 - val_accuracy: 0.9814\n",
      "Epoch 969/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0261 - accuracy: 0.9940\n",
      "Epoch 00969: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 0.0578 - val_accuracy: 0.9783\n",
      "Epoch 970/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0238 - accuracy: 0.9920\n",
      "Epoch 00970: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0311 - accuracy: 0.9908 - val_loss: 0.0531 - val_accuracy: 0.9783\n",
      "Epoch 971/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0285 - accuracy: 0.9920\n",
      "Epoch 00971: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0275 - accuracy: 0.9939 - val_loss: 0.0500 - val_accuracy: 0.9814\n",
      "Epoch 972/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0325 - accuracy: 0.9880\n",
      "Epoch 00972: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 0.9908 - val_loss: 0.0499 - val_accuracy: 0.9814\n",
      "Epoch 973/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0331 - accuracy: 0.9900\n",
      "Epoch 00973: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 0.9923 - val_loss: 0.0549 - val_accuracy: 0.9783\n",
      "Epoch 974/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0304 - accuracy: 0.9900\n",
      "Epoch 00974: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.0592 - val_accuracy: 0.9783\n",
      "Epoch 975/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0308 - accuracy: 0.9900\n",
      "Epoch 00975: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0313 - accuracy: 0.9908 - val_loss: 0.0522 - val_accuracy: 0.9814\n",
      "Epoch 976/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0280 - accuracy: 0.9940\n",
      "Epoch 00976: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 0.9954 - val_loss: 0.0501 - val_accuracy: 0.9814\n",
      "Epoch 977/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0267 - accuracy: 0.9960\n",
      "Epoch 00977: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9908 - val_loss: 0.0529 - val_accuracy: 0.9814\n",
      "Epoch 978/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0248 - accuracy: 0.9920\n",
      "Epoch 00978: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.9908 - val_loss: 0.0568 - val_accuracy: 0.9783\n",
      "Epoch 979/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0335 - accuracy: 0.9900\n",
      "Epoch 00979: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 0.0503 - val_accuracy: 0.9845\n",
      "Epoch 980/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0292 - accuracy: 0.9980\n",
      "Epoch 00980: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0293 - accuracy: 0.9954 - val_loss: 0.0504 - val_accuracy: 0.9814\n",
      "Epoch 981/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0313 - accuracy: 0.9960\n",
      "Epoch 00981: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0280 - accuracy: 0.9954 - val_loss: 0.0552 - val_accuracy: 0.9783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 982/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0294 - accuracy: 0.9920\n",
      "Epoch 00982: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.0524 - val_accuracy: 0.9783\n",
      "Epoch 983/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0266 - accuracy: 0.9940\n",
      "Epoch 00983: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9939 - val_loss: 0.0500 - val_accuracy: 0.9814\n",
      "Epoch 984/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0255 - accuracy: 0.9940\n",
      "Epoch 00984: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0287 - accuracy: 0.9923 - val_loss: 0.0533 - val_accuracy: 0.9783\n",
      "Epoch 985/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0232 - accuracy: 0.9920\n",
      "Epoch 00985: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9923 - val_loss: 0.0605 - val_accuracy: 0.9752\n",
      "Epoch 986/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0301 - accuracy: 0.9900\n",
      "Epoch 00986: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0321 - accuracy: 0.9908 - val_loss: 0.0520 - val_accuracy: 0.9814\n",
      "Epoch 987/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0281 - accuracy: 0.9940\n",
      "Epoch 00987: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0286 - accuracy: 0.9923 - val_loss: 0.0500 - val_accuracy: 0.9814\n",
      "Epoch 988/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0226 - accuracy: 0.9960\n",
      "Epoch 00988: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0286 - accuracy: 0.9954 - val_loss: 0.0529 - val_accuracy: 0.9814\n",
      "Epoch 989/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0321 - accuracy: 0.9920\n",
      "Epoch 00989: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0275 - accuracy: 0.9923 - val_loss: 0.0553 - val_accuracy: 0.9783\n",
      "Epoch 990/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0288 - accuracy: 0.9900\n",
      "Epoch 00990: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.9908 - val_loss: 0.0522 - val_accuracy: 0.9814\n",
      "Epoch 991/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0269 - accuracy: 0.9920\n",
      "Epoch 00991: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9939 - val_loss: 0.0516 - val_accuracy: 0.9814\n",
      "Epoch 992/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0289 - accuracy: 0.9960\n",
      "Epoch 00992: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0271 - accuracy: 0.9954 - val_loss: 0.0531 - val_accuracy: 0.9783\n",
      "Epoch 993/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0289 - accuracy: 0.9900\n",
      "Epoch 00993: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0273 - accuracy: 0.9908 - val_loss: 0.0524 - val_accuracy: 0.9783\n",
      "Epoch 994/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0328 - accuracy: 0.9900\n",
      "Epoch 00994: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 0.0518 - val_accuracy: 0.9783\n",
      "Epoch 995/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0313 - accuracy: 0.9960\n",
      "Epoch 00995: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0272 - accuracy: 0.9969 - val_loss: 0.0518 - val_accuracy: 0.9783\n",
      "Epoch 996/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0254 - accuracy: 0.9980\n",
      "Epoch 00996: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0275 - accuracy: 0.9954 - val_loss: 0.0510 - val_accuracy: 0.9783\n",
      "Epoch 997/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0293 - accuracy: 0.9940\n",
      "Epoch 00997: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 0.9939 - val_loss: 0.0507 - val_accuracy: 0.9814\n",
      "Epoch 998/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0282 - accuracy: 0.9940\n",
      "Epoch 00998: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.9954 - val_loss: 0.0539 - val_accuracy: 0.9783\n",
      "Epoch 999/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0259 - accuracy: 0.9920\n",
      "Epoch 00999: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0278 - accuracy: 0.9893 - val_loss: 0.0525 - val_accuracy: 0.9783\n",
      "Epoch 1000/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0244 - accuracy: 0.9960\n",
      "Epoch 01000: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9954 - val_loss: 0.0497 - val_accuracy: 0.9814\n",
      "Epoch 1001/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0304 - accuracy: 0.9900\n",
      "Epoch 01001: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 0.0499 - val_accuracy: 0.9814\n",
      "Epoch 1002/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0309 - accuracy: 0.9900\n",
      "Epoch 01002: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9923 - val_loss: 0.0542 - val_accuracy: 0.9783\n",
      "Epoch 1003/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0231 - accuracy: 0.9920\n",
      "Epoch 01003: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 0.0536 - val_accuracy: 0.9814\n",
      "Epoch 1004/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0319 - accuracy: 0.9920\n",
      "Epoch 01004: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9939 - val_loss: 0.0508 - val_accuracy: 0.9814\n",
      "Epoch 1005/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0282 - accuracy: 0.9920\n",
      "Epoch 01005: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 0.0509 - val_accuracy: 0.9814\n",
      "Epoch 1006/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0201 - accuracy: 0.9980\n",
      "Epoch 01006: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0274 - accuracy: 0.9939 - val_loss: 0.0519 - val_accuracy: 0.9814\n",
      "Epoch 1007/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0223 - accuracy: 0.9980\n",
      "Epoch 01007: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9954 - val_loss: 0.0556 - val_accuracy: 0.9783\n",
      "Epoch 1008/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0304 - accuracy: 0.9900\n",
      "Epoch 01008: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9893 - val_loss: 0.0524 - val_accuracy: 0.9783\n",
      "Epoch 1009/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0288 - accuracy: 0.9920\n",
      "Epoch 01009: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0268 - accuracy: 0.9923 - val_loss: 0.0502 - val_accuracy: 0.9814\n",
      "Epoch 1010/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0292 - accuracy: 0.9880\n",
      "Epoch 01010: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 0.0510 - val_accuracy: 0.9783\n",
      "Epoch 1011/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0295 - accuracy: 0.9940\n",
      "Epoch 01011: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0267 - accuracy: 0.9939 - val_loss: 0.0560 - val_accuracy: 0.9783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1012/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0314 - accuracy: 0.9880\n",
      "Epoch 01012: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.9893 - val_loss: 0.0554 - val_accuracy: 0.9783\n",
      "Epoch 1013/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0306 - accuracy: 0.9880\n",
      "Epoch 01013: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 0.0514 - val_accuracy: 0.9814\n",
      "Epoch 1014/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0292 - accuracy: 0.9940\n",
      "Epoch 01014: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0272 - accuracy: 0.9939 - val_loss: 0.0522 - val_accuracy: 0.9814\n",
      "Epoch 1015/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0324 - accuracy: 0.9960\n",
      "Epoch 01015: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9969 - val_loss: 0.0570 - val_accuracy: 0.9783\n",
      "Epoch 1016/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0220 - accuracy: 0.9920\n",
      "Epoch 01016: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0285 - accuracy: 0.9908 - val_loss: 0.0536 - val_accuracy: 0.9814\n",
      "Epoch 1017/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0293 - accuracy: 0.9900\n",
      "Epoch 01017: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.9908 - val_loss: 0.0508 - val_accuracy: 0.9814\n",
      "Epoch 1018/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0304 - accuracy: 0.9920\n",
      "Epoch 01018: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0275 - accuracy: 0.9923 - val_loss: 0.0519 - val_accuracy: 0.9814\n",
      "Epoch 1019/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0283 - accuracy: 0.9960\n",
      "Epoch 01019: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9954 - val_loss: 0.0516 - val_accuracy: 0.9814\n",
      "Epoch 1020/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0289 - accuracy: 0.9940\n",
      "Epoch 01020: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 0.9954 - val_loss: 0.0507 - val_accuracy: 0.9814\n",
      "Epoch 1021/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0299 - accuracy: 0.9960\n",
      "Epoch 01021: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 0.9969 - val_loss: 0.0505 - val_accuracy: 0.9845\n",
      "Epoch 1022/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0256 - accuracy: 0.9960\n",
      "Epoch 01022: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0263 - accuracy: 0.9969 - val_loss: 0.0503 - val_accuracy: 0.9845\n",
      "Epoch 1023/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0283 - accuracy: 0.9940\n",
      "Epoch 01023: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9939 - val_loss: 0.0507 - val_accuracy: 0.9845\n",
      "Epoch 1024/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0217 - accuracy: 0.9980\n",
      "Epoch 01024: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 0.9954 - val_loss: 0.0539 - val_accuracy: 0.9783\n",
      "Epoch 1025/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0282 - accuracy: 0.9880\n",
      "Epoch 01025: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9908 - val_loss: 0.0538 - val_accuracy: 0.9783\n",
      "Epoch 1026/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0268 - accuracy: 0.9920\n",
      "Epoch 01026: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0264 - accuracy: 0.9939 - val_loss: 0.0512 - val_accuracy: 0.9845\n",
      "Epoch 1027/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0269 - accuracy: 0.9940\n",
      "Epoch 01027: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0267 - accuracy: 0.9939 - val_loss: 0.0517 - val_accuracy: 0.9845\n",
      "Epoch 1028/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0230 - accuracy: 0.9960\n",
      "Epoch 01028: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 0.9954 - val_loss: 0.0547 - val_accuracy: 0.9783\n",
      "Epoch 1029/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0182 - accuracy: 0.9940\n",
      "Epoch 01029: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0272 - accuracy: 0.9893 - val_loss: 0.0509 - val_accuracy: 0.9845\n",
      "Epoch 1030/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0251 - accuracy: 0.9940\n",
      "Epoch 01030: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0281 - accuracy: 0.9923 - val_loss: 0.0502 - val_accuracy: 0.9814\n",
      "Epoch 1031/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0320 - accuracy: 0.9880\n",
      "Epoch 01031: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.9908 - val_loss: 0.0539 - val_accuracy: 0.9783\n",
      "Epoch 1032/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0296 - accuracy: 0.9900\n",
      "Epoch 01032: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0269 - accuracy: 0.9908 - val_loss: 0.0547 - val_accuracy: 0.9814\n",
      "Epoch 1033/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0231 - accuracy: 0.9920\n",
      "Epoch 01033: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0271 - accuracy: 0.9893 - val_loss: 0.0504 - val_accuracy: 0.9845\n",
      "Epoch 1034/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0227 - accuracy: 0.9980\n",
      "Epoch 01034: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0260 - accuracy: 0.9969 - val_loss: 0.0490 - val_accuracy: 0.9814\n",
      "Epoch 1035/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0282 - accuracy: 0.9880\n",
      "Epoch 01035: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9893 - val_loss: 0.0495 - val_accuracy: 0.9845\n",
      "Epoch 1036/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0231 - accuracy: 0.9960\n",
      "Epoch 01036: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0260 - accuracy: 0.9954 - val_loss: 0.0584 - val_accuracy: 0.9783\n",
      "Epoch 1037/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0361 - accuracy: 0.9880\n",
      "Epoch 01037: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.0552 - val_accuracy: 0.9783\n",
      "Epoch 1038/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0233 - accuracy: 0.9900\n",
      "Epoch 01038: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 0.9893 - val_loss: 0.0499 - val_accuracy: 0.9783\n",
      "Epoch 1039/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0236 - accuracy: 0.9960\n",
      "Epoch 01039: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 0.9923 - val_loss: 0.0500 - val_accuracy: 0.9783\n",
      "Epoch 1040/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0269 - accuracy: 0.9940\n",
      "Epoch 01040: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0267 - accuracy: 0.9908 - val_loss: 0.0559 - val_accuracy: 0.9783\n",
      "Epoch 1041/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0279 - accuracy: 0.9900\n",
      "Epoch 01041: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.0574 - val_accuracy: 0.9783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1042/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0298 - accuracy: 0.9920\n",
      "Epoch 01042: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0281 - accuracy: 0.9923 - val_loss: 0.0503 - val_accuracy: 0.9814\n",
      "Epoch 1043/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0198 - accuracy: 0.9980\n",
      "Epoch 01043: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 0.0500 - val_accuracy: 0.9814\n",
      "Epoch 1044/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0240 - accuracy: 0.9940\n",
      "Epoch 01044: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 0.9923 - val_loss: 0.0547 - val_accuracy: 0.9814\n",
      "Epoch 1045/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0266 - accuracy: 0.9920\n",
      "Epoch 01045: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0278 - accuracy: 0.9893 - val_loss: 0.0527 - val_accuracy: 0.9814\n",
      "Epoch 1046/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0320 - accuracy: 0.9940\n",
      "Epoch 01046: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9954 - val_loss: 0.0491 - val_accuracy: 0.9814\n",
      "Epoch 1047/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0252 - accuracy: 0.9940\n",
      "Epoch 01047: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0268 - accuracy: 0.9939 - val_loss: 0.0498 - val_accuracy: 0.9845\n",
      "Epoch 1048/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0257 - accuracy: 0.9960\n",
      "Epoch 01048: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9969 - val_loss: 0.0525 - val_accuracy: 0.9783\n",
      "Epoch 1049/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0289 - accuracy: 0.9920\n",
      "Epoch 01049: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9923 - val_loss: 0.0522 - val_accuracy: 0.9814\n",
      "Epoch 1050/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0273 - accuracy: 0.9940\n",
      "Epoch 01050: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 0.9954 - val_loss: 0.0501 - val_accuracy: 0.9814\n",
      "Epoch 1051/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0234 - accuracy: 0.9980\n",
      "Epoch 01051: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0267 - accuracy: 0.9954 - val_loss: 0.0519 - val_accuracy: 0.9814\n",
      "Epoch 1052/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0290 - accuracy: 0.9940\n",
      "Epoch 01052: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0258 - accuracy: 0.9939 - val_loss: 0.0572 - val_accuracy: 0.9814\n",
      "Epoch 1053/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0256 - accuracy: 0.9900\n",
      "Epoch 01053: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.0524 - val_accuracy: 0.9814\n",
      "Epoch 1054/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0200 - accuracy: 0.9960\n",
      "Epoch 01054: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0267 - accuracy: 0.9908 - val_loss: 0.0495 - val_accuracy: 0.9814\n",
      "Epoch 1055/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0298 - accuracy: 0.9900\n",
      "Epoch 01055: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0269 - accuracy: 0.9923 - val_loss: 0.0503 - val_accuracy: 0.9845\n",
      "Epoch 1056/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0264 - accuracy: 0.9960\n",
      "Epoch 01056: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0256 - accuracy: 0.9954 - val_loss: 0.0498 - val_accuracy: 0.9845\n",
      "Epoch 1057/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 01057: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0256 - accuracy: 0.9969 - val_loss: 0.0489 - val_accuracy: 0.9814\n",
      "Epoch 1058/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0298 - accuracy: 0.9960\n",
      "Epoch 01058: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0259 - accuracy: 0.9969 - val_loss: 0.0492 - val_accuracy: 0.9845\n",
      "Epoch 1059/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0222 - accuracy: 0.9980\n",
      "Epoch 01059: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 0.9969 - val_loss: 0.0529 - val_accuracy: 0.9814\n",
      "Epoch 1060/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0300 - accuracy: 0.9860\n",
      "Epoch 01060: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0264 - accuracy: 0.9893 - val_loss: 0.0550 - val_accuracy: 0.9814\n",
      "Epoch 1061/3500\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0272 - accuracy: 0.9900\n",
      "Epoch 01061: val_loss did not improve from 0.04846\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0274 - accuracy: 0.9893 - val_loss: 0.0539 - val_accuracy: 0.9814\n",
      "31/31 [==============================] - 0s 644us/step - loss: 0.0354 - accuracy: 0.9867\n",
      "Accuracy:0.9866666793823242\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping   #과적합 멈추게 함\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint  #모델 계속 모니터링 및 저장\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "df_pre=pd.read_csv('C:/Users/user/machine_learning1/wine.csv',header=None)\n",
    "df=df_pre.sample(frac=0.15) #전체 샘플 중 15%정도 읽음\n",
    "dataset=df.values\n",
    "X=dataset[:,0:12]\n",
    "Y=dataset[:,12]\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(30,input_dim=12,activation='relu'))\n",
    "model.add(Dense(12,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#모델 저장 폴더 만들기\n",
    "import os\n",
    "MODEL_DIR='./model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "modelpath='./model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "#모델 업데이트 및 저장\n",
    "checkpointer=ModelCheckpoint(filepath=modelpath,monitor='val_loss',verbose=1,save_best_only=True) #성능 좋아질때만 저장됨\n",
    "\n",
    "#학습 자동중단 설정\n",
    "early_stopping_callback=EarlyStopping(monitor='val_loss',patience=100) #patience=100 : 100개의 데이터까지 개선이 없으면 멈춰라\n",
    "\n",
    "#모델 실행\n",
    "hist=model.fit(X,Y,validation_split=0.33,epochs=3500,batch_size=500,\n",
    "         callbacks=[early_stopping_callback,checkpointer])\n",
    "\n",
    "print('Accuracy:{}'.format(model.evaluate(X,Y)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAejklEQVR4nO3dfZBc1X3m8e9vel6QhGDQSyysF6SAICiLETARDGvwBHl5MzFySGUxaGWncAY5NgW7DhJOyuXapBYQhTcsMRgmgIMWDHFZlCNsMKS0HstYTZAA8R6BAL0MQkhIwgiBNNLM2T9+fd09Pd0zPaOe6b63n0/VVPe9fbvnnNboueeec+69FkJARETir67SBRARkfJQoIuIJIQCXUQkIRToIiIJoUAXEUmI+kr94kmTJoWZM2dW6teLiMTSs88++34IYXKh1yoW6DNnzmTdunWV+vUiIrFkZpuLvaYuFxGRhFCgi4gkhAJdRCQhFOgiIgkxaKCb2X1mtsPMXi7yupnZ7Wa20cxeNLPTy19MEREZTCkt9H8GLhzg9YuA2ZmfduAHh18sEREZqkGnLYYQVpvZzAE2uRRYHvyyjU+bWbOZHRtCeLdMZRQRqah0Gjo7oa0NWlv7rl++HLZvhylTYNEiX5+7be57f/pTeOQR+NM/hWXLyl/OcsxDnwpszVnuyqxToIskTEcH3HsvfPrTsGRJNtyi0Jo4EXbt6ht8Qw098O0hu23ucqFALbYtwA03wGuvQXMz1NdDUxPs2QN798LBgzBuHJx1Flx0ETz+OGzb5ts+9xwcOAA9PfDxx9nfOX68PzY0wO7dfb+fu+4CMwjBHydNgp07+3+Pt9zij+UOdSvleuiZFvrPQgj/qcBrPwduCiE8lVleBSwJITxbYNt2vFuGGTNmnLF5c9H58SI1p1ArsNC6KFSPOALmzIGjjoJHH4X33ssG1IknwoQJsGkTbNjg68eM8df27YNPPoG6Og+3nh4PoPr67M8HH/g6yD729mafR1Ip/+nu7l+furrs+wYydmzfwBxMKgWNjR6YQ3lftZk6Fbq6hv4+M3s2hNBS6LVytNC7gOk5y9OAbYU2DCF0AB0ALS0turOGxFIUsh98AOvXw9y58PrrHpyTJ3uQ7t4Nmzd76DQ3w5Yt8OGH/QMxEkLf4Kuv9wDeuze77uij4aOPPIAjq1f3/6y9e701XGh97udB4SAeip6evuXJNViQR4Yayj09vkOKu+3b/W8p94jjcJUj0FcC3zSzh4Ezgd+q/1yqRbFWb9QFsGkTvPMOnHwyTJ/u25p5WAOccIK3gDdv9sPvffv6h+KTT2afv/Zaecp96FD/3/Pb35bns6U69Pb639uoBrqZPQS0AZPMrAv4LtAAEEK4C3gMuBjYCHwM/EX5iidJlR+0xfpg02nvb9ywAU46ybsSOju9u2HChL59slFIR63jAwdgx45sq/jII/v3h0YK9XOCt8BFRkJjY3bMoFxK6kMfCS0tLUEX54q//MGs3JDu6IDbbvPD4+ZmD9imJg/d3C6B2bPhzTf7H6KnUsUP52Xk1dX5T25EpFK+Yzx40HeMhf596jPNxOh9Zh5e0b9nNNA4mKYmP1LJ3baurnBXTn29bxtpbMxud9RRMGOGD4QeOODrjjjC10XdYy+/7N1ZTU0+2BkCHHccRBeEnTIFTjstO2g6e7YPmu7Z459xySX+N/7KK/DEE/67Gxv998yd6wOuzz+f/buPGiLDaZ2PdB+61Kh0GubP937YaGS/t9f/4553Xt+uiIG88Ubh9UkM87o6/64KMfPv7uDB0vqfx4/PDmgefXTfgdBNm/y1MWPgq1+FBQv6HuksWQIvvQQrVnjgfPhh9uhm/3646ipobx+8DIVmsJQSUtH7/umfsv/OTU1w++2FZ8nkH81ddx2sXet1T6Xg7/7OXy80tbCcSvlOKkktdClZ7n9e8JbKunWlD34lSUODB0lTkwdgY6PPIOnu9kBuaPCWYUOD98effDLcfHPpQVNoJks0ANvcPLKhNZrypx2WWqfcxkRjI6xalYzvoxQDtdAV6PI7xVpbHR1w443eL50U0SySMWP8sHrDBg+H/fuzrb758/2wurfXA7W52cOj1NarjKxiJ/sknQJdisoN8Z//3FuXuYr1WVa78eP7zxKZPRtmzYLLLiseyLUaEhIf6kOXft0l4P2sg83iqFSYm8H113vfb+7sl9zHa67Jdm/84z/6oBNkjyyWLoVbb/V1TU1w//2Dh3Rrq4Jc4kuBXkaF+gOH0uLL7/I47bRsSJ12mgdZdDILwFtvwZlnwh/+of+Op57KDpKZ+fNoEC4a3a8mDQ3ZMl5yCaxc6TsQM7j66uxp0cW+t1NOGfi7XbYsu0NQi1tqgbpcShDNhV69uvjZfvln+kF25kdkwoRsl0Z3d99pVoXenxQzZ/oUsdzBvcsu6xvIULuDXCJDoS6XIhYuhJ/8xMO0qal/yMLhBW1+8OdfyCcuivWj19XBF7/oszseeig7ZfFb3/IdHww+cyH3tVWr1JoWORw1E+jRSS5dXX6iS35wH+41LeKuvt4DurExe7p77nzk3O6kqPsnN3i/8Y3DD2P1X4scnkR3uSxdCnfc4We0VaiaVaWpyQM70tDgffXXXqtpeCJxUTNdLh0dfubbZZf5Y6lnKg5VsbP9zDwkzbzFH3XXFNuZmGUvMRot554ifehQ9jTq6Igilcpe4nTcOB8k7e72S5B+4Qs+QJp7PRRQN4ZIrUhMoHd0+MwIOLwgzw/ZaN0RR8Dppw/tbL/I0qXw4INw/PF+If1oUHC0WsUKcpHakJgul4kThzbomEr5ySft7R60UcteXQ8iUs0S3+WycOHgYd7Y6NMGzzqr762zIgpyEYm7RAT6ihUDv3733QpsEUm+usE3qW5nnunT64o57jiFuYjUhlgH+tKl8MwzA2/zN38zOmUREam0WHe53Hln/3VXXun3fdy2TZc5FZHaEttAX7jQbxmVa9o0eOCBypRHRKTSYtnlkk7Dj37Uf/2Pfzz6ZRERqRaxDPTOzv5nX155pU6gEZHaFstAnzix7/L556urRUQkloG+a1f29Py6uuw1S0REalksA72tza8cGN11XYEuIhLTWS6trX5t8+j6K+o7FxGJaaCn03DddX7Z2F//2m9lplAXkVoXyy6Xzk4P854ef+zsrHSJREQqL5aB3taWvRFEY6P60EVEIKZdLq2tuqGwiEi+WAY66IbCIiL5YtnlIiIi/SnQRUQSIraBnk7DTTf5o4iIlNiHbmYXAv8HSAH3hBBuznv9aOABYEbmM28NIfywzGX9nXQa5s/3KYuNjT5Aqv50Eal1g7bQzSwF3AFcBMwBvmxmc/I2+wbwagjhVKAN+J6ZNZa5rL+jeegiIv2V0uUyD9gYQngrhNANPAxcmrdNAMabmQFHAruBQ2UtaQ7NQxcR6a+ULpepwNac5S7gzLxtvg+sBLYB44H/GkLozf8gM2sH2gFmzJgxnPICmocuIlJIKYFuBdbl3V6CC4D1wHnA8cC/mdmvQwgf9nlTCB1AB0BLS0v+ZwyJ5qGLiPRVSpdLFzA9Z3ka3hLP9RfAI8FtBN4G/qA8RRQRkVKUEuhrgdlmNisz0Hk53r2SawswH8DMPgWcBLxVzoKKiMjABg30EMIh4JvAE8BrwI9DCK+Y2WIzW5zZ7O+Bs83sJWAVsDSE8P5IFbqjAy64wB9FRMSVNA89hPAY8Fjeurtynm8Dzi9v0Qrr6ICrr/bnTz7pj+3to/GbRUSqW+zOFF2xYuBlEZFaFbtAnzy57/LcuZUph4hItYlVoKfT8C//0nddc3NlyiIiUm1iFeidndCbc7pSQ4POEhURicQq0NvaoKkJ6uqgvh6+/32dXCQiEonVHYt0yr+ISHGxCnTQKf8iIsXEqstFRESKU6CLiCSEAl1EJCEU6CIiCaFAFxFJCAW6iEhCKNBFRBJCgS4ikhAKdBGRhFCgi4gkhAJdRCQhFOgiIgmhQBcRSQgFuohIQijQRUQSQoEuIpIQCnQRkYRQoIuIJIQCXUQkIRToIiIJoUAXEUkIBbqISEIo0EVEEkKBLiKSEAp0EZGEUKCLiCRESYFuZhea2QYz22hmNxTZps3M1pvZK2b2q/IWU0REBlM/2AZmlgLuAP4L0AWsNbOVIYRXc7ZpBu4ELgwhbDGz3xupAouISGGltNDnARtDCG+FELqBh4FL87a5AngkhLAFIISwo7zFFBGRwZQS6FOBrTnLXZl1uU4EjjGzTjN71swWFfogM2s3s3Vmtm7nzp3DK7GIiBRUSqBbgXUhb7keOAP4AnAB8B0zO7Hfm0LoCCG0hBBaJk+ePOTCiohIcYP2oeMt8uk5y9OAbQW2eT+EsA/YZ2argVOB18tSShERGVQpLfS1wGwzm2VmjcDlwMq8bf4VOMfM6s1sLHAm8Fp5iyoiIgMZtIUeQjhkZt8EngBSwH0hhFfMbHHm9btCCK+Z2S+AF4Fe4J4QwssjUuJ0Gjo7oa0NWltH5FeIiMSRhZDfHT46Wlpawrp164b2pnQa5s+H7m5obIRVqxTqIlJTzOzZEEJLodfidaZoZ6eHeU+PP3Z2VrpEIiJVI16B3tbmLfNUyh/b2ipdIhGRqlHKLJfq0drq3SzqQxcR6SdegQ4e4gpyEZF+4tXlIiIiRSnQRUQSQoEuIpIQCnQRkYRQoIuIJIQCXUQkIRToIiIJoUAXEUkIBbqISEIo0EVEEkKBLiKSEAp0EZGEUKCLiCSEAl1EJCEU6CIiCaFAFxFJCAW6iEhCKNBFRBJCgS4ikhAKdBGRhFCgi4gkhAJdRCQhFOgiIgmhQBcRSQgFuohIQijQRUQSQoEuIpIQ8Qz0dBpuuskfRUQEKDHQzexCM9tgZhvN7IYBtvsjM+sxsz8rXxHzpNMwfz585zv+qFAXEQFKCHQzSwF3ABcBc4Avm9mcItstA54odyH76OyE7m7o6fHHzs4R/XUiInFRSgt9HrAxhPBWCKEbeBi4tMB21wArgB1lLF9/bW3Q2AiplD+2tY3orxMRiYv6EraZCmzNWe4CzszdwMymAl8CzgP+qGylK6S1FVat8pZ5W5svi4hISYFuBdaFvOXbgKUhhB6zQptnPsisHWgHmDFjRqll7K+1VUEuIpKnlEDvAqbnLE8DtuVt0wI8nAnzScDFZnYohPDT3I1CCB1AB0BLS0v+TkFERA5DKYG+FphtZrOAd4DLgStyNwghzIqem9k/Az/LD3MRERlZgwZ6COGQmX0Tn72SAu4LIbxiZoszr981wmUUEZESlNJCJ4TwGPBY3rqCQR5C+OrhF0tERIYqnmeKiohIPwp0EZGEUKCLiCSEAl1EJCEU6CIiCRHfQNcldEVE+ihp2mLViS6h293tF+hatUqXAhCRmhfPFvry5bB/vy6hKyKSI36Bnk7DvfdCyFwKpq5Ol9AVESGOgb58ORw8mF3u6alcWUREqkj8Aj1fCOpyEREhjoG+aBHU54zl6q5FIiJAHGe5tLbC6tVwyy2wbRtcdZVmuIiIEMdAjzzxhM9weeklOOUUhbqI1Lz4dbmA95l3d2vaoohIjngGelsbpFJg5o/qQxcRiWmgg4d5CN5C//rXdQkAEal58Qz0zk44cCC7/MILcM45CnURqWnxDPS2Nm+h5+rp8ZOORERqVDwDvbUVrrii//rt20e/LCIiVSKegQ7wwANwwgl91+3eXZmyiIhUgfgGOsDnP993+amn1I8uIjUr3oG+aJFfbTHS2wt/8icKdRGpSfEO9NZW+Oxn+67btcvXKdRFpMbEO9AB5szpv663F77yldEvi4hIBcU/0Bct6j+FEeCNN+DMM0e/PCIiFRL/QG9thd/8BiZO7P/aM8/AwoWjXyYRkQqIf6CDh/qjjxZuqT/4oEJdRGpCMgIdsi31o47q/5pCXURqQHICHTzUf/GLwq8p1EUk4ZIV6OChvmRJ4dcefBAuuGB0yyMiMkqSF+gAy5YVD/Unn1Soi0giJTPQQaEuIjWnpEA3swvNbIOZbTSzGwq8fqWZvZj5WWNmp5a/qMMwWKgffTR0dIxumURERsiggW5mKeAO4CJgDvBlM8s/PfNt4HMhhM8Afw9UT0ouWwZ33134tQ8/hKuvhunTdakAEYm9Ulro84CNIYS3QgjdwMPApbkbhBDWhBD2ZBafBqaVt5iHqb29eKgDdHXB2WdDfT2MHw8nnuhnmar1LiIxUkqgTwW25ix3ZdYVcxXweKEXzKzdzNaZ2bqdO3eWXspyGCzUwe969NFHftmAZ57x1ntdHYwdC5/7nFrxIlLVSgn0AqdfEgpuaPbHeKAvLfR6CKEjhNASQmiZPHly6aUsl/Z2WLMG5s4t/T0hwCefwOrV3opvaPD3K9xFpMqUEuhdwPSc5WnAtvyNzOwzwD3ApSGEXeUp3ghobYXnn/dgnzaMnqFDh/ym1GefDamUd9M0NfkZqp/6FCwtuC8TERlxpQT6WmC2mc0ys0bgcmBl7gZmNgN4BPhvIYTXy1/MEdDaClu3ejfMlCkezkPV2+vdNN3dsHcv7NgBt9zi15Spr8921Sxd6tMk1ScvIiPIQijYe9J3I7OLgduAFHBfCOF/mdligBDCXWZ2D3AZsDnzlkMhhJaBPrOlpSWsW7fusApfdum0B/Lzz3tA79sHBw6U93c0NsJZZ8HNN/tOJdLRAStWwGWXedeQiEgBZvZssXwtKdBHQlUGejFLl3pLfu9eb5WXS309jBvX/3MXLPCZNuvXK+BFpA8Fejl1dMB3vwvvv+8Dpr29/jiSxo3zkH/ggZH9PSJS9QYK9OSe+j9S2tvh3Xfh4EEfIO3t9db7+efDvHk+QDqc/viB7NvnFxabORNmz/Y58rNnZwdgOzrURy8iaqGPqKirprvbu1c+/tgHUcuprq5vd82SJX52rIgkklrolbJsGXzwgQf5hx96i37JEr+GTF2Zvvr8Pv1bblFLXaRGKdBHWxTyPT3Zrpq77x76CU8DufpqPwFq1iyFu0gNUZdLtYmmTm7Y4C36nTt9B3A45s3zQdW2tr5TJUUkdjTLJe6imTV798KkSf44fjxs2TL0GTbnntt/DryIxIYCPckWLoSVK70vfd++0t5TVwdPPaVQF4khDYom2QMP+IDrRx9lL2Mw2IBrb2/2csFjxvhOIZ2GL31Jlw0WiTG10JOqowP++q+9e2Y4xo/3G39ce63OVBWpImqh16L2dm+5L1niZ5oO1d698OqrPmMmOmlpoJOX0mm46SZdVlikgtRCrxXpNPz5n/vdmQ5Xc7Nfa+aqq3zHsXQp3HqrD9AecQSsWuXbdXZqZo1ImWlQVLKWLoU77oD9+8t/1mrk3HPhN7/xvvqGBg92hbpIWSjQpbgo4A8c8Ev7fvxx+X9Hc7O35JubvcUOHvITJ8KuXX3XlbtFn07rSEESRYEupcu9JvzmzYNvXw51dX5Bs+iIYcYMP2t2yZKBQ3igsI7q8eij3hXU1ORdQQp1iTkFugxPOg033ABr13rY1tV5V81oMYPrr/eWfW5rvrXVy9bW5le9TKXga1+D007zbSZOhGuu8Yui5X7W1VfDD34weuUXGQEKdCmfjg647TZ47z0/kenQIQ9Us/Lf3akQMzjnHD9LdtOmob23oQF+9Su10iXWFOgyOvIvFzzcOfAj6Zhj/D6vUXdObrcNwPLlsH17dvspU2DRIu0Eqk0Nj40o0KUyon7sp5+GPXtGpwU/FFOn+s1KBrutYFMT/PKX2eAYrO8+/7XhhE/SAyud9p0nDH2HmU7D/PnecGhsrLlpsgp0qQ5RSE2cCI8/nr2i5ObNffu7q9GECfDJJ9k7VUUmTfJuoOZmr8PWrdkdxLnn+g3Bv/e9gadw5n4v0RjAddf5DrCuzmchnXJK/5lB1RBc+WUvpVzR+Ef0b55KwZ13+kyo/B1ZoR3b17/uR4Ih+Hv/8i/h/vv7Bnw1fDcjZKBAJ4RQkZ8zzjgjiPzO3XeHMG9eCOeeG8KCBSHMnRvCkUeGUF8fgv/XTcbPlCnZ+k2e7I9NTX23SaX6v8+s7/NUyr+rxYtDWLPGv8M1a0K48cbscrRu8eLsdoW2ib7/k08OYc4cf16KNWtCGDMmWzYzX87/7Hw33ti3PlGdFyzw7yKV8s9ZsiSEhgbftr7elxcv9nXR+5qa/H3R56VS/vnFvo8EANaFIrmqFrpUv+jw/NVX4fXX/ZIGxebLNzVVX9fOaBg7tu93MmcOXHIJ/MM/+FEF+JFEKpUdyP7Wt/y7fPppWL++7+edeir81V9lj6Samnxs4cABP1q48kq491545pn+ZVmwwMcoCnWBRN1w0RVCi4kuMDdYd9jkyX5kEG3X1AS33+7Tbn/4Q697dJQz1GsSVWm3l7pcJHmikN++HXbv9umU0aUIopk4e/b4pQhmzPD3bN7sA7W7d1e27LXAzH/q6vyG5pMn+87jhReGfg3/oRg71kM82olFohlOUHxHE3UdPf+8/109/njhHULu3x4UHjiPdlzbtvnfZdRlVoadgwJdJFfuYO2BA3DccXDUUd76z72mfDXO0pHhyz+KOfJIOOEEf17KjiaV8tlbxY4A6+s9/Bsb/e+o0OfV1cFJJ/nPYCfOFaFAFxmOqCX29NPw/vtwxRVw/PGwYoWfyfr669nuiD17fAewZ0/2P3Ktdv9IaYZ5XsRAgV5floKJJFFra+H/bAP1xRabpfHBB34Zgvfe88P4ceP8UH3LFr85SVOTH+7v2+f3kZXkO3iw7BeuUwtdpNoUmsa4a5fvFNavzx4dPP207wDGjfPLGU+Y4GfP5g9wNjfD0Uf72MHBg97VsG+fT8OMHHkkHHusdxscOuTz87u7+04nnTIFduwYfKBSSmPmVyVVC10kwYodGZQqf0Cu2BFFKbM4Ch1xRN1Q77zjO4v6eh/0nDDBdxrR4PP+/d79NGaMf1YIvvP56CMfrD7xRF//1FPZncSUKfCZz8Bzz/m6KVP8Gj3PPZcd5G5u9iOb/MHtefP8CGjnTu+rPvZY3xGO9CB4tBMcquuvL/vsGbXQRaSyhjs9MJrNZDbwrRJzt7vkEj+62bbNdwzPPeeBPGWK7zDMsrOi9u/3MuVe9jk6uzW6EFx+19rEifDgg/Dii77zmTLFx1GiWT6bNvnnffvbw761owZFRUQSQvcUFRGpAQp0EZGEUKCLiCSEAl1EJCEU6CIiCaFAFxFJiIpNWzSzncBwbys/CXi/jMWpVrVQz1qoI9RGPWuhjlD5eh4XQphc6IWKBfrhMLN1xeZhJkkt1LMW6gi1Uc9aqCNUdz3V5SIikhAKdBGRhIhroHdUugCjpBbqWQt1hNqoZy3UEaq4nrHsQxcRkf7i2kIXEZE8CnQRkYSIXaCb2YVmtsHMNprZDZUuz3CZ2XQz+6WZvWZmr5jZtZn1E8zs38zsjczjMTnv+Xam3hvM7ILKlX5ozCxlZs+b2c8yy0msY7OZ/cTM/iPzb9qatHqa2X/P/K2+bGYPmdkRSaijmd1nZjvM7OWcdUOul5mdYWYvZV673cxstOtCCCE2P0AKeBP4faAReAGYU+lyDbMuxwKnZ56PB14H5gC3ADdk1t8ALMs8n5OpbxMwK/M9pCpdjxLr+j+AHwE/yywnsY73A1/LPG8EmpNUT2Aq8DYwJrP8Y+CrSagjcC5wOvByzroh1wt4BmgFDHgcuGi06xK3Fvo8YGMI4a0QQjfwMHBphcs0LCGEd0MIz2We7wVew//TXIqHA5nHBZnnlwIPhxAOhBDeBjbi30dVM7NpwBeAe3JWJ62OR+GhcC9ACKE7hPABCasnfsvKMWZWD4wFtpGAOoYQVgP596kbUr3M7FjgqBBCOni6L895z6iJW6BPBbbmLHdl1sWamc0ETgP+HfhUCOFd8NAHfi+zWVzrfhuwBMi9s3DS6vj7wE7gh5mupXvMbBwJqmcI4R3gVmAL8C7w2xDCkySojnmGWq+pmef560dV3AK9UJ9UrOddmtmRwArguhDChwNtWmBdVdfdzC4BdoQQni31LQXWVXUdM+rxQ/YfhBBOA/bhh+nFxK6emT7kS/Fuhk8D48xs4UBvKbCuqutYomL1qor6xi3Qu4DpOcvT8MO+WDKzBjzMHwwhPJJZ/V7m8I3M447M+jjW/T8DXzSzTXj32Hlm9gDJqiN4ubtCCP+eWf4JHvBJqufngbdDCDtDCAeBR4CzSVYdcw21Xl2Z5/nrR1XcAn0tMNvMZplZI3A5sLLCZRqWzAj4vcBrIYT/nfPSSuArmedfAf41Z/3lZtZkZrOA2fggTNUKIXw7hDAthDAT/7f6fyGEhSSojgAhhO3AVjM7KbNqPvAqyarnFuAsMxub+dudj4/7JKmOuYZUr0y3zF4zOyvz/SzKec/oqfQI8zBGpC/GZ4S8CfxtpctzGPX4LH5I9iKwPvNzMTARWAW8kXmckPOev83UewMVGEE/zPq2kZ3lkrg6AnOBdZl/z58CxyStnsD/BP4DeBn4v/hMj9jXEXgIHxc4iLe0rxpOvYCWzHfzJvB9Mmfij+aPTv0XEUmIuHW5iIhIEQp0EZGEUKCLiCSEAl1EJCEU6CIiCaFAFxFJCAW6iEhC/H+W1cVCRBpMlAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#테스트셋으로 실험결과의 오차값을 저장\n",
    "y_vloss=hist.history['val_loss']   #.history : 학습이력 정보(loss,acc..) 리턴\n",
    "\n",
    "#학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc=hist.history['accuracy']\n",
    "\n",
    "#x값을 지정하고 정확도를 파란색으로,오차를 빨간색으로\n",
    "x_len=np.arange(len(y_acc))\n",
    "plt.plot(x_len,y_vloss,'o',c='red',markersize=3)\n",
    "plt.plot(x_len,y_acc,'o',c='blue',markersize=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보스턴 집값(수치) 예측  \n",
    "주어진 환경요인과 집값의 변동을 학습해서, 환경요인만 놓고 집값을 예측하는 것(선형회귀 문제)  \n",
    "!=참(1) 또는 거짓(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "36/36 [==============================] - 0s 613us/step - loss: 8395.1074\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 594us/step - loss: 730.6397\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 565us/step - loss: 524.4141\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 0s 690us/step - loss: 389.0129\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 0s 650us/step - loss: 249.0719\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 667us/step - loss: 163.8280\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 0s 626us/step - loss: 136.2905\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 0s 638us/step - loss: 125.9917\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 0s 630us/step - loss: 116.4055\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 672us/step - loss: 96.4093\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 0s 616us/step - loss: 85.5798\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 0s 639us/step - loss: 81.3189\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 0s 686us/step - loss: 78.2532\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 636us/step - loss: 75.2325\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 0s 656us/step - loss: 74.4882\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 0s 649us/step - loss: 72.1562\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 0s 630us/step - loss: 70.7751\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 0s 678us/step - loss: 71.6290\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 0s 629us/step - loss: 71.7665\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 0s 656us/step - loss: 68.7220\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 0s 662us/step - loss: 66.9720\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 0s 614us/step - loss: 66.6811\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 0s 628us/step - loss: 65.9604\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 0s 638us/step - loss: 67.3767\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 0s 638us/step - loss: 64.7091\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 0s 665us/step - loss: 63.2263\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 0s 610us/step - loss: 62.5428\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 0s 629us/step - loss: 62.1428\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 0s 676us/step - loss: 60.8460\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 0s 654us/step - loss: 59.9760\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 0s 614us/step - loss: 59.6081\n",
      "Epoch 32/200\n",
      "36/36 [==============================] - 0s 664us/step - loss: 59.2471\n",
      "Epoch 33/200\n",
      "36/36 [==============================] - 0s 648us/step - loss: 59.1214\n",
      "Epoch 34/200\n",
      "36/36 [==============================] - 0s 625us/step - loss: 58.2043\n",
      "Epoch 35/200\n",
      "36/36 [==============================] - 0s 644us/step - loss: 57.4716\n",
      "Epoch 36/200\n",
      "36/36 [==============================] - 0s 634us/step - loss: 57.0950\n",
      "Epoch 37/200\n",
      "36/36 [==============================] - 0s 637us/step - loss: 56.4797\n",
      "Epoch 38/200\n",
      "36/36 [==============================] - 0s 683us/step - loss: 56.4587\n",
      "Epoch 39/200\n",
      "36/36 [==============================] - 0s 668us/step - loss: 57.0936\n",
      "Epoch 40/200\n",
      "36/36 [==============================] - 0s 613us/step - loss: 55.1260\n",
      "Epoch 41/200\n",
      "36/36 [==============================] - 0s 617us/step - loss: 55.4455\n",
      "Epoch 42/200\n",
      "36/36 [==============================] - 0s 619us/step - loss: 53.6486\n",
      "Epoch 43/200\n",
      "36/36 [==============================] - 0s 634us/step - loss: 54.2613\n",
      "Epoch 44/200\n",
      "36/36 [==============================] - 0s 626us/step - loss: 52.4336\n",
      "Epoch 45/200\n",
      "36/36 [==============================] - 0s 669us/step - loss: 51.3286\n",
      "Epoch 46/200\n",
      "36/36 [==============================] - 0s 667us/step - loss: 52.1833\n",
      "Epoch 47/200\n",
      "36/36 [==============================] - 0s 601us/step - loss: 52.7158\n",
      "Epoch 48/200\n",
      "36/36 [==============================] - 0s 652us/step - loss: 48.7377\n",
      "Epoch 49/200\n",
      "36/36 [==============================] - 0s 667us/step - loss: 48.7043\n",
      "Epoch 50/200\n",
      "36/36 [==============================] - 0s 640us/step - loss: 49.4026\n",
      "Epoch 51/200\n",
      "36/36 [==============================] - 0s 595us/step - loss: 47.9500\n",
      "Epoch 52/200\n",
      "36/36 [==============================] - 0s 659us/step - loss: 52.8490\n",
      "Epoch 53/200\n",
      "36/36 [==============================] - 0s 607us/step - loss: 45.8987\n",
      "Epoch 54/200\n",
      "36/36 [==============================] - 0s 665us/step - loss: 46.0393\n",
      "Epoch 55/200\n",
      "36/36 [==============================] - 0s 618us/step - loss: 44.8300\n",
      "Epoch 56/200\n",
      "36/36 [==============================] - 0s 674us/step - loss: 43.7604\n",
      "Epoch 57/200\n",
      "36/36 [==============================] - 0s 659us/step - loss: 45.7915\n",
      "Epoch 58/200\n",
      "36/36 [==============================] - 0s 631us/step - loss: 43.0590\n",
      "Epoch 59/200\n",
      "36/36 [==============================] - 0s 606us/step - loss: 43.9800\n",
      "Epoch 60/200\n",
      "36/36 [==============================] - 0s 638us/step - loss: 42.0464\n",
      "Epoch 61/200\n",
      "36/36 [==============================] - 0s 645us/step - loss: 44.1056\n",
      "Epoch 62/200\n",
      "36/36 [==============================] - 0s 634us/step - loss: 41.3432\n",
      "Epoch 63/200\n",
      "36/36 [==============================] - 0s 648us/step - loss: 40.3069\n",
      "Epoch 64/200\n",
      "36/36 [==============================] - 0s 638us/step - loss: 39.5048\n",
      "Epoch 65/200\n",
      "36/36 [==============================] - 0s 607us/step - loss: 40.4932\n",
      "Epoch 66/200\n",
      "36/36 [==============================] - 0s 623us/step - loss: 40.0232\n",
      "Epoch 67/200\n",
      "36/36 [==============================] - 0s 626us/step - loss: 39.9562\n",
      "Epoch 68/200\n",
      "36/36 [==============================] - 0s 653us/step - loss: 38.9052\n",
      "Epoch 69/200\n",
      "36/36 [==============================] - 0s 655us/step - loss: 38.3564\n",
      "Epoch 70/200\n",
      "36/36 [==============================] - 0s 630us/step - loss: 37.1640\n",
      "Epoch 71/200\n",
      "36/36 [==============================] - 0s 667us/step - loss: 37.6937\n",
      "Epoch 72/200\n",
      "36/36 [==============================] - 0s 621us/step - loss: 38.4587\n",
      "Epoch 73/200\n",
      "36/36 [==============================] - 0s 665us/step - loss: 35.8720\n",
      "Epoch 74/200\n",
      "36/36 [==============================] - 0s 643us/step - loss: 36.5010\n",
      "Epoch 75/200\n",
      "36/36 [==============================] - 0s 647us/step - loss: 35.3036\n",
      "Epoch 76/200\n",
      "36/36 [==============================] - 0s 647us/step - loss: 34.3613\n",
      "Epoch 77/200\n",
      "36/36 [==============================] - 0s 626us/step - loss: 33.7435\n",
      "Epoch 78/200\n",
      "36/36 [==============================] - 0s 638us/step - loss: 35.6204\n",
      "Epoch 79/200\n",
      "36/36 [==============================] - 0s 621us/step - loss: 33.2903\n",
      "Epoch 80/200\n",
      "36/36 [==============================] - 0s 628us/step - loss: 35.4231\n",
      "Epoch 81/200\n",
      "36/36 [==============================] - 0s 620us/step - loss: 32.6619\n",
      "Epoch 82/200\n",
      "36/36 [==============================] - 0s 632us/step - loss: 32.5662\n",
      "Epoch 83/200\n",
      "36/36 [==============================] - 0s 686us/step - loss: 31.7612\n",
      "Epoch 84/200\n",
      "36/36 [==============================] - 0s 644us/step - loss: 31.0580\n",
      "Epoch 85/200\n",
      "36/36 [==============================] - 0s 659us/step - loss: 32.1685\n",
      "Epoch 86/200\n",
      "36/36 [==============================] - 0s 650us/step - loss: 31.4837\n",
      "Epoch 87/200\n",
      "36/36 [==============================] - 0s 644us/step - loss: 32.4219\n",
      "Epoch 88/200\n",
      "36/36 [==============================] - 0s 625us/step - loss: 31.9967\n",
      "Epoch 89/200\n",
      "36/36 [==============================] - 0s 621us/step - loss: 32.8900\n",
      "Epoch 90/200\n",
      "36/36 [==============================] - 0s 603us/step - loss: 29.8707\n",
      "Epoch 91/200\n",
      "36/36 [==============================] - 0s 635us/step - loss: 30.8259\n",
      "Epoch 92/200\n",
      "36/36 [==============================] - 0s 630us/step - loss: 31.9341\n",
      "Epoch 93/200\n",
      "36/36 [==============================] - 0s 620us/step - loss: 29.9997\n",
      "Epoch 94/200\n",
      "36/36 [==============================] - 0s 639us/step - loss: 32.2160\n",
      "Epoch 95/200\n",
      "36/36 [==============================] - 0s 603us/step - loss: 29.4866\n",
      "Epoch 96/200\n",
      "36/36 [==============================] - 0s 639us/step - loss: 32.4124\n",
      "Epoch 97/200\n",
      "36/36 [==============================] - 0s 658us/step - loss: 30.7747\n",
      "Epoch 98/200\n",
      "36/36 [==============================] - 0s 652us/step - loss: 33.3727\n",
      "Epoch 99/200\n",
      "36/36 [==============================] - 0s 624us/step - loss: 29.0691\n",
      "Epoch 100/200\n",
      "36/36 [==============================] - 0s 642us/step - loss: 29.0715\n",
      "Epoch 101/200\n",
      "36/36 [==============================] - 0s 608us/step - loss: 28.4275\n",
      "Epoch 102/200\n",
      "36/36 [==============================] - 0s 653us/step - loss: 27.5390\n",
      "Epoch 103/200\n",
      "36/36 [==============================] - 0s 619us/step - loss: 27.3095\n",
      "Epoch 104/200\n",
      "36/36 [==============================] - 0s 612us/step - loss: 27.8468\n",
      "Epoch 105/200\n",
      "36/36 [==============================] - 0s 615us/step - loss: 27.3879\n",
      "Epoch 106/200\n",
      "36/36 [==============================] - 0s 671us/step - loss: 27.4102\n",
      "Epoch 107/200\n",
      "36/36 [==============================] - 0s 630us/step - loss: 26.8992\n",
      "Epoch 108/200\n",
      "36/36 [==============================] - 0s 616us/step - loss: 27.9743\n",
      "Epoch 109/200\n",
      "36/36 [==============================] - 0s 631us/step - loss: 29.0295\n",
      "Epoch 110/200\n",
      "36/36 [==============================] - 0s 645us/step - loss: 27.0552\n",
      "Epoch 111/200\n",
      "36/36 [==============================] - 0s 602us/step - loss: 27.1602\n",
      "Epoch 112/200\n",
      "36/36 [==============================] - 0s 621us/step - loss: 26.8427\n",
      "Epoch 113/200\n",
      "36/36 [==============================] - 0s 597us/step - loss: 26.2062\n",
      "Epoch 114/200\n",
      "36/36 [==============================] - 0s 597us/step - loss: 26.3352\n",
      "Epoch 115/200\n",
      "36/36 [==============================] - 0s 608us/step - loss: 26.8930\n",
      "Epoch 116/200\n",
      "36/36 [==============================] - 0s 612us/step - loss: 27.1321\n",
      "Epoch 117/200\n",
      "36/36 [==============================] - 0s 612us/step - loss: 26.7697\n",
      "Epoch 118/200\n",
      "36/36 [==============================] - 0s 625us/step - loss: 27.3890\n",
      "Epoch 119/200\n",
      "36/36 [==============================] - 0s 601us/step - loss: 26.9682\n",
      "Epoch 120/200\n",
      "36/36 [==============================] - 0s 619us/step - loss: 28.5625\n",
      "Epoch 121/200\n",
      "36/36 [==============================] - 0s 604us/step - loss: 27.8233\n",
      "Epoch 122/200\n",
      "36/36 [==============================] - 0s 633us/step - loss: 26.5831\n",
      "Epoch 123/200\n",
      "36/36 [==============================] - 0s 608us/step - loss: 26.6183\n",
      "Epoch 124/200\n",
      "36/36 [==============================] - 0s 614us/step - loss: 27.2429\n",
      "Epoch 125/200\n",
      "36/36 [==============================] - 0s 609us/step - loss: 26.5517\n",
      "Epoch 126/200\n",
      "36/36 [==============================] - 0s 605us/step - loss: 25.0431\n",
      "Epoch 127/200\n",
      "36/36 [==============================] - 0s 633us/step - loss: 25.4685\n",
      "Epoch 128/200\n",
      "36/36 [==============================] - 0s 599us/step - loss: 25.5374\n",
      "Epoch 129/200\n",
      "36/36 [==============================] - 0s 653us/step - loss: 26.0870\n",
      "Epoch 130/200\n",
      "36/36 [==============================] - 0s 616us/step - loss: 26.5442\n",
      "Epoch 131/200\n",
      "36/36 [==============================] - 0s 607us/step - loss: 26.9640\n",
      "Epoch 132/200\n",
      "36/36 [==============================] - 0s 587us/step - loss: 25.4937\n",
      "Epoch 133/200\n",
      "36/36 [==============================] - 0s 615us/step - loss: 27.3169\n",
      "Epoch 134/200\n",
      "36/36 [==============================] - 0s 624us/step - loss: 25.2230\n",
      "Epoch 135/200\n",
      "36/36 [==============================] - 0s 616us/step - loss: 26.4761\n",
      "Epoch 136/200\n",
      "36/36 [==============================] - 0s 653us/step - loss: 25.8260\n",
      "Epoch 137/200\n",
      "36/36 [==============================] - 0s 646us/step - loss: 26.1035\n",
      "Epoch 138/200\n",
      "36/36 [==============================] - 0s 619us/step - loss: 26.3405\n",
      "Epoch 139/200\n",
      "36/36 [==============================] - 0s 619us/step - loss: 26.8791\n",
      "Epoch 140/200\n",
      "36/36 [==============================] - 0s 606us/step - loss: 27.6349\n",
      "Epoch 141/200\n",
      "36/36 [==============================] - 0s 601us/step - loss: 32.6681\n",
      "Epoch 142/200\n",
      "36/36 [==============================] - 0s 642us/step - loss: 25.7608\n",
      "Epoch 143/200\n",
      "36/36 [==============================] - 0s 626us/step - loss: 24.7145\n",
      "Epoch 144/200\n",
      "36/36 [==============================] - 0s 599us/step - loss: 28.2596\n",
      "Epoch 145/200\n",
      "36/36 [==============================] - 0s 635us/step - loss: 25.6739\n",
      "Epoch 146/200\n",
      "36/36 [==============================] - 0s 609us/step - loss: 24.7848\n",
      "Epoch 147/200\n",
      "36/36 [==============================] - 0s 609us/step - loss: 24.5725\n",
      "Epoch 148/200\n",
      "36/36 [==============================] - 0s 602us/step - loss: 25.7273\n",
      "Epoch 149/200\n",
      "36/36 [==============================] - 0s 579us/step - loss: 24.3180\n",
      "Epoch 150/200\n",
      "36/36 [==============================] - 0s 601us/step - loss: 26.5079\n",
      "Epoch 151/200\n",
      "36/36 [==============================] - 0s 620us/step - loss: 24.2038\n",
      "Epoch 152/200\n",
      "36/36 [==============================] - 0s 654us/step - loss: 23.7742\n",
      "Epoch 153/200\n",
      "36/36 [==============================] - 0s 609us/step - loss: 25.7836\n",
      "Epoch 154/200\n",
      "36/36 [==============================] - 0s 604us/step - loss: 24.9930\n",
      "Epoch 155/200\n",
      "36/36 [==============================] - 0s 663us/step - loss: 23.5989\n",
      "Epoch 156/200\n",
      "36/36 [==============================] - 0s 610us/step - loss: 23.7238\n",
      "Epoch 157/200\n",
      "36/36 [==============================] - 0s 604us/step - loss: 24.9944\n",
      "Epoch 158/200\n",
      "36/36 [==============================] - 0s 622us/step - loss: 24.5613\n",
      "Epoch 159/200\n",
      "36/36 [==============================] - 0s 635us/step - loss: 24.5942\n",
      "Epoch 160/200\n",
      "36/36 [==============================] - 0s 622us/step - loss: 23.0612\n",
      "Epoch 161/200\n",
      "36/36 [==============================] - 0s 645us/step - loss: 23.2568\n",
      "Epoch 162/200\n",
      "36/36 [==============================] - 0s 640us/step - loss: 22.9149\n",
      "Epoch 163/200\n",
      "36/36 [==============================] - 0s 610us/step - loss: 24.5465\n",
      "Epoch 164/200\n",
      "36/36 [==============================] - 0s 628us/step - loss: 25.8017\n",
      "Epoch 165/200\n",
      "36/36 [==============================] - 0s 588us/step - loss: 22.7946\n",
      "Epoch 166/200\n",
      "36/36 [==============================] - 0s 632us/step - loss: 22.4869\n",
      "Epoch 167/200\n",
      "36/36 [==============================] - 0s 641us/step - loss: 24.4647\n",
      "Epoch 168/200\n",
      "36/36 [==============================] - 0s 625us/step - loss: 23.2690\n",
      "Epoch 169/200\n",
      "36/36 [==============================] - 0s 614us/step - loss: 21.9328\n",
      "Epoch 170/200\n",
      "36/36 [==============================] - 0s 660us/step - loss: 22.9404\n",
      "Epoch 171/200\n",
      "36/36 [==============================] - 0s 649us/step - loss: 21.6677\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 0s 596us/step - loss: 21.8817\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 0s 603us/step - loss: 21.9830\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 0s 604us/step - loss: 23.4227\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 0s 619us/step - loss: 21.4012\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 0s 628us/step - loss: 22.5939\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 0s 636us/step - loss: 21.2416\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 0s 634us/step - loss: 22.9736\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 0s 630us/step - loss: 20.6140\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 0s 622us/step - loss: 21.3899\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 0s 647us/step - loss: 21.7303\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 0s 652us/step - loss: 20.5079\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 0s 685us/step - loss: 21.4368\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 0s 631us/step - loss: 21.2129\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 0s 618us/step - loss: 21.0200\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 0s 627us/step - loss: 21.0126\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 0s 626us/step - loss: 21.3600\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 0s 634us/step - loss: 22.8090\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 0s 649us/step - loss: 21.8894\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 0s 666us/step - loss: 20.2678\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 0s 634us/step - loss: 19.6487\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 0s 627us/step - loss: 22.5670\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - ETA: 0s - loss: 27.51 - 0s 641us/step - loss: 23.3860\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 666us/step - loss: 21.8140\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 0s 657us/step - loss: 19.7876\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 0s 662us/step - loss: 20.5867\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 0s 652us/step - loss: 19.8300\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 0s 615us/step - loss: 20.1106\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 0s 607us/step - loss: 20.5687\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 0s 639us/step - loss: 20.0043\n",
      "실제가격:22.0, 예상가격:24.666141510009766\n",
      "실제가격:43.8, 예상가격:32.396339416503906\n",
      "실제가격:14.6, 예상가격:14.762693405151367\n",
      "실제가격:32.7, 예상가격:28.130172729492188\n",
      "실제가격:12.5, 예상가격:15.842721939086914\n",
      "실제가격:23.1, 예상가격:22.731189727783203\n",
      "실제가격:21.0, 예상가격:20.126985549926758\n",
      "실제가격:5.6, 예상가격:11.413947105407715\n",
      "실제가격:27.0, 예상가격:34.75926971435547\n",
      "실제가격:17.0, 예상가격:15.238564491271973\n",
      "실제가격:8.7, 예상가격:13.4194917678833\n",
      "실제가격:21.9, 예상가격:23.867578506469727\n",
      "실제가격:20.9, 예상가격:19.809568405151367\n",
      "실제가격:26.7, 예상가격:27.43148422241211\n",
      "실제가격:23.1, 예상가격:20.635522842407227\n",
      "실제가격:29.0, 예상가격:30.67214012145996\n",
      "실제가격:13.8, 예상가격:14.09794807434082\n",
      "실제가격:50.0, 예상가격:42.82939910888672\n",
      "실제가격:15.6, 예상가격:8.515216827392578\n",
      "실제가격:24.7, 예상가격:20.081157684326172\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split  #학습셋,검증셋 나누기\n",
    "\n",
    "seed=0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "df=pd.read_csv('C:/Users/user/machine_learning1/housing.csv')  #delim_whitespace=True 로도 가능(구분자 탭일 경우)\n",
    "dataset=df.values\n",
    "X=dataset[:,0:13]\n",
    "Y=dataset[:,13]\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=seed) #학습셋, 검증셋 나눔\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(30,input_dim=13,activation='relu'))\n",
    "model.add(Dense(6,activation='relu'))\n",
    "model.add(Dense(1))  #마지막에 참과 거짓 구분필요 X=>출력층에 활성화함수 지정할 필요 X\n",
    "       \n",
    "model.compile(loss='mean_squared_error', #선형회귀니까\n",
    "             optimizer='adam')\n",
    "model.fit(X_train,Y_train,epochs=200,batch_size=10)\n",
    "\n",
    "#예측값과 실제값의 비교\n",
    "Y_prediction=model.predict(X_test).flatten()\n",
    "for i in range(20):\n",
    "    label=Y_test[i]\n",
    "    prediction=Y_prediction[i]\n",
    "    print('실제가격:{}, 예상가격:{}'.format(label,prediction)) #이진분류 아니니까 accuracy 출력X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 피마인디언 당뇨병 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 11.5562 - accuracy: 0.6231\n",
      "Epoch 2/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 9.8860 - accuracy: 0.6213\n",
      "Epoch 3/1500\n",
      "9/9 [==============================] - 0s 876us/step - loss: 8.3591 - accuracy: 0.6231\n",
      "Epoch 4/1500\n",
      "9/9 [==============================] - 0s 886us/step - loss: 6.9267 - accuracy: 0.6175\n",
      "Epoch 5/1500\n",
      "9/9 [==============================] - 0s 767us/step - loss: 5.5075 - accuracy: 0.6194\n",
      "Epoch 6/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 4.1984 - accuracy: 0.6213\n",
      "Epoch 7/1500\n",
      "9/9 [==============================] - 0s 757us/step - loss: 3.1246 - accuracy: 0.6287\n",
      "Epoch 8/1500\n",
      "9/9 [==============================] - 0s 746us/step - loss: 2.3000 - accuracy: 0.6306\n",
      "Epoch 9/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 1.8287 - accuracy: 0.6418\n",
      "Epoch 10/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 1.5169 - accuracy: 0.6213\n",
      "Epoch 11/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 1.3661 - accuracy: 0.5970\n",
      "Epoch 12/1500\n",
      "9/9 [==============================] - 0s 666us/step - loss: 1.2584 - accuracy: 0.5784\n",
      "Epoch 13/1500\n",
      "9/9 [==============================] - 0s 664us/step - loss: 1.2100 - accuracy: 0.5690\n",
      "Epoch 14/1500\n",
      "9/9 [==============================] - 0s 708us/step - loss: 1.1912 - accuracy: 0.5560\n",
      "Epoch 15/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 1.1361 - accuracy: 0.5616\n",
      "Epoch 16/1500\n",
      "9/9 [==============================] - 0s 683us/step - loss: 1.1176 - accuracy: 0.5728\n",
      "Epoch 17/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 1.0860 - accuracy: 0.5746\n",
      "Epoch 18/1500\n",
      "9/9 [==============================] - 0s 770us/step - loss: 1.0596 - accuracy: 0.5728\n",
      "Epoch 19/1500\n",
      "9/9 [==============================] - 0s 645us/step - loss: 1.0329 - accuracy: 0.5653\n",
      "Epoch 20/1500\n",
      "9/9 [==============================] - 0s 709us/step - loss: 1.0067 - accuracy: 0.5672\n",
      "Epoch 21/1500\n",
      "9/9 [==============================] - 0s 589us/step - loss: 0.9821 - accuracy: 0.5802\n",
      "Epoch 22/1500\n",
      "9/9 [==============================] - 0s 790us/step - loss: 0.9644 - accuracy: 0.5672\n",
      "Epoch 23/1500\n",
      "9/9 [==============================] - 0s 647us/step - loss: 0.9424 - accuracy: 0.5970\n",
      "Epoch 24/1500\n",
      "9/9 [==============================] - 0s 671us/step - loss: 0.9205 - accuracy: 0.6082\n",
      "Epoch 25/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.9035 - accuracy: 0.5858\n",
      "Epoch 26/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.8840 - accuracy: 0.6138\n",
      "Epoch 27/1500\n",
      "9/9 [==============================] - 0s 688us/step - loss: 0.8700 - accuracy: 0.6007\n",
      "Epoch 28/1500\n",
      "9/9 [==============================] - 0s 562us/step - loss: 0.8506 - accuracy: 0.6213\n",
      "Epoch 29/1500\n",
      "9/9 [==============================] - 0s 664us/step - loss: 0.8379 - accuracy: 0.6213\n",
      "Epoch 30/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.8290 - accuracy: 0.6213\n",
      "Epoch 31/1500\n",
      "9/9 [==============================] - 0s 642us/step - loss: 0.8174 - accuracy: 0.6343\n",
      "Epoch 32/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.8055 - accuracy: 0.6213\n",
      "Epoch 33/1500\n",
      "9/9 [==============================] - 0s 655us/step - loss: 0.7940 - accuracy: 0.6381\n",
      "Epoch 34/1500\n",
      "9/9 [==============================] - 0s 671us/step - loss: 0.7786 - accuracy: 0.6493\n",
      "Epoch 35/1500\n",
      "9/9 [==============================] - 0s 728us/step - loss: 0.7686 - accuracy: 0.6493\n",
      "Epoch 36/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.7598 - accuracy: 0.6474\n",
      "Epoch 37/1500\n",
      "9/9 [==============================] - 0s 671us/step - loss: 0.7532 - accuracy: 0.6586\n",
      "Epoch 38/1500\n",
      "9/9 [==============================] - 0s 547us/step - loss: 0.7425 - accuracy: 0.6642\n",
      "Epoch 39/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.7351 - accuracy: 0.6716\n",
      "Epoch 40/1500\n",
      "9/9 [==============================] - 0s 694us/step - loss: 0.7288 - accuracy: 0.6698\n",
      "Epoch 41/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.7197 - accuracy: 0.6698\n",
      "Epoch 42/1500\n",
      "9/9 [==============================] - 0s 598us/step - loss: 0.7163 - accuracy: 0.6735\n",
      "Epoch 43/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.7109 - accuracy: 0.6716\n",
      "Epoch 44/1500\n",
      "9/9 [==============================] - 0s 718us/step - loss: 0.7049 - accuracy: 0.6791\n",
      "Epoch 45/1500\n",
      "9/9 [==============================] - 0s 639us/step - loss: 0.7049 - accuracy: 0.6567\n",
      "Epoch 46/1500\n",
      "9/9 [==============================] - 0s 771us/step - loss: 0.7000 - accuracy: 0.6642\n",
      "Epoch 47/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.6988 - accuracy: 0.6716\n",
      "Epoch 48/1500\n",
      "9/9 [==============================] - 0s 673us/step - loss: 0.6964 - accuracy: 0.6623\n",
      "Epoch 49/1500\n",
      "9/9 [==============================] - 0s 535us/step - loss: 0.6865 - accuracy: 0.6698\n",
      "Epoch 50/1500\n",
      "9/9 [==============================] - 0s 759us/step - loss: 0.6855 - accuracy: 0.6679\n",
      "Epoch 51/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.6822 - accuracy: 0.6604\n",
      "Epoch 52/1500\n",
      "9/9 [==============================] - 0s 764us/step - loss: 0.6793 - accuracy: 0.6679\n",
      "Epoch 53/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.6772 - accuracy: 0.6735\n",
      "Epoch 54/1500\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.6782 - accuracy: 0.6698\n",
      "Epoch 55/1500\n",
      "9/9 [==============================] - 0s 672us/step - loss: 0.6707 - accuracy: 0.6679\n",
      "Epoch 56/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.6680 - accuracy: 0.6604\n",
      "Epoch 57/1500\n",
      "9/9 [==============================] - 0s 683us/step - loss: 0.6685 - accuracy: 0.6567\n",
      "Epoch 58/1500\n",
      "9/9 [==============================] - 0s 567us/step - loss: 0.6674 - accuracy: 0.6810\n",
      "Epoch 59/1500\n",
      "9/9 [==============================] - 0s 695us/step - loss: 0.6628 - accuracy: 0.6679\n",
      "Epoch 60/1500\n",
      "9/9 [==============================] - 0s 562us/step - loss: 0.6599 - accuracy: 0.6754\n",
      "Epoch 61/1500\n",
      "9/9 [==============================] - 0s 629us/step - loss: 0.6566 - accuracy: 0.6772\n",
      "Epoch 62/1500\n",
      "9/9 [==============================] - 0s 625us/step - loss: 0.6567 - accuracy: 0.6660\n",
      "Epoch 63/1500\n",
      "9/9 [==============================] - 0s 778us/step - loss: 0.6526 - accuracy: 0.6754\n",
      "Epoch 64/1500\n",
      "9/9 [==============================] - 0s 678us/step - loss: 0.6512 - accuracy: 0.6772\n",
      "Epoch 65/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.6511 - accuracy: 0.6698\n",
      "Epoch 66/1500\n",
      "9/9 [==============================] - 0s 678us/step - loss: 0.6513 - accuracy: 0.6660\n",
      "Epoch 67/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.6479 - accuracy: 0.6847\n",
      "Epoch 68/1500\n",
      "9/9 [==============================] - 0s 622us/step - loss: 0.6451 - accuracy: 0.6866\n",
      "Epoch 69/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6438 - accuracy: 0.6866\n",
      "Epoch 70/1500\n",
      "9/9 [==============================] - 0s 613us/step - loss: 0.6432 - accuracy: 0.6754\n",
      "Epoch 71/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6384 - accuracy: 0.6959\n",
      "Epoch 72/1500\n",
      "9/9 [==============================] - 0s 705us/step - loss: 0.6371 - accuracy: 0.6959\n",
      "Epoch 73/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6362 - accuracy: 0.6884\n",
      "Epoch 74/1500\n",
      "9/9 [==============================] - 0s 682us/step - loss: 0.6342 - accuracy: 0.6903\n",
      "Epoch 75/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.6364 - accuracy: 0.6922\n",
      "Epoch 76/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6369 - accuracy: 0.6959\n",
      "Epoch 77/1500\n",
      "9/9 [==============================] - 0s 642us/step - loss: 0.6409 - accuracy: 0.6754\n",
      "Epoch 78/1500\n",
      "9/9 [==============================] - 0s 550us/step - loss: 0.6316 - accuracy: 0.6866\n",
      "Epoch 79/1500\n",
      "9/9 [==============================] - 0s 709us/step - loss: 0.6310 - accuracy: 0.6903\n",
      "Epoch 80/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6258 - accuracy: 0.6922\n",
      "Epoch 81/1500\n",
      "9/9 [==============================] - 0s 640us/step - loss: 0.6255 - accuracy: 0.6884\n",
      "Epoch 82/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.6286 - accuracy: 0.6922\n",
      "Epoch 83/1500\n",
      "9/9 [==============================] - 0s 716us/step - loss: 0.6264 - accuracy: 0.6996\n",
      "Epoch 84/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.6329 - accuracy: 0.6903\n",
      "Epoch 85/1500\n",
      "9/9 [==============================] - 0s 641us/step - loss: 0.6410 - accuracy: 0.6735\n",
      "Epoch 86/1500\n",
      "9/9 [==============================] - 0s 673us/step - loss: 0.6334 - accuracy: 0.6884\n",
      "Epoch 87/1500\n",
      "9/9 [==============================] - 0s 717us/step - loss: 0.6391 - accuracy: 0.6810\n",
      "Epoch 88/1500\n",
      "9/9 [==============================] - 0s 652us/step - loss: 0.6275 - accuracy: 0.6847\n",
      "Epoch 89/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6223 - accuracy: 0.6959\n",
      "Epoch 90/1500\n",
      "9/9 [==============================] - 0s 637us/step - loss: 0.6191 - accuracy: 0.6884\n",
      "Epoch 91/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6206 - accuracy: 0.6903\n",
      "Epoch 92/1500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.6399 - accuracy: 0.6493\n",
      "Epoch 93/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6163 - accuracy: 0.6903\n",
      "Epoch 94/1500\n",
      "9/9 [==============================] - 0s 655us/step - loss: 0.6130 - accuracy: 0.7071\n",
      "Epoch 95/1500\n",
      "9/9 [==============================] - 0s 721us/step - loss: 0.6136 - accuracy: 0.6903\n",
      "Epoch 96/1500\n",
      "9/9 [==============================] - 0s 703us/step - loss: 0.6106 - accuracy: 0.6922\n",
      "Epoch 97/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6121 - accuracy: 0.6828\n",
      "Epoch 98/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.6109 - accuracy: 0.6940\n",
      "Epoch 99/1500\n",
      "9/9 [==============================] - 0s 769us/step - loss: 0.6061 - accuracy: 0.6996\n",
      "Epoch 100/1500\n",
      "9/9 [==============================] - 0s 593us/step - loss: 0.6064 - accuracy: 0.6940\n",
      "Epoch 101/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6090 - accuracy: 0.6959\n",
      "Epoch 102/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6031 - accuracy: 0.6978\n",
      "Epoch 103/1500\n",
      "9/9 [==============================] - 0s 664us/step - loss: 0.6077 - accuracy: 0.6847\n",
      "Epoch 104/1500\n",
      "9/9 [==============================] - 0s 633us/step - loss: 0.6023 - accuracy: 0.6978\n",
      "Epoch 105/1500\n",
      "9/9 [==============================] - 0s 615us/step - loss: 0.6013 - accuracy: 0.6978\n",
      "Epoch 106/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.6052 - accuracy: 0.6922\n",
      "Epoch 107/1500\n",
      "9/9 [==============================] - 0s 687us/step - loss: 0.5992 - accuracy: 0.6978\n",
      "Epoch 108/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6046 - accuracy: 0.6978\n",
      "Epoch 109/1500\n",
      "9/9 [==============================] - 0s 550us/step - loss: 0.6039 - accuracy: 0.6940\n",
      "Epoch 110/1500\n",
      "9/9 [==============================] - 0s 540us/step - loss: 0.5964 - accuracy: 0.7034\n",
      "Epoch 111/1500\n",
      "9/9 [==============================] - 0s 733us/step - loss: 0.5975 - accuracy: 0.6978\n",
      "Epoch 112/1500\n",
      "9/9 [==============================] - 0s 651us/step - loss: 0.5986 - accuracy: 0.7071\n",
      "Epoch 113/1500\n",
      "9/9 [==============================] - 0s 778us/step - loss: 0.5950 - accuracy: 0.6903\n",
      "Epoch 114/1500\n",
      "9/9 [==============================] - 0s 662us/step - loss: 0.5976 - accuracy: 0.6978\n",
      "Epoch 115/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5907 - accuracy: 0.7015\n",
      "Epoch 116/1500\n",
      "9/9 [==============================] - 0s 674us/step - loss: 0.5919 - accuracy: 0.6978\n",
      "Epoch 117/1500\n",
      "9/9 [==============================] - 0s 746us/step - loss: 0.5924 - accuracy: 0.6940\n",
      "Epoch 118/1500\n",
      "9/9 [==============================] - 0s 727us/step - loss: 0.5920 - accuracy: 0.7034\n",
      "Epoch 119/1500\n",
      "9/9 [==============================] - 0s 736us/step - loss: 0.5928 - accuracy: 0.6996\n",
      "Epoch 120/1500\n",
      "9/9 [==============================] - 0s 647us/step - loss: 0.5897 - accuracy: 0.6940\n",
      "Epoch 121/1500\n",
      "9/9 [==============================] - 0s 567us/step - loss: 0.5883 - accuracy: 0.7015\n",
      "Epoch 122/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5892 - accuracy: 0.6959\n",
      "Epoch 123/1500\n",
      "9/9 [==============================] - 0s 701us/step - loss: 0.5897 - accuracy: 0.6978\n",
      "Epoch 124/1500\n",
      "9/9 [==============================] - 0s 562us/step - loss: 0.5873 - accuracy: 0.7015\n",
      "Epoch 125/1500\n",
      "9/9 [==============================] - 0s 596us/step - loss: 0.5853 - accuracy: 0.7015\n",
      "Epoch 126/1500\n",
      "9/9 [==============================] - 0s 750us/step - loss: 0.5847 - accuracy: 0.7015\n",
      "Epoch 127/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5862 - accuracy: 0.6940\n",
      "Epoch 128/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5821 - accuracy: 0.6959\n",
      "Epoch 129/1500\n",
      "9/9 [==============================] - 0s 576us/step - loss: 0.5840 - accuracy: 0.6996\n",
      "Epoch 130/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5813 - accuracy: 0.6978\n",
      "Epoch 131/1500\n",
      "9/9 [==============================] - 0s 579us/step - loss: 0.5787 - accuracy: 0.7015\n",
      "Epoch 132/1500\n",
      "9/9 [==============================] - 0s 570us/step - loss: 0.5836 - accuracy: 0.6996\n",
      "Epoch 133/1500\n",
      "9/9 [==============================] - 0s 631us/step - loss: 0.5793 - accuracy: 0.6922\n",
      "Epoch 134/1500\n",
      "9/9 [==============================] - 0s 546us/step - loss: 0.5879 - accuracy: 0.6828\n",
      "Epoch 135/1500\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.5763 - accuracy: 0.6996\n",
      "Epoch 136/1500\n",
      "9/9 [==============================] - 0s 551us/step - loss: 0.5749 - accuracy: 0.7071\n",
      "Epoch 137/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.5761 - accuracy: 0.7034\n",
      "Epoch 138/1500\n",
      "9/9 [==============================] - 0s 524us/step - loss: 0.5784 - accuracy: 0.6810\n",
      "Epoch 139/1500\n",
      "9/9 [==============================] - 0s 586us/step - loss: 0.5933 - accuracy: 0.6586\n",
      "Epoch 140/1500\n",
      "9/9 [==============================] - 0s 590us/step - loss: 0.6000 - accuracy: 0.6884\n",
      "Epoch 141/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5830 - accuracy: 0.6866\n",
      "Epoch 142/1500\n",
      "9/9 [==============================] - 0s 612us/step - loss: 0.5712 - accuracy: 0.7015\n",
      "Epoch 143/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.5690 - accuracy: 0.7108\n",
      "Epoch 144/1500\n",
      "9/9 [==============================] - 0s 596us/step - loss: 0.5729 - accuracy: 0.6959\n",
      "Epoch 145/1500\n",
      "9/9 [==============================] - 0s 605us/step - loss: 0.5723 - accuracy: 0.6959\n",
      "Epoch 146/1500\n",
      "9/9 [==============================] - 0s 675us/step - loss: 0.5697 - accuracy: 0.6940\n",
      "Epoch 147/1500\n",
      "9/9 [==============================] - 0s 561us/step - loss: 0.5677 - accuracy: 0.7071\n",
      "Epoch 148/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5665 - accuracy: 0.7071\n",
      "Epoch 149/1500\n",
      "9/9 [==============================] - 0s 709us/step - loss: 0.5653 - accuracy: 0.7052\n",
      "Epoch 150/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.5641 - accuracy: 0.7052\n",
      "Epoch 151/1500\n",
      "9/9 [==============================] - 0s 691us/step - loss: 0.5668 - accuracy: 0.7034\n",
      "Epoch 152/1500\n",
      "9/9 [==============================] - 0s 553us/step - loss: 0.5625 - accuracy: 0.7071\n",
      "Epoch 153/1500\n",
      "9/9 [==============================] - 0s 684us/step - loss: 0.5636 - accuracy: 0.7052\n",
      "Epoch 154/1500\n",
      "9/9 [==============================] - 0s 576us/step - loss: 0.5609 - accuracy: 0.7164\n",
      "Epoch 155/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.5636 - accuracy: 0.7071\n",
      "Epoch 156/1500\n",
      "9/9 [==============================] - 0s 707us/step - loss: 0.5640 - accuracy: 0.6978\n",
      "Epoch 157/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5634 - accuracy: 0.7034\n",
      "Epoch 158/1500\n",
      "9/9 [==============================] - 0s 627us/step - loss: 0.5601 - accuracy: 0.7071\n",
      "Epoch 159/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5644 - accuracy: 0.6996\n",
      "Epoch 160/1500\n",
      "9/9 [==============================] - 0s 633us/step - loss: 0.5616 - accuracy: 0.6978\n",
      "Epoch 161/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5571 - accuracy: 0.7034\n",
      "Epoch 162/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 664us/step - loss: 0.5584 - accuracy: 0.7015\n",
      "Epoch 163/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5590 - accuracy: 0.7052\n",
      "Epoch 164/1500\n",
      "9/9 [==============================] - 0s 688us/step - loss: 0.5546 - accuracy: 0.7201\n",
      "Epoch 165/1500\n",
      "9/9 [==============================] - 0s 570us/step - loss: 0.5532 - accuracy: 0.7183\n",
      "Epoch 166/1500\n",
      "9/9 [==============================] - 0s 641us/step - loss: 0.5554 - accuracy: 0.7108\n",
      "Epoch 167/1500\n",
      "9/9 [==============================] - 0s 561us/step - loss: 0.5504 - accuracy: 0.7239\n",
      "Epoch 168/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5543 - accuracy: 0.7146\n",
      "Epoch 169/1500\n",
      "9/9 [==============================] - 0s 613us/step - loss: 0.5544 - accuracy: 0.7052\n",
      "Epoch 170/1500\n",
      "9/9 [==============================] - 0s 695us/step - loss: 0.5525 - accuracy: 0.7090\n",
      "Epoch 171/1500\n",
      "9/9 [==============================] - 0s 640us/step - loss: 0.5528 - accuracy: 0.7183\n",
      "Epoch 172/1500\n",
      "9/9 [==============================] - 0s 652us/step - loss: 0.5500 - accuracy: 0.7183\n",
      "Epoch 173/1500\n",
      "9/9 [==============================] - 0s 588us/step - loss: 0.5505 - accuracy: 0.7220\n",
      "Epoch 174/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5626 - accuracy: 0.7052\n",
      "Epoch 175/1500\n",
      "9/9 [==============================] - 0s 621us/step - loss: 0.5527 - accuracy: 0.7146\n",
      "Epoch 176/1500\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.5495 - accuracy: 0.7239\n",
      "Epoch 177/1500\n",
      "9/9 [==============================] - 0s 655us/step - loss: 0.5511 - accuracy: 0.7164\n",
      "Epoch 178/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5451 - accuracy: 0.7220\n",
      "Epoch 179/1500\n",
      "9/9 [==============================] - 0s 744us/step - loss: 0.5502 - accuracy: 0.7220\n",
      "Epoch 180/1500\n",
      "9/9 [==============================] - 0s 643us/step - loss: 0.5474 - accuracy: 0.7108\n",
      "Epoch 181/1500\n",
      "9/9 [==============================] - 0s 710us/step - loss: 0.5479 - accuracy: 0.7127\n",
      "Epoch 182/1500\n",
      "9/9 [==============================] - 0s 681us/step - loss: 0.5459 - accuracy: 0.7183\n",
      "Epoch 183/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5446 - accuracy: 0.7183\n",
      "Epoch 184/1500\n",
      "9/9 [==============================] - 0s 634us/step - loss: 0.5544 - accuracy: 0.7090\n",
      "Epoch 185/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5540 - accuracy: 0.7127\n",
      "Epoch 186/1500\n",
      "9/9 [==============================] - 0s 602us/step - loss: 0.5465 - accuracy: 0.7034\n",
      "Epoch 187/1500\n",
      "9/9 [==============================] - 0s 564us/step - loss: 0.5474 - accuracy: 0.7183\n",
      "Epoch 188/1500\n",
      "9/9 [==============================] - 0s 688us/step - loss: 0.5437 - accuracy: 0.7220\n",
      "Epoch 189/1500\n",
      "9/9 [==============================] - 0s 545us/step - loss: 0.5520 - accuracy: 0.7090\n",
      "Epoch 190/1500\n",
      "9/9 [==============================] - 0s 758us/step - loss: 0.5427 - accuracy: 0.7164\n",
      "Epoch 191/1500\n",
      "9/9 [==============================] - 0s 541us/step - loss: 0.5456 - accuracy: 0.7220\n",
      "Epoch 192/1500\n",
      "9/9 [==============================] - 0s 715us/step - loss: 0.5403 - accuracy: 0.7239\n",
      "Epoch 193/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5451 - accuracy: 0.7108\n",
      "Epoch 194/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5496 - accuracy: 0.7220\n",
      "Epoch 195/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5571 - accuracy: 0.7034\n",
      "Epoch 196/1500\n",
      "9/9 [==============================] - 0s 673us/step - loss: 0.5410 - accuracy: 0.7164\n",
      "Epoch 197/1500\n",
      "9/9 [==============================] - 0s 698us/step - loss: 0.5524 - accuracy: 0.7146\n",
      "Epoch 198/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5432 - accuracy: 0.7220\n",
      "Epoch 199/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5418 - accuracy: 0.7183\n",
      "Epoch 200/1500\n",
      "9/9 [==============================] - 0s 648us/step - loss: 0.5378 - accuracy: 0.7276\n",
      "Epoch 201/1500\n",
      "9/9 [==============================] - 0s 762us/step - loss: 0.5398 - accuracy: 0.7164\n",
      "Epoch 202/1500\n",
      "9/9 [==============================] - 0s 653us/step - loss: 0.5371 - accuracy: 0.7276\n",
      "Epoch 203/1500\n",
      "9/9 [==============================] - 0s 653us/step - loss: 0.5378 - accuracy: 0.7313\n",
      "Epoch 204/1500\n",
      "9/9 [==============================] - 0s 613us/step - loss: 0.5439 - accuracy: 0.7220\n",
      "Epoch 205/1500\n",
      "9/9 [==============================] - 0s 760us/step - loss: 0.5405 - accuracy: 0.7164\n",
      "Epoch 206/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.5423 - accuracy: 0.7201\n",
      "Epoch 207/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5389 - accuracy: 0.7239\n",
      "Epoch 208/1500\n",
      "9/9 [==============================] - 0s 631us/step - loss: 0.5449 - accuracy: 0.7220\n",
      "Epoch 209/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5473 - accuracy: 0.7201\n",
      "Epoch 210/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5381 - accuracy: 0.7257\n",
      "Epoch 211/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5386 - accuracy: 0.7183\n",
      "Epoch 212/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5545 - accuracy: 0.7127\n",
      "Epoch 213/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.5406 - accuracy: 0.7183\n",
      "Epoch 214/1500\n",
      "9/9 [==============================] - 0s 562us/step - loss: 0.5418 - accuracy: 0.7183\n",
      "Epoch 215/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5488 - accuracy: 0.7183\n",
      "Epoch 216/1500\n",
      "9/9 [==============================] - 0s 548us/step - loss: 0.5443 - accuracy: 0.7257\n",
      "Epoch 217/1500\n",
      "9/9 [==============================] - 0s 701us/step - loss: 0.5363 - accuracy: 0.7220\n",
      "Epoch 218/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5494 - accuracy: 0.7164\n",
      "Epoch 219/1500\n",
      "9/9 [==============================] - 0s 648us/step - loss: 0.5343 - accuracy: 0.7239\n",
      "Epoch 220/1500\n",
      "9/9 [==============================] - 0s 790us/step - loss: 0.5314 - accuracy: 0.7295\n",
      "Epoch 221/1500\n",
      "9/9 [==============================] - 0s 653us/step - loss: 0.5344 - accuracy: 0.7239\n",
      "Epoch 222/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5310 - accuracy: 0.7257\n",
      "Epoch 223/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5301 - accuracy: 0.7313\n",
      "Epoch 224/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.5306 - accuracy: 0.7351\n",
      "Epoch 225/1500\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.5313 - accuracy: 0.7332\n",
      "Epoch 226/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5284 - accuracy: 0.7369\n",
      "Epoch 227/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5327 - accuracy: 0.7407\n",
      "Epoch 228/1500\n",
      "9/9 [==============================] - 0s 569us/step - loss: 0.5332 - accuracy: 0.7332\n",
      "Epoch 229/1500\n",
      "9/9 [==============================] - 0s 642us/step - loss: 0.5321 - accuracy: 0.7388\n",
      "Epoch 230/1500\n",
      "9/9 [==============================] - 0s 780us/step - loss: 0.5719 - accuracy: 0.7239\n",
      "Epoch 231/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5577 - accuracy: 0.7052\n",
      "Epoch 232/1500\n",
      "9/9 [==============================] - 0s 672us/step - loss: 0.5684 - accuracy: 0.6978\n",
      "Epoch 233/1500\n",
      "9/9 [==============================] - 0s 576us/step - loss: 0.5398 - accuracy: 0.7257\n",
      "Epoch 234/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5289 - accuracy: 0.7425\n",
      "Epoch 235/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5271 - accuracy: 0.7463\n",
      "Epoch 236/1500\n",
      "9/9 [==============================] - 0s 673us/step - loss: 0.5295 - accuracy: 0.7369\n",
      "Epoch 237/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5322 - accuracy: 0.7351\n",
      "Epoch 238/1500\n",
      "9/9 [==============================] - 0s 671us/step - loss: 0.5286 - accuracy: 0.7407\n",
      "Epoch 239/1500\n",
      "9/9 [==============================] - 0s 582us/step - loss: 0.5286 - accuracy: 0.7332\n",
      "Epoch 240/1500\n",
      "9/9 [==============================] - 0s 550us/step - loss: 0.5272 - accuracy: 0.7332\n",
      "Epoch 241/1500\n",
      "9/9 [==============================] - 0s 682us/step - loss: 0.5267 - accuracy: 0.7407\n",
      "Epoch 242/1500\n",
      "9/9 [==============================] - 0s 564us/step - loss: 0.5270 - accuracy: 0.7407\n",
      "Epoch 243/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.5254 - accuracy: 0.7407\n",
      "Epoch 244/1500\n",
      "9/9 [==============================] - 0s 563us/step - loss: 0.5268 - accuracy: 0.7444\n",
      "Epoch 245/1500\n",
      "9/9 [==============================] - 0s 766us/step - loss: 0.5273 - accuracy: 0.7425\n",
      "Epoch 246/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.5325 - accuracy: 0.7407\n",
      "Epoch 247/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.5247 - accuracy: 0.7276\n",
      "Epoch 248/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5274 - accuracy: 0.7407\n",
      "Epoch 249/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.5208 - accuracy: 0.7425\n",
      "Epoch 250/1500\n",
      "9/9 [==============================] - 0s 746us/step - loss: 0.5277 - accuracy: 0.7425\n",
      "Epoch 251/1500\n",
      "9/9 [==============================] - 0s 678us/step - loss: 0.5346 - accuracy: 0.7313\n",
      "Epoch 252/1500\n",
      "9/9 [==============================] - 0s 596us/step - loss: 0.5364 - accuracy: 0.7313\n",
      "Epoch 253/1500\n",
      "9/9 [==============================] - 0s 567us/step - loss: 0.5314 - accuracy: 0.7220\n",
      "Epoch 254/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5281 - accuracy: 0.7444\n",
      "Epoch 255/1500\n",
      "9/9 [==============================] - 0s 534us/step - loss: 0.5259 - accuracy: 0.7500\n",
      "Epoch 256/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.5276 - accuracy: 0.7407\n",
      "Epoch 257/1500\n",
      "9/9 [==============================] - 0s 583us/step - loss: 0.5424 - accuracy: 0.7351\n",
      "Epoch 258/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.5298 - accuracy: 0.7351\n",
      "Epoch 259/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5215 - accuracy: 0.7463\n",
      "Epoch 260/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5261 - accuracy: 0.7425\n",
      "Epoch 261/1500\n",
      "9/9 [==============================] - 0s 663us/step - loss: 0.5210 - accuracy: 0.7425\n",
      "Epoch 262/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5158 - accuracy: 0.7500\n",
      "Epoch 263/1500\n",
      "9/9 [==============================] - 0s 727us/step - loss: 0.5165 - accuracy: 0.7537\n",
      "Epoch 264/1500\n",
      "9/9 [==============================] - 0s 613us/step - loss: 0.5176 - accuracy: 0.7519\n",
      "Epoch 265/1500\n",
      "9/9 [==============================] - 0s 695us/step - loss: 0.5193 - accuracy: 0.7369\n",
      "Epoch 266/1500\n",
      "9/9 [==============================] - 0s 648us/step - loss: 0.5189 - accuracy: 0.7425\n",
      "Epoch 267/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5239 - accuracy: 0.7276\n",
      "Epoch 268/1500\n",
      "9/9 [==============================] - 0s 626us/step - loss: 0.5243 - accuracy: 0.7407\n",
      "Epoch 269/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.5179 - accuracy: 0.7407\n",
      "Epoch 270/1500\n",
      "9/9 [==============================] - 0s 671us/step - loss: 0.5216 - accuracy: 0.7463\n",
      "Epoch 271/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5181 - accuracy: 0.7593\n",
      "Epoch 272/1500\n",
      "9/9 [==============================] - 0s 690us/step - loss: 0.5229 - accuracy: 0.7463\n",
      "Epoch 273/1500\n",
      "9/9 [==============================] - 0s 551us/step - loss: 0.5316 - accuracy: 0.7369\n",
      "Epoch 274/1500\n",
      "9/9 [==============================] - 0s 743us/step - loss: 0.5181 - accuracy: 0.7351\n",
      "Epoch 275/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5229 - accuracy: 0.7575\n",
      "Epoch 276/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5159 - accuracy: 0.7500\n",
      "Epoch 277/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.5149 - accuracy: 0.7463\n",
      "Epoch 278/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5194 - accuracy: 0.7388\n",
      "Epoch 279/1500\n",
      "9/9 [==============================] - 0s 591us/step - loss: 0.5147 - accuracy: 0.7500\n",
      "Epoch 280/1500\n",
      "9/9 [==============================] - 0s 603us/step - loss: 0.5235 - accuracy: 0.7425\n",
      "Epoch 281/1500\n",
      "9/9 [==============================] - 0s 682us/step - loss: 0.5337 - accuracy: 0.7276\n",
      "Epoch 282/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.5158 - accuracy: 0.7556\n",
      "Epoch 283/1500\n",
      "9/9 [==============================] - 0s 664us/step - loss: 0.5196 - accuracy: 0.7612\n",
      "Epoch 284/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5174 - accuracy: 0.7388\n",
      "Epoch 285/1500\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.5121 - accuracy: 0.7537\n",
      "Epoch 286/1500\n",
      "9/9 [==============================] - 0s 581us/step - loss: 0.5209 - accuracy: 0.7444\n",
      "Epoch 287/1500\n",
      "9/9 [==============================] - 0s 723us/step - loss: 0.5289 - accuracy: 0.7463\n",
      "Epoch 288/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.5164 - accuracy: 0.7575\n",
      "Epoch 289/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5145 - accuracy: 0.7519\n",
      "Epoch 290/1500\n",
      "9/9 [==============================] - 0s 563us/step - loss: 0.5142 - accuracy: 0.7519\n",
      "Epoch 291/1500\n",
      "9/9 [==============================] - 0s 562us/step - loss: 0.5114 - accuracy: 0.7556\n",
      "Epoch 292/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5140 - accuracy: 0.7481\n",
      "Epoch 293/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5191 - accuracy: 0.7500\n",
      "Epoch 294/1500\n",
      "9/9 [==============================] - 0s 748us/step - loss: 0.5141 - accuracy: 0.7519\n",
      "Epoch 295/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.5101 - accuracy: 0.7556\n",
      "Epoch 296/1500\n",
      "9/9 [==============================] - 0s 670us/step - loss: 0.5130 - accuracy: 0.7444\n",
      "Epoch 297/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5129 - accuracy: 0.7500\n",
      "Epoch 298/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.5216 - accuracy: 0.7519\n",
      "Epoch 299/1500\n",
      "9/9 [==============================] - 0s 672us/step - loss: 0.5149 - accuracy: 0.7500\n",
      "Epoch 300/1500\n",
      "9/9 [==============================] - 0s 765us/step - loss: 0.5122 - accuracy: 0.7481\n",
      "Epoch 301/1500\n",
      "9/9 [==============================] - 0s 676us/step - loss: 0.5115 - accuracy: 0.7593\n",
      "Epoch 302/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.5086 - accuracy: 0.7575\n",
      "Epoch 303/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5100 - accuracy: 0.7519\n",
      "Epoch 304/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5100 - accuracy: 0.7537\n",
      "Epoch 305/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5159 - accuracy: 0.7519\n",
      "Epoch 306/1500\n",
      "9/9 [==============================] - 0s 481us/step - loss: 0.5097 - accuracy: 0.7463\n",
      "Epoch 307/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5145 - accuracy: 0.7668\n",
      "Epoch 308/1500\n",
      "9/9 [==============================] - 0s 521us/step - loss: 0.5102 - accuracy: 0.7612\n",
      "Epoch 309/1500\n",
      "9/9 [==============================] - 0s 681us/step - loss: 0.5161 - accuracy: 0.7481\n",
      "Epoch 310/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.5075 - accuracy: 0.7519\n",
      "Epoch 311/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.5075 - accuracy: 0.7687\n",
      "Epoch 312/1500\n",
      "9/9 [==============================] - 0s 555us/step - loss: 0.5076 - accuracy: 0.7537\n",
      "Epoch 313/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.5043 - accuracy: 0.7575\n",
      "Epoch 314/1500\n",
      "9/9 [==============================] - 0s 695us/step - loss: 0.5054 - accuracy: 0.7612\n",
      "Epoch 315/1500\n",
      "9/9 [==============================] - 0s 558us/step - loss: 0.5104 - accuracy: 0.7463\n",
      "Epoch 316/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5059 - accuracy: 0.7556\n",
      "Epoch 317/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5042 - accuracy: 0.7631\n",
      "Epoch 318/1500\n",
      "9/9 [==============================] - 0s 648us/step - loss: 0.5075 - accuracy: 0.7537\n",
      "Epoch 319/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5099 - accuracy: 0.7556\n",
      "Epoch 320/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.5143 - accuracy: 0.7537\n",
      "Epoch 321/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5075 - accuracy: 0.7463\n",
      "Epoch 322/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 665us/step - loss: 0.5136 - accuracy: 0.7481\n",
      "Epoch 323/1500\n",
      "9/9 [==============================] - 0s 573us/step - loss: 0.5085 - accuracy: 0.7481\n",
      "Epoch 324/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5094 - accuracy: 0.7668\n",
      "Epoch 325/1500\n",
      "9/9 [==============================] - 0s 798us/step - loss: 0.5026 - accuracy: 0.7668\n",
      "Epoch 326/1500\n",
      "9/9 [==============================] - 0s 719us/step - loss: 0.5168 - accuracy: 0.7519\n",
      "Epoch 327/1500\n",
      "9/9 [==============================] - 0s 674us/step - loss: 0.5068 - accuracy: 0.7519\n",
      "Epoch 328/1500\n",
      "9/9 [==============================] - 0s 546us/step - loss: 0.5064 - accuracy: 0.7612\n",
      "Epoch 329/1500\n",
      "9/9 [==============================] - 0s 721us/step - loss: 0.5049 - accuracy: 0.7593\n",
      "Epoch 330/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5044 - accuracy: 0.7593\n",
      "Epoch 331/1500\n",
      "9/9 [==============================] - 0s 684us/step - loss: 0.5026 - accuracy: 0.7556\n",
      "Epoch 332/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5096 - accuracy: 0.7556\n",
      "Epoch 333/1500\n",
      "9/9 [==============================] - 0s 546us/step - loss: 0.5048 - accuracy: 0.7575\n",
      "Epoch 334/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.5015 - accuracy: 0.7612\n",
      "Epoch 335/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.5019 - accuracy: 0.7649\n",
      "Epoch 336/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5025 - accuracy: 0.7519\n",
      "Epoch 337/1500\n",
      "9/9 [==============================] - 0s 544us/step - loss: 0.5048 - accuracy: 0.7612\n",
      "Epoch 338/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5080 - accuracy: 0.7537\n",
      "Epoch 339/1500\n",
      "9/9 [==============================] - 0s 549us/step - loss: 0.5053 - accuracy: 0.7519\n",
      "Epoch 340/1500\n",
      "9/9 [==============================] - 0s 670us/step - loss: 0.5037 - accuracy: 0.7687\n",
      "Epoch 341/1500\n",
      "9/9 [==============================] - 0s 540us/step - loss: 0.5012 - accuracy: 0.7687\n",
      "Epoch 342/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.5104 - accuracy: 0.7425\n",
      "Epoch 343/1500\n",
      "9/9 [==============================] - 0s 513us/step - loss: 0.5108 - accuracy: 0.7407\n",
      "Epoch 344/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5031 - accuracy: 0.7668\n",
      "Epoch 345/1500\n",
      "9/9 [==============================] - 0s 680us/step - loss: 0.5063 - accuracy: 0.7500\n",
      "Epoch 346/1500\n",
      "9/9 [==============================] - 0s 555us/step - loss: 0.4994 - accuracy: 0.7593\n",
      "Epoch 347/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5089 - accuracy: 0.7519\n",
      "Epoch 348/1500\n",
      "9/9 [==============================] - 0s 630us/step - loss: 0.5094 - accuracy: 0.7481\n",
      "Epoch 349/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.5103 - accuracy: 0.7537\n",
      "Epoch 350/1500\n",
      "9/9 [==============================] - 0s 561us/step - loss: 0.5034 - accuracy: 0.7463\n",
      "Epoch 351/1500\n",
      "9/9 [==============================] - 0s 562us/step - loss: 0.5075 - accuracy: 0.7575\n",
      "Epoch 352/1500\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.5036 - accuracy: 0.7481\n",
      "Epoch 353/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5014 - accuracy: 0.7593\n",
      "Epoch 354/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4987 - accuracy: 0.7556\n",
      "Epoch 355/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.5004 - accuracy: 0.7575\n",
      "Epoch 356/1500\n",
      "9/9 [==============================] - 0s 559us/step - loss: 0.4999 - accuracy: 0.7575\n",
      "Epoch 357/1500\n",
      "9/9 [==============================] - 0s 671us/step - loss: 0.5052 - accuracy: 0.7593\n",
      "Epoch 358/1500\n",
      "9/9 [==============================] - 0s 683us/step - loss: 0.5111 - accuracy: 0.7463\n",
      "Epoch 359/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5066 - accuracy: 0.7481\n",
      "Epoch 360/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.5024 - accuracy: 0.7575\n",
      "Epoch 361/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5010 - accuracy: 0.7575\n",
      "Epoch 362/1500\n",
      "9/9 [==============================] - 0s 628us/step - loss: 0.4981 - accuracy: 0.7631\n",
      "Epoch 363/1500\n",
      "9/9 [==============================] - 0s 686us/step - loss: 0.4977 - accuracy: 0.7612\n",
      "Epoch 364/1500\n",
      "9/9 [==============================] - 0s 559us/step - loss: 0.5088 - accuracy: 0.7519\n",
      "Epoch 365/1500\n",
      "9/9 [==============================] - 0s 716us/step - loss: 0.5094 - accuracy: 0.7556\n",
      "Epoch 366/1500\n",
      "9/9 [==============================] - 0s 768us/step - loss: 0.5038 - accuracy: 0.7519\n",
      "Epoch 367/1500\n",
      "9/9 [==============================] - 0s 607us/step - loss: 0.4956 - accuracy: 0.7575\n",
      "Epoch 368/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4968 - accuracy: 0.7612\n",
      "Epoch 369/1500\n",
      "9/9 [==============================] - 0s 756us/step - loss: 0.4970 - accuracy: 0.7631\n",
      "Epoch 370/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4967 - accuracy: 0.7575\n",
      "Epoch 371/1500\n",
      "9/9 [==============================] - 0s 591us/step - loss: 0.4963 - accuracy: 0.7668\n",
      "Epoch 372/1500\n",
      "9/9 [==============================] - 0s 548us/step - loss: 0.4991 - accuracy: 0.7463\n",
      "Epoch 373/1500\n",
      "9/9 [==============================] - 0s 698us/step - loss: 0.4983 - accuracy: 0.7649\n",
      "Epoch 374/1500\n",
      "9/9 [==============================] - 0s 565us/step - loss: 0.4972 - accuracy: 0.7556\n",
      "Epoch 375/1500\n",
      "9/9 [==============================] - 0s 552us/step - loss: 0.5055 - accuracy: 0.7556\n",
      "Epoch 376/1500\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.5061 - accuracy: 0.7593\n",
      "Epoch 377/1500\n",
      "9/9 [==============================] - 0s 585us/step - loss: 0.5014 - accuracy: 0.7537\n",
      "Epoch 378/1500\n",
      "9/9 [==============================] - 0s 650us/step - loss: 0.4964 - accuracy: 0.7500\n",
      "Epoch 379/1500\n",
      "9/9 [==============================] - 0s 682us/step - loss: 0.5012 - accuracy: 0.7631\n",
      "Epoch 380/1500\n",
      "9/9 [==============================] - 0s 605us/step - loss: 0.4965 - accuracy: 0.7649\n",
      "Epoch 381/1500\n",
      "9/9 [==============================] - 0s 650us/step - loss: 0.4970 - accuracy: 0.7631\n",
      "Epoch 382/1500\n",
      "9/9 [==============================] - 0s 664us/step - loss: 0.5036 - accuracy: 0.7593\n",
      "Epoch 383/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.4981 - accuracy: 0.7649\n",
      "Epoch 384/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4984 - accuracy: 0.7481\n",
      "Epoch 385/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.4957 - accuracy: 0.7556\n",
      "Epoch 386/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4939 - accuracy: 0.7649\n",
      "Epoch 387/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.4981 - accuracy: 0.7612\n",
      "Epoch 388/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.4979 - accuracy: 0.7575\n",
      "Epoch 389/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.5046 - accuracy: 0.7332\n",
      "Epoch 390/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.5435 - accuracy: 0.7276\n",
      "Epoch 391/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5019 - accuracy: 0.7556\n",
      "Epoch 392/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4954 - accuracy: 0.7612\n",
      "Epoch 393/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4969 - accuracy: 0.7593\n",
      "Epoch 394/1500\n",
      "9/9 [==============================] - 0s 621us/step - loss: 0.5055 - accuracy: 0.7649\n",
      "Epoch 395/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5031 - accuracy: 0.7463\n",
      "Epoch 396/1500\n",
      "9/9 [==============================] - 0s 672us/step - loss: 0.4947 - accuracy: 0.7537\n",
      "Epoch 397/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4994 - accuracy: 0.7575\n",
      "Epoch 398/1500\n",
      "9/9 [==============================] - 0s 626us/step - loss: 0.4952 - accuracy: 0.7556\n",
      "Epoch 399/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.4977 - accuracy: 0.7612\n",
      "Epoch 400/1500\n",
      "9/9 [==============================] - 0s 610us/step - loss: 0.4999 - accuracy: 0.7593\n",
      "Epoch 401/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.4921 - accuracy: 0.7649\n",
      "Epoch 402/1500\n",
      "9/9 [==============================] - 0s 718us/step - loss: 0.4978 - accuracy: 0.7612\n",
      "Epoch 403/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.5145 - accuracy: 0.7537\n",
      "Epoch 404/1500\n",
      "9/9 [==============================] - 0s 691us/step - loss: 0.5133 - accuracy: 0.7444\n",
      "Epoch 405/1500\n",
      "9/9 [==============================] - 0s 635us/step - loss: 0.4926 - accuracy: 0.7631\n",
      "Epoch 406/1500\n",
      "9/9 [==============================] - 0s 635us/step - loss: 0.4983 - accuracy: 0.7556\n",
      "Epoch 407/1500\n",
      "9/9 [==============================] - 0s 663us/step - loss: 0.4947 - accuracy: 0.7668\n",
      "Epoch 408/1500\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.4928 - accuracy: 0.7593\n",
      "Epoch 409/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4907 - accuracy: 0.7612\n",
      "Epoch 410/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4903 - accuracy: 0.7705\n",
      "Epoch 411/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4933 - accuracy: 0.7649\n",
      "Epoch 412/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.4906 - accuracy: 0.7724\n",
      "Epoch 413/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4881 - accuracy: 0.7705\n",
      "Epoch 414/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.4885 - accuracy: 0.7649\n",
      "Epoch 415/1500\n",
      "9/9 [==============================] - 0s 756us/step - loss: 0.4902 - accuracy: 0.7649\n",
      "Epoch 416/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4887 - accuracy: 0.7687\n",
      "Epoch 417/1500\n",
      "9/9 [==============================] - 0s 626us/step - loss: 0.4898 - accuracy: 0.7631\n",
      "Epoch 418/1500\n",
      "9/9 [==============================] - 0s 687us/step - loss: 0.4971 - accuracy: 0.7575\n",
      "Epoch 419/1500\n",
      "9/9 [==============================] - 0s 716us/step - loss: 0.4975 - accuracy: 0.7612\n",
      "Epoch 420/1500\n",
      "9/9 [==============================] - 0s 517us/step - loss: 0.5014 - accuracy: 0.7575\n",
      "Epoch 421/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.4895 - accuracy: 0.7687\n",
      "Epoch 422/1500\n",
      "9/9 [==============================] - 0s 610us/step - loss: 0.4891 - accuracy: 0.7705\n",
      "Epoch 423/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4897 - accuracy: 0.7705\n",
      "Epoch 424/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4885 - accuracy: 0.7743\n",
      "Epoch 425/1500\n",
      "9/9 [==============================] - 0s 652us/step - loss: 0.4906 - accuracy: 0.7687\n",
      "Epoch 426/1500\n",
      "9/9 [==============================] - 0s 707us/step - loss: 0.5092 - accuracy: 0.7556\n",
      "Epoch 427/1500\n",
      "9/9 [==============================] - 0s 559us/step - loss: 0.5012 - accuracy: 0.7519\n",
      "Epoch 428/1500\n",
      "9/9 [==============================] - 0s 641us/step - loss: 0.4974 - accuracy: 0.7668\n",
      "Epoch 429/1500\n",
      "9/9 [==============================] - 0s 605us/step - loss: 0.4969 - accuracy: 0.7556\n",
      "Epoch 430/1500\n",
      "9/9 [==============================] - 0s 663us/step - loss: 0.4973 - accuracy: 0.7575\n",
      "Epoch 431/1500\n",
      "9/9 [==============================] - 0s 651us/step - loss: 0.4928 - accuracy: 0.7687\n",
      "Epoch 432/1500\n",
      "9/9 [==============================] - 0s 767us/step - loss: 0.4953 - accuracy: 0.7519\n",
      "Epoch 433/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4890 - accuracy: 0.7649\n",
      "Epoch 434/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5016 - accuracy: 0.7537\n",
      "Epoch 435/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4887 - accuracy: 0.7631\n",
      "Epoch 436/1500\n",
      "9/9 [==============================] - 0s 561us/step - loss: 0.4891 - accuracy: 0.7668\n",
      "Epoch 437/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5015 - accuracy: 0.7556\n",
      "Epoch 438/1500\n",
      "9/9 [==============================] - 0s 605us/step - loss: 0.4891 - accuracy: 0.7687\n",
      "Epoch 439/1500\n",
      "9/9 [==============================] - 0s 653us/step - loss: 0.4891 - accuracy: 0.7668\n",
      "Epoch 440/1500\n",
      "9/9 [==============================] - 0s 764us/step - loss: 0.4912 - accuracy: 0.7631\n",
      "Epoch 441/1500\n",
      "9/9 [==============================] - 0s 677us/step - loss: 0.4897 - accuracy: 0.7631\n",
      "Epoch 442/1500\n",
      "9/9 [==============================] - 0s 675us/step - loss: 0.4934 - accuracy: 0.7631\n",
      "Epoch 443/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4899 - accuracy: 0.7817\n",
      "Epoch 444/1500\n",
      "9/9 [==============================] - 0s 590us/step - loss: 0.4973 - accuracy: 0.7612\n",
      "Epoch 445/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4957 - accuracy: 0.7537\n",
      "Epoch 446/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4906 - accuracy: 0.7649\n",
      "Epoch 447/1500\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.4866 - accuracy: 0.7687\n",
      "Epoch 448/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.4860 - accuracy: 0.7743\n",
      "Epoch 449/1500\n",
      "9/9 [==============================] - 0s 632us/step - loss: 0.4910 - accuracy: 0.7668\n",
      "Epoch 450/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.4854 - accuracy: 0.7705\n",
      "Epoch 451/1500\n",
      "9/9 [==============================] - 0s 649us/step - loss: 0.4846 - accuracy: 0.7687\n",
      "Epoch 452/1500\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.4963 - accuracy: 0.7631\n",
      "Epoch 453/1500\n",
      "9/9 [==============================] - 0s 633us/step - loss: 0.4808 - accuracy: 0.7612\n",
      "Epoch 454/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.4866 - accuracy: 0.7687\n",
      "Epoch 455/1500\n",
      "9/9 [==============================] - 0s 535us/step - loss: 0.4881 - accuracy: 0.7743\n",
      "Epoch 456/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4871 - accuracy: 0.7668\n",
      "Epoch 457/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4902 - accuracy: 0.7612\n",
      "Epoch 458/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4916 - accuracy: 0.7687\n",
      "Epoch 459/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.4839 - accuracy: 0.7705\n",
      "Epoch 460/1500\n",
      "9/9 [==============================] - 0s 546us/step - loss: 0.4848 - accuracy: 0.7631\n",
      "Epoch 461/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4882 - accuracy: 0.7556\n",
      "Epoch 462/1500\n",
      "9/9 [==============================] - 0s 722us/step - loss: 0.4862 - accuracy: 0.7537\n",
      "Epoch 463/1500\n",
      "9/9 [==============================] - 0s 652us/step - loss: 0.4822 - accuracy: 0.7687\n",
      "Epoch 464/1500\n",
      "9/9 [==============================] - 0s 673us/step - loss: 0.4878 - accuracy: 0.7649\n",
      "Epoch 465/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4840 - accuracy: 0.7687\n",
      "Epoch 466/1500\n",
      "9/9 [==============================] - 0s 717us/step - loss: 0.4901 - accuracy: 0.7631\n",
      "Epoch 467/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4865 - accuracy: 0.7612\n",
      "Epoch 468/1500\n",
      "9/9 [==============================] - 0s 707us/step - loss: 0.5002 - accuracy: 0.7519\n",
      "Epoch 469/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5120 - accuracy: 0.7519\n",
      "Epoch 470/1500\n",
      "9/9 [==============================] - 0s 553us/step - loss: 0.4967 - accuracy: 0.7537\n",
      "Epoch 471/1500\n",
      "9/9 [==============================] - 0s 641us/step - loss: 0.4885 - accuracy: 0.7649\n",
      "Epoch 472/1500\n",
      "9/9 [==============================] - 0s 768us/step - loss: 0.4830 - accuracy: 0.7743\n",
      "Epoch 473/1500\n",
      "9/9 [==============================] - 0s 652us/step - loss: 0.4801 - accuracy: 0.7705\n",
      "Epoch 474/1500\n",
      "9/9 [==============================] - 0s 673us/step - loss: 0.4806 - accuracy: 0.7631\n",
      "Epoch 475/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4832 - accuracy: 0.7705\n",
      "Epoch 476/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4824 - accuracy: 0.7743\n",
      "Epoch 477/1500\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.4842 - accuracy: 0.7687\n",
      "Epoch 478/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4908 - accuracy: 0.7631\n",
      "Epoch 479/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5027 - accuracy: 0.7556\n",
      "Epoch 480/1500\n",
      "9/9 [==============================] - 0s 510us/step - loss: 0.4890 - accuracy: 0.7556\n",
      "Epoch 481/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4826 - accuracy: 0.7724\n",
      "Epoch 482/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 598us/step - loss: 0.4840 - accuracy: 0.7705\n",
      "Epoch 483/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4798 - accuracy: 0.7724\n",
      "Epoch 484/1500\n",
      "9/9 [==============================] - 0s 728us/step - loss: 0.4803 - accuracy: 0.7724\n",
      "Epoch 485/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4828 - accuracy: 0.7705\n",
      "Epoch 486/1500\n",
      "9/9 [==============================] - 0s 742us/step - loss: 0.4794 - accuracy: 0.7649\n",
      "Epoch 487/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4841 - accuracy: 0.7687\n",
      "Epoch 488/1500\n",
      "9/9 [==============================] - 0s 603us/step - loss: 0.4811 - accuracy: 0.7743\n",
      "Epoch 489/1500\n",
      "9/9 [==============================] - 0s 596us/step - loss: 0.4800 - accuracy: 0.7705\n",
      "Epoch 490/1500\n",
      "9/9 [==============================] - 0s 663us/step - loss: 0.4781 - accuracy: 0.7687\n",
      "Epoch 491/1500\n",
      "9/9 [==============================] - 0s 630us/step - loss: 0.4784 - accuracy: 0.7668\n",
      "Epoch 492/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4808 - accuracy: 0.7649\n",
      "Epoch 493/1500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.4789 - accuracy: 0.7705\n",
      "Epoch 494/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4913 - accuracy: 0.7649\n",
      "Epoch 495/1500\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.4848 - accuracy: 0.7575\n",
      "Epoch 496/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4865 - accuracy: 0.7743\n",
      "Epoch 497/1500\n",
      "9/9 [==============================] - 0s 640us/step - loss: 0.4840 - accuracy: 0.7705\n",
      "Epoch 498/1500\n",
      "9/9 [==============================] - 0s 653us/step - loss: 0.4776 - accuracy: 0.7780\n",
      "Epoch 499/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4786 - accuracy: 0.7761\n",
      "Epoch 500/1500\n",
      "9/9 [==============================] - 0s 631us/step - loss: 0.4838 - accuracy: 0.7724\n",
      "Epoch 501/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4789 - accuracy: 0.7743\n",
      "Epoch 502/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4787 - accuracy: 0.7631\n",
      "Epoch 503/1500\n",
      "9/9 [==============================] - 0s 664us/step - loss: 0.4909 - accuracy: 0.7780\n",
      "Epoch 504/1500\n",
      "9/9 [==============================] - 0s 555us/step - loss: 0.4899 - accuracy: 0.7687\n",
      "Epoch 505/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4837 - accuracy: 0.7687\n",
      "Epoch 506/1500\n",
      "9/9 [==============================] - 0s 616us/step - loss: 0.4787 - accuracy: 0.7687\n",
      "Epoch 507/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4773 - accuracy: 0.7817\n",
      "Epoch 508/1500\n",
      "9/9 [==============================] - 0s 616us/step - loss: 0.4784 - accuracy: 0.7799\n",
      "Epoch 509/1500\n",
      "9/9 [==============================] - 0s 673us/step - loss: 0.4796 - accuracy: 0.7649\n",
      "Epoch 510/1500\n",
      "9/9 [==============================] - 0s 687us/step - loss: 0.4846 - accuracy: 0.7743\n",
      "Epoch 511/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4849 - accuracy: 0.7575\n",
      "Epoch 512/1500\n",
      "9/9 [==============================] - 0s 700us/step - loss: 0.4770 - accuracy: 0.7743\n",
      "Epoch 513/1500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.4819 - accuracy: 0.7761\n",
      "Epoch 514/1500\n",
      "9/9 [==============================] - 0s 676us/step - loss: 0.4826 - accuracy: 0.7817\n",
      "Epoch 515/1500\n",
      "9/9 [==============================] - 0s 562us/step - loss: 0.4985 - accuracy: 0.7463\n",
      "Epoch 516/1500\n",
      "9/9 [==============================] - 0s 771us/step - loss: 0.4948 - accuracy: 0.7649\n",
      "Epoch 517/1500\n",
      "9/9 [==============================] - 0s 662us/step - loss: 0.4826 - accuracy: 0.7687\n",
      "Epoch 518/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4772 - accuracy: 0.7705\n",
      "Epoch 519/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4843 - accuracy: 0.7687\n",
      "Epoch 520/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.5054 - accuracy: 0.7537\n",
      "Epoch 521/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4763 - accuracy: 0.7873\n",
      "Epoch 522/1500\n",
      "9/9 [==============================] - 0s 772us/step - loss: 0.4816 - accuracy: 0.7743\n",
      "Epoch 523/1500\n",
      "9/9 [==============================] - 0s 788us/step - loss: 0.4881 - accuracy: 0.7612\n",
      "Epoch 524/1500\n",
      "9/9 [==============================] - 0s 599us/step - loss: 0.4814 - accuracy: 0.7724\n",
      "Epoch 525/1500\n",
      "9/9 [==============================] - 0s 672us/step - loss: 0.4739 - accuracy: 0.7724\n",
      "Epoch 526/1500\n",
      "9/9 [==============================] - 0s 557us/step - loss: 0.4829 - accuracy: 0.7556\n",
      "Epoch 527/1500\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.4866 - accuracy: 0.7724\n",
      "Epoch 528/1500\n",
      "9/9 [==============================] - 0s 641us/step - loss: 0.4763 - accuracy: 0.7761\n",
      "Epoch 529/1500\n",
      "9/9 [==============================] - 0s 722us/step - loss: 0.4861 - accuracy: 0.7612\n",
      "Epoch 530/1500\n",
      "9/9 [==============================] - 0s 632us/step - loss: 0.4813 - accuracy: 0.7761\n",
      "Epoch 531/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4830 - accuracy: 0.7724\n",
      "Epoch 532/1500\n",
      "9/9 [==============================] - 0s 558us/step - loss: 0.4884 - accuracy: 0.7687\n",
      "Epoch 533/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.4800 - accuracy: 0.7649\n",
      "Epoch 534/1500\n",
      "9/9 [==============================] - 0s 650us/step - loss: 0.4812 - accuracy: 0.7687\n",
      "Epoch 535/1500\n",
      "9/9 [==============================] - 0s 662us/step - loss: 0.4833 - accuracy: 0.7761\n",
      "Epoch 536/1500\n",
      "9/9 [==============================] - 0s 706us/step - loss: 0.4898 - accuracy: 0.7687\n",
      "Epoch 537/1500\n",
      "9/9 [==============================] - 0s 565us/step - loss: 0.4813 - accuracy: 0.7743\n",
      "Epoch 538/1500\n",
      "9/9 [==============================] - 0s 725us/step - loss: 0.4777 - accuracy: 0.7687\n",
      "Epoch 539/1500\n",
      "9/9 [==============================] - 0s 645us/step - loss: 0.4714 - accuracy: 0.7761\n",
      "Epoch 540/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4789 - accuracy: 0.7687\n",
      "Epoch 541/1500\n",
      "9/9 [==============================] - 0s 531us/step - loss: 0.4825 - accuracy: 0.7593\n",
      "Epoch 542/1500\n",
      "9/9 [==============================] - 0s 540us/step - loss: 0.4765 - accuracy: 0.7724\n",
      "Epoch 543/1500\n",
      "9/9 [==============================] - 0s 725us/step - loss: 0.4767 - accuracy: 0.7780\n",
      "Epoch 544/1500\n",
      "9/9 [==============================] - 0s 674us/step - loss: 0.4738 - accuracy: 0.7817\n",
      "Epoch 545/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4769 - accuracy: 0.7724\n",
      "Epoch 546/1500\n",
      "9/9 [==============================] - 0s 558us/step - loss: 0.4797 - accuracy: 0.7780\n",
      "Epoch 547/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4758 - accuracy: 0.7836\n",
      "Epoch 548/1500\n",
      "9/9 [==============================] - 0s 712us/step - loss: 0.4742 - accuracy: 0.7593\n",
      "Epoch 549/1500\n",
      "9/9 [==============================] - 0s 681us/step - loss: 0.4743 - accuracy: 0.7854\n",
      "Epoch 550/1500\n",
      "9/9 [==============================] - 0s 676us/step - loss: 0.4812 - accuracy: 0.7668\n",
      "Epoch 551/1500\n",
      "9/9 [==============================] - 0s 653us/step - loss: 0.4849 - accuracy: 0.7854\n",
      "Epoch 552/1500\n",
      "9/9 [==============================] - 0s 632us/step - loss: 0.4794 - accuracy: 0.7705\n",
      "Epoch 553/1500\n",
      "9/9 [==============================] - 0s 663us/step - loss: 0.4785 - accuracy: 0.7743\n",
      "Epoch 554/1500\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.4724 - accuracy: 0.7743\n",
      "Epoch 555/1500\n",
      "9/9 [==============================] - 0s 670us/step - loss: 0.4769 - accuracy: 0.7668\n",
      "Epoch 556/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.4823 - accuracy: 0.7705\n",
      "Epoch 557/1500\n",
      "9/9 [==============================] - 0s 680us/step - loss: 0.4821 - accuracy: 0.7705\n",
      "Epoch 558/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.4742 - accuracy: 0.7761\n",
      "Epoch 559/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4725 - accuracy: 0.7817\n",
      "Epoch 560/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.4785 - accuracy: 0.7780\n",
      "Epoch 561/1500\n",
      "9/9 [==============================] - 0s 575us/step - loss: 0.4776 - accuracy: 0.7854\n",
      "Epoch 562/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4739 - accuracy: 0.7649\n",
      "Epoch 563/1500\n",
      "9/9 [==============================] - 0s 767us/step - loss: 0.4826 - accuracy: 0.7873\n",
      "Epoch 564/1500\n",
      "9/9 [==============================] - 0s 563us/step - loss: 0.4835 - accuracy: 0.7705\n",
      "Epoch 565/1500\n",
      "9/9 [==============================] - 0s 720us/step - loss: 0.4796 - accuracy: 0.7649\n",
      "Epoch 566/1500\n",
      "9/9 [==============================] - 0s 651us/step - loss: 0.4721 - accuracy: 0.7780\n",
      "Epoch 567/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4720 - accuracy: 0.7724\n",
      "Epoch 568/1500\n",
      "9/9 [==============================] - 0s 548us/step - loss: 0.4745 - accuracy: 0.7780\n",
      "Epoch 569/1500\n",
      "9/9 [==============================] - 0s 730us/step - loss: 0.4756 - accuracy: 0.7743\n",
      "Epoch 570/1500\n",
      "9/9 [==============================] - 0s 484us/step - loss: 0.4720 - accuracy: 0.7780\n",
      "Epoch 571/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4738 - accuracy: 0.7705\n",
      "Epoch 572/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4783 - accuracy: 0.7761\n",
      "Epoch 573/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4766 - accuracy: 0.7780\n",
      "Epoch 574/1500\n",
      "9/9 [==============================] - 0s 653us/step - loss: 0.4726 - accuracy: 0.7892\n",
      "Epoch 575/1500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.4697 - accuracy: 0.7799\n",
      "Epoch 576/1500\n",
      "9/9 [==============================] - 0s 570us/step - loss: 0.4699 - accuracy: 0.7799\n",
      "Epoch 577/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4707 - accuracy: 0.7780\n",
      "Epoch 578/1500\n",
      "9/9 [==============================] - 0s 638us/step - loss: 0.4742 - accuracy: 0.7854\n",
      "Epoch 579/1500\n",
      "9/9 [==============================] - 0s 542us/step - loss: 0.4664 - accuracy: 0.7780\n",
      "Epoch 580/1500\n",
      "9/9 [==============================] - 0s 716us/step - loss: 0.4770 - accuracy: 0.7761\n",
      "Epoch 581/1500\n",
      "9/9 [==============================] - 0s 574us/step - loss: 0.4813 - accuracy: 0.7724\n",
      "Epoch 582/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4705 - accuracy: 0.7761\n",
      "Epoch 583/1500\n",
      "9/9 [==============================] - 0s 692us/step - loss: 0.4720 - accuracy: 0.7687\n",
      "Epoch 584/1500\n",
      "9/9 [==============================] - 0s 726us/step - loss: 0.4726 - accuracy: 0.7780\n",
      "Epoch 585/1500\n",
      "9/9 [==============================] - 0s 640us/step - loss: 0.4707 - accuracy: 0.7799\n",
      "Epoch 586/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4776 - accuracy: 0.7743\n",
      "Epoch 587/1500\n",
      "9/9 [==============================] - 0s 691us/step - loss: 0.4785 - accuracy: 0.7780\n",
      "Epoch 588/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4786 - accuracy: 0.7743\n",
      "Epoch 589/1500\n",
      "9/9 [==============================] - 0s 754us/step - loss: 0.4788 - accuracy: 0.7966\n",
      "Epoch 590/1500\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.4836 - accuracy: 0.7705\n",
      "Epoch 591/1500\n",
      "9/9 [==============================] - 0s 726us/step - loss: 0.4791 - accuracy: 0.7743\n",
      "Epoch 592/1500\n",
      "9/9 [==============================] - 0s 551us/step - loss: 0.5046 - accuracy: 0.7556\n",
      "Epoch 593/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.5469 - accuracy: 0.7444\n",
      "Epoch 594/1500\n",
      "9/9 [==============================] - 0s 579us/step - loss: 0.4856 - accuracy: 0.7705\n",
      "Epoch 595/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4815 - accuracy: 0.7668\n",
      "Epoch 596/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4704 - accuracy: 0.7836\n",
      "Epoch 597/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.4774 - accuracy: 0.7761\n",
      "Epoch 598/1500\n",
      "9/9 [==============================] - 0s 735us/step - loss: 0.4713 - accuracy: 0.7649\n",
      "Epoch 599/1500\n",
      "9/9 [==============================] - 0s 693us/step - loss: 0.4681 - accuracy: 0.7854\n",
      "Epoch 600/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4726 - accuracy: 0.7854\n",
      "Epoch 601/1500\n",
      "9/9 [==============================] - 0s 632us/step - loss: 0.4710 - accuracy: 0.7724\n",
      "Epoch 602/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4771 - accuracy: 0.7817\n",
      "Epoch 603/1500\n",
      "9/9 [==============================] - 0s 464us/step - loss: 0.4693 - accuracy: 0.7892\n",
      "Epoch 604/1500\n",
      "9/9 [==============================] - 0s 569us/step - loss: 0.4790 - accuracy: 0.7705\n",
      "Epoch 605/1500\n",
      "9/9 [==============================] - 0s 640us/step - loss: 0.4725 - accuracy: 0.7892\n",
      "Epoch 606/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.4713 - accuracy: 0.7892\n",
      "Epoch 607/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4777 - accuracy: 0.7780\n",
      "Epoch 608/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.4720 - accuracy: 0.7799\n",
      "Epoch 609/1500\n",
      "9/9 [==============================] - 0s 588us/step - loss: 0.4721 - accuracy: 0.7724\n",
      "Epoch 610/1500\n",
      "9/9 [==============================] - 0s 602us/step - loss: 0.4825 - accuracy: 0.7799\n",
      "Epoch 611/1500\n",
      "9/9 [==============================] - 0s 670us/step - loss: 0.4710 - accuracy: 0.7761\n",
      "Epoch 612/1500\n",
      "9/9 [==============================] - 0s 628us/step - loss: 0.4685 - accuracy: 0.7799\n",
      "Epoch 613/1500\n",
      "9/9 [==============================] - 0s 550us/step - loss: 0.4719 - accuracy: 0.7799\n",
      "Epoch 614/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4671 - accuracy: 0.7761\n",
      "Epoch 615/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4679 - accuracy: 0.7705\n",
      "Epoch 616/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4670 - accuracy: 0.7966\n",
      "Epoch 617/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4682 - accuracy: 0.7836\n",
      "Epoch 618/1500\n",
      "9/9 [==============================] - 0s 617us/step - loss: 0.4643 - accuracy: 0.7836\n",
      "Epoch 619/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4682 - accuracy: 0.7854\n",
      "Epoch 620/1500\n",
      "9/9 [==============================] - 0s 671us/step - loss: 0.4701 - accuracy: 0.7743\n",
      "Epoch 621/1500\n",
      "9/9 [==============================] - 0s 543us/step - loss: 0.4658 - accuracy: 0.7948\n",
      "Epoch 622/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.4715 - accuracy: 0.7743\n",
      "Epoch 623/1500\n",
      "9/9 [==============================] - 0s 521us/step - loss: 0.4729 - accuracy: 0.7687\n",
      "Epoch 624/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4663 - accuracy: 0.7799\n",
      "Epoch 625/1500\n",
      "9/9 [==============================] - 0s 662us/step - loss: 0.4660 - accuracy: 0.7817\n",
      "Epoch 626/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.4652 - accuracy: 0.7817\n",
      "Epoch 627/1500\n",
      "9/9 [==============================] - 0s 608us/step - loss: 0.4670 - accuracy: 0.7873\n",
      "Epoch 628/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.4710 - accuracy: 0.7761\n",
      "Epoch 629/1500\n",
      "9/9 [==============================] - 0s 655us/step - loss: 0.4764 - accuracy: 0.7575\n",
      "Epoch 630/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4835 - accuracy: 0.7687\n",
      "Epoch 631/1500\n",
      "9/9 [==============================] - 0s 707us/step - loss: 0.4687 - accuracy: 0.7724\n",
      "Epoch 632/1500\n",
      "9/9 [==============================] - 0s 730us/step - loss: 0.4713 - accuracy: 0.7873\n",
      "Epoch 633/1500\n",
      "9/9 [==============================] - 0s 678us/step - loss: 0.4676 - accuracy: 0.7743\n",
      "Epoch 634/1500\n",
      "9/9 [==============================] - 0s 631us/step - loss: 0.4772 - accuracy: 0.7780\n",
      "Epoch 635/1500\n",
      "9/9 [==============================] - 0s 655us/step - loss: 0.4766 - accuracy: 0.7761\n",
      "Epoch 636/1500\n",
      "9/9 [==============================] - 0s 588us/step - loss: 0.4676 - accuracy: 0.7761\n",
      "Epoch 637/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4672 - accuracy: 0.7892\n",
      "Epoch 638/1500\n",
      "9/9 [==============================] - 0s 585us/step - loss: 0.4699 - accuracy: 0.7724\n",
      "Epoch 639/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4691 - accuracy: 0.7799\n",
      "Epoch 640/1500\n",
      "9/9 [==============================] - 0s 597us/step - loss: 0.4720 - accuracy: 0.7854\n",
      "Epoch 641/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4726 - accuracy: 0.7836\n",
      "Epoch 642/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 665us/step - loss: 0.4694 - accuracy: 0.7743\n",
      "Epoch 643/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4658 - accuracy: 0.7910\n",
      "Epoch 644/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4641 - accuracy: 0.7799\n",
      "Epoch 645/1500\n",
      "9/9 [==============================] - 0s 631us/step - loss: 0.4645 - accuracy: 0.7929\n",
      "Epoch 646/1500\n",
      "9/9 [==============================] - 0s 731us/step - loss: 0.4640 - accuracy: 0.7854\n",
      "Epoch 647/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4672 - accuracy: 0.7780\n",
      "Epoch 648/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4668 - accuracy: 0.7873\n",
      "Epoch 649/1500\n",
      "9/9 [==============================] - 0s 639us/step - loss: 0.4777 - accuracy: 0.7724\n",
      "Epoch 650/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4792 - accuracy: 0.7724\n",
      "Epoch 651/1500\n",
      "9/9 [==============================] - 0s 699us/step - loss: 0.4701 - accuracy: 0.7780\n",
      "Epoch 652/1500\n",
      "9/9 [==============================] - 0s 737us/step - loss: 0.4796 - accuracy: 0.7687\n",
      "Epoch 653/1500\n",
      "9/9 [==============================] - 0s 634us/step - loss: 0.4744 - accuracy: 0.7799\n",
      "Epoch 654/1500\n",
      "9/9 [==============================] - 0s 679us/step - loss: 0.4721 - accuracy: 0.7761\n",
      "Epoch 655/1500\n",
      "9/9 [==============================] - 0s 761us/step - loss: 0.4633 - accuracy: 0.7892\n",
      "Epoch 656/1500\n",
      "9/9 [==============================] - 0s 601us/step - loss: 0.4629 - accuracy: 0.7854\n",
      "Epoch 657/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4614 - accuracy: 0.7836\n",
      "Epoch 658/1500\n",
      "9/9 [==============================] - 0s 581us/step - loss: 0.4622 - accuracy: 0.7836\n",
      "Epoch 659/1500\n",
      "9/9 [==============================] - 0s 726us/step - loss: 0.4676 - accuracy: 0.7836\n",
      "Epoch 660/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.4631 - accuracy: 0.7780\n",
      "Epoch 661/1500\n",
      "9/9 [==============================] - 0s 662us/step - loss: 0.4617 - accuracy: 0.7836\n",
      "Epoch 662/1500\n",
      "9/9 [==============================] - 0s 546us/step - loss: 0.4680 - accuracy: 0.7761\n",
      "Epoch 663/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4616 - accuracy: 0.7836\n",
      "Epoch 664/1500\n",
      "9/9 [==============================] - 0s 740us/step - loss: 0.4641 - accuracy: 0.7817\n",
      "Epoch 665/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4641 - accuracy: 0.7724\n",
      "Epoch 666/1500\n",
      "9/9 [==============================] - 0s 783us/step - loss: 0.4611 - accuracy: 0.7761\n",
      "Epoch 667/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.4604 - accuracy: 0.7854\n",
      "Epoch 668/1500\n",
      "9/9 [==============================] - 0s 694us/step - loss: 0.4615 - accuracy: 0.7873\n",
      "Epoch 669/1500\n",
      "9/9 [==============================] - 0s 627us/step - loss: 0.4723 - accuracy: 0.7724\n",
      "Epoch 670/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4674 - accuracy: 0.7948\n",
      "Epoch 671/1500\n",
      "9/9 [==============================] - 0s 684us/step - loss: 0.4731 - accuracy: 0.7687\n",
      "Epoch 672/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4668 - accuracy: 0.7854\n",
      "Epoch 673/1500\n",
      "9/9 [==============================] - 0s 621us/step - loss: 0.4661 - accuracy: 0.8060\n",
      "Epoch 674/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4648 - accuracy: 0.7817\n",
      "Epoch 675/1500\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.4739 - accuracy: 0.7854\n",
      "Epoch 676/1500\n",
      "9/9 [==============================] - 0s 673us/step - loss: 0.4687 - accuracy: 0.7836\n",
      "Epoch 677/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4626 - accuracy: 0.7817\n",
      "Epoch 678/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4631 - accuracy: 0.7929\n",
      "Epoch 679/1500\n",
      "9/9 [==============================] - 0s 544us/step - loss: 0.4634 - accuracy: 0.7892\n",
      "Epoch 680/1500\n",
      "9/9 [==============================] - 0s 644us/step - loss: 0.4625 - accuracy: 0.7892\n",
      "Epoch 681/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4701 - accuracy: 0.7817\n",
      "Epoch 682/1500\n",
      "9/9 [==============================] - 0s 605us/step - loss: 0.4687 - accuracy: 0.7761\n",
      "Epoch 683/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4796 - accuracy: 0.7799\n",
      "Epoch 684/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4801 - accuracy: 0.7687\n",
      "Epoch 685/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4582 - accuracy: 0.7892\n",
      "Epoch 686/1500\n",
      "9/9 [==============================] - 0s 579us/step - loss: 0.4620 - accuracy: 0.7873\n",
      "Epoch 687/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.4680 - accuracy: 0.7761\n",
      "Epoch 688/1500\n",
      "9/9 [==============================] - 0s 794us/step - loss: 0.4828 - accuracy: 0.7649\n",
      "Epoch 689/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4703 - accuracy: 0.7817\n",
      "Epoch 690/1500\n",
      "9/9 [==============================] - 0s 741us/step - loss: 0.4588 - accuracy: 0.7780\n",
      "Epoch 691/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4623 - accuracy: 0.7873\n",
      "Epoch 692/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4608 - accuracy: 0.7799\n",
      "Epoch 693/1500\n",
      "9/9 [==============================] - 0s 616us/step - loss: 0.4663 - accuracy: 0.7929\n",
      "Epoch 694/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4624 - accuracy: 0.7910\n",
      "Epoch 695/1500\n",
      "9/9 [==============================] - 0s 567us/step - loss: 0.4632 - accuracy: 0.7817\n",
      "Epoch 696/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4654 - accuracy: 0.7761\n",
      "Epoch 697/1500\n",
      "9/9 [==============================] - 0s 687us/step - loss: 0.4603 - accuracy: 0.7836\n",
      "Epoch 698/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.4593 - accuracy: 0.7817\n",
      "Epoch 699/1500\n",
      "9/9 [==============================] - 0s 620us/step - loss: 0.4582 - accuracy: 0.7929\n",
      "Epoch 700/1500\n",
      "9/9 [==============================] - 0s 549us/step - loss: 0.4596 - accuracy: 0.7873\n",
      "Epoch 701/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.4609 - accuracy: 0.7910\n",
      "Epoch 702/1500\n",
      "9/9 [==============================] - 0s 559us/step - loss: 0.4641 - accuracy: 0.7892\n",
      "Epoch 703/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.4581 - accuracy: 0.7873\n",
      "Epoch 704/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4642 - accuracy: 0.8004\n",
      "Epoch 705/1500\n",
      "9/9 [==============================] - 0s 673us/step - loss: 0.4605 - accuracy: 0.7910\n",
      "Epoch 706/1500\n",
      "9/9 [==============================] - 0s 576us/step - loss: 0.4605 - accuracy: 0.7985\n",
      "Epoch 707/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4586 - accuracy: 0.7873\n",
      "Epoch 708/1500\n",
      "9/9 [==============================] - 0s 674us/step - loss: 0.4562 - accuracy: 0.7817\n",
      "Epoch 709/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.4597 - accuracy: 0.7799\n",
      "Epoch 710/1500\n",
      "9/9 [==============================] - 0s 739us/step - loss: 0.4573 - accuracy: 0.7854\n",
      "Epoch 711/1500\n",
      "9/9 [==============================] - 0s 573us/step - loss: 0.4660 - accuracy: 0.7817\n",
      "Epoch 712/1500\n",
      "9/9 [==============================] - 0s 565us/step - loss: 0.4676 - accuracy: 0.7668\n",
      "Epoch 713/1500\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.4652 - accuracy: 0.7854\n",
      "Epoch 714/1500\n",
      "9/9 [==============================] - 0s 670us/step - loss: 0.4673 - accuracy: 0.7873\n",
      "Epoch 715/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4891 - accuracy: 0.7612\n",
      "Epoch 716/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4709 - accuracy: 0.7780\n",
      "Epoch 717/1500\n",
      "9/9 [==============================] - 0s 571us/step - loss: 0.4661 - accuracy: 0.7799\n",
      "Epoch 718/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4649 - accuracy: 0.7854\n",
      "Epoch 719/1500\n",
      "9/9 [==============================] - 0s 611us/step - loss: 0.4586 - accuracy: 0.7929\n",
      "Epoch 720/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4621 - accuracy: 0.7836\n",
      "Epoch 721/1500\n",
      "9/9 [==============================] - 0s 692us/step - loss: 0.4661 - accuracy: 0.7854\n",
      "Epoch 722/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.4567 - accuracy: 0.7854\n",
      "Epoch 723/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4643 - accuracy: 0.7799\n",
      "Epoch 724/1500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.4642 - accuracy: 0.7873\n",
      "Epoch 725/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4611 - accuracy: 0.7817\n",
      "Epoch 726/1500\n",
      "9/9 [==============================] - 0s 565us/step - loss: 0.4556 - accuracy: 0.7910\n",
      "Epoch 727/1500\n",
      "9/9 [==============================] - 0s 572us/step - loss: 0.4584 - accuracy: 0.7873\n",
      "Epoch 728/1500\n",
      "9/9 [==============================] - 0s 545us/step - loss: 0.4654 - accuracy: 0.7985\n",
      "Epoch 729/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4697 - accuracy: 0.7836\n",
      "Epoch 730/1500\n",
      "9/9 [==============================] - 0s 548us/step - loss: 0.4672 - accuracy: 0.7892\n",
      "Epoch 731/1500\n",
      "9/9 [==============================] - 0s 565us/step - loss: 0.4657 - accuracy: 0.7892\n",
      "Epoch 732/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4599 - accuracy: 0.7892\n",
      "Epoch 733/1500\n",
      "9/9 [==============================] - 0s 559us/step - loss: 0.4554 - accuracy: 0.7780\n",
      "Epoch 734/1500\n",
      "9/9 [==============================] - 0s 547us/step - loss: 0.4592 - accuracy: 0.7910\n",
      "Epoch 735/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4605 - accuracy: 0.7799\n",
      "Epoch 736/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4735 - accuracy: 0.7612\n",
      "Epoch 737/1500\n",
      "9/9 [==============================] - 0s 677us/step - loss: 0.4724 - accuracy: 0.7668\n",
      "Epoch 738/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4610 - accuracy: 0.7892\n",
      "Epoch 739/1500\n",
      "9/9 [==============================] - 0s 555us/step - loss: 0.4615 - accuracy: 0.7892\n",
      "Epoch 740/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4637 - accuracy: 0.7910\n",
      "Epoch 741/1500\n",
      "9/9 [==============================] - 0s 557us/step - loss: 0.4597 - accuracy: 0.7985\n",
      "Epoch 742/1500\n",
      "9/9 [==============================] - 0s 546us/step - loss: 0.4573 - accuracy: 0.7873\n",
      "Epoch 743/1500\n",
      "9/9 [==============================] - 0s 568us/step - loss: 0.4654 - accuracy: 0.7817\n",
      "Epoch 744/1500\n",
      "9/9 [==============================] - 0s 546us/step - loss: 0.4585 - accuracy: 0.7854\n",
      "Epoch 745/1500\n",
      "9/9 [==============================] - 0s 793us/step - loss: 0.4561 - accuracy: 0.7948\n",
      "Epoch 746/1500\n",
      "9/9 [==============================] - 0s 587us/step - loss: 0.4528 - accuracy: 0.7966\n",
      "Epoch 747/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.4581 - accuracy: 0.7854\n",
      "Epoch 748/1500\n",
      "9/9 [==============================] - 0s 644us/step - loss: 0.4569 - accuracy: 0.7910\n",
      "Epoch 749/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4588 - accuracy: 0.7873\n",
      "Epoch 750/1500\n",
      "9/9 [==============================] - 0s 601us/step - loss: 0.4608 - accuracy: 0.7985\n",
      "Epoch 751/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.4628 - accuracy: 0.7799\n",
      "Epoch 752/1500\n",
      "9/9 [==============================] - 0s 766us/step - loss: 0.4604 - accuracy: 0.7892\n",
      "Epoch 753/1500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.4574 - accuracy: 0.7966\n",
      "Epoch 754/1500\n",
      "9/9 [==============================] - 0s 690us/step - loss: 0.4545 - accuracy: 0.7910\n",
      "Epoch 755/1500\n",
      "9/9 [==============================] - 0s 663us/step - loss: 0.4646 - accuracy: 0.7836\n",
      "Epoch 756/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4641 - accuracy: 0.7873\n",
      "Epoch 757/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4669 - accuracy: 0.7743\n",
      "Epoch 758/1500\n",
      "9/9 [==============================] - 0s 548us/step - loss: 0.4605 - accuracy: 0.7854\n",
      "Epoch 759/1500\n",
      "9/9 [==============================] - 0s 613us/step - loss: 0.4596 - accuracy: 0.7948\n",
      "Epoch 760/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4656 - accuracy: 0.7892\n",
      "Epoch 761/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4542 - accuracy: 0.7892\n",
      "Epoch 762/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4550 - accuracy: 0.7836\n",
      "Epoch 763/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4532 - accuracy: 0.7929\n",
      "Epoch 764/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4593 - accuracy: 0.7985\n",
      "Epoch 765/1500\n",
      "9/9 [==============================] - 0s 664us/step - loss: 0.4651 - accuracy: 0.7836\n",
      "Epoch 766/1500\n",
      "9/9 [==============================] - 0s 686us/step - loss: 0.4678 - accuracy: 0.7743\n",
      "Epoch 767/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4539 - accuracy: 0.7948\n",
      "Epoch 768/1500\n",
      "9/9 [==============================] - 0s 598us/step - loss: 0.4569 - accuracy: 0.7780\n",
      "Epoch 769/1500\n",
      "9/9 [==============================] - 0s 766us/step - loss: 0.4593 - accuracy: 0.7854\n",
      "Epoch 770/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4605 - accuracy: 0.7761\n",
      "Epoch 771/1500\n",
      "9/9 [==============================] - 0s 681us/step - loss: 0.4566 - accuracy: 0.7761\n",
      "Epoch 772/1500\n",
      "9/9 [==============================] - 0s 587us/step - loss: 0.4553 - accuracy: 0.7892\n",
      "Epoch 773/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4610 - accuracy: 0.7910\n",
      "Epoch 774/1500\n",
      "9/9 [==============================] - 0s 576us/step - loss: 0.4567 - accuracy: 0.7910\n",
      "Epoch 775/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4494 - accuracy: 0.7929\n",
      "Epoch 776/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4548 - accuracy: 0.8022\n",
      "Epoch 777/1500\n",
      "9/9 [==============================] - 0s 634us/step - loss: 0.4585 - accuracy: 0.7985\n",
      "Epoch 778/1500\n",
      "9/9 [==============================] - 0s 695us/step - loss: 0.4590 - accuracy: 0.7743\n",
      "Epoch 779/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.4524 - accuracy: 0.7873\n",
      "Epoch 780/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4517 - accuracy: 0.7892\n",
      "Epoch 781/1500\n",
      "9/9 [==============================] - 0s 598us/step - loss: 0.4593 - accuracy: 0.7873\n",
      "Epoch 782/1500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.4514 - accuracy: 0.8004\n",
      "Epoch 783/1500\n",
      "9/9 [==============================] - 0s 697us/step - loss: 0.4489 - accuracy: 0.7910\n",
      "Epoch 784/1500\n",
      "9/9 [==============================] - 0s 787us/step - loss: 0.4580 - accuracy: 0.7910\n",
      "Epoch 785/1500\n",
      "9/9 [==============================] - 0s 683us/step - loss: 0.4582 - accuracy: 0.7985\n",
      "Epoch 786/1500\n",
      "9/9 [==============================] - 0s 579us/step - loss: 0.4555 - accuracy: 0.7817\n",
      "Epoch 787/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.4662 - accuracy: 0.7929\n",
      "Epoch 788/1500\n",
      "9/9 [==============================] - 0s 671us/step - loss: 0.4573 - accuracy: 0.7892\n",
      "Epoch 789/1500\n",
      "9/9 [==============================] - 0s 771us/step - loss: 0.4563 - accuracy: 0.7929\n",
      "Epoch 790/1500\n",
      "9/9 [==============================] - 0s 694us/step - loss: 0.4511 - accuracy: 0.7854\n",
      "Epoch 791/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.4582 - accuracy: 0.7854\n",
      "Epoch 792/1500\n",
      "9/9 [==============================] - 0s 692us/step - loss: 0.4832 - accuracy: 0.7705\n",
      "Epoch 793/1500\n",
      "9/9 [==============================] - 0s 766us/step - loss: 0.4680 - accuracy: 0.7817\n",
      "Epoch 794/1500\n",
      "9/9 [==============================] - 0s 652us/step - loss: 0.4635 - accuracy: 0.7799\n",
      "Epoch 795/1500\n",
      "9/9 [==============================] - 0s 557us/step - loss: 0.4588 - accuracy: 0.7817\n",
      "Epoch 796/1500\n",
      "9/9 [==============================] - 0s 739us/step - loss: 0.4517 - accuracy: 0.7892\n",
      "Epoch 797/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.4591 - accuracy: 0.7817\n",
      "Epoch 798/1500\n",
      "9/9 [==============================] - 0s 623us/step - loss: 0.4535 - accuracy: 0.7854\n",
      "Epoch 799/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.4525 - accuracy: 0.7892\n",
      "Epoch 800/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.4509 - accuracy: 0.8041\n",
      "Epoch 801/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4557 - accuracy: 0.7854\n",
      "Epoch 802/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 661us/step - loss: 0.4555 - accuracy: 0.7836\n",
      "Epoch 803/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4533 - accuracy: 0.7985\n",
      "Epoch 804/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4523 - accuracy: 0.7873\n",
      "Epoch 805/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4555 - accuracy: 0.7929\n",
      "Epoch 806/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4550 - accuracy: 0.8004\n",
      "Epoch 807/1500\n",
      "9/9 [==============================] - 0s 606us/step - loss: 0.4512 - accuracy: 0.7892\n",
      "Epoch 808/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4528 - accuracy: 0.7892\n",
      "Epoch 809/1500\n",
      "9/9 [==============================] - 0s 673us/step - loss: 0.4488 - accuracy: 0.7948\n",
      "Epoch 810/1500\n",
      "9/9 [==============================] - 0s 590us/step - loss: 0.4485 - accuracy: 0.8004\n",
      "Epoch 811/1500\n",
      "9/9 [==============================] - 0s 677us/step - loss: 0.4498 - accuracy: 0.7854\n",
      "Epoch 812/1500\n",
      "9/9 [==============================] - 0s 624us/step - loss: 0.4602 - accuracy: 0.7910\n",
      "Epoch 813/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4571 - accuracy: 0.7761\n",
      "Epoch 814/1500\n",
      "9/9 [==============================] - 0s 527us/step - loss: 0.4565 - accuracy: 0.7966\n",
      "Epoch 815/1500\n",
      "9/9 [==============================] - 0s 592us/step - loss: 0.4533 - accuracy: 0.7780\n",
      "Epoch 816/1500\n",
      "9/9 [==============================] - 0s 524us/step - loss: 0.4507 - accuracy: 0.7929\n",
      "Epoch 817/1500\n",
      "9/9 [==============================] - 0s 730us/step - loss: 0.4489 - accuracy: 0.7948\n",
      "Epoch 818/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4490 - accuracy: 0.7985\n",
      "Epoch 819/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4626 - accuracy: 0.7892\n",
      "Epoch 820/1500\n",
      "9/9 [==============================] - 0s 578us/step - loss: 0.4547 - accuracy: 0.7854\n",
      "Epoch 821/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4511 - accuracy: 0.8004\n",
      "Epoch 822/1500\n",
      "9/9 [==============================] - 0s 747us/step - loss: 0.4524 - accuracy: 0.7817\n",
      "Epoch 823/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4483 - accuracy: 0.7948\n",
      "Epoch 824/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.4528 - accuracy: 0.7836\n",
      "Epoch 825/1500\n",
      "9/9 [==============================] - 0s 560us/step - loss: 0.4576 - accuracy: 0.7948\n",
      "Epoch 826/1500\n",
      "9/9 [==============================] - 0s 703us/step - loss: 0.4526 - accuracy: 0.7854\n",
      "Epoch 827/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4517 - accuracy: 0.7929\n",
      "Epoch 828/1500\n",
      "9/9 [==============================] - 0s 727us/step - loss: 0.4476 - accuracy: 0.8004\n",
      "Epoch 829/1500\n",
      "9/9 [==============================] - 0s 492us/step - loss: 0.4497 - accuracy: 0.7948\n",
      "Epoch 830/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.4679 - accuracy: 0.7705\n",
      "Epoch 831/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4598 - accuracy: 0.7836\n",
      "Epoch 832/1500\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.4641 - accuracy: 0.7799\n",
      "Epoch 833/1500\n",
      "9/9 [==============================] - 0s 684us/step - loss: 0.4541 - accuracy: 0.7910\n",
      "Epoch 834/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4534 - accuracy: 0.7780\n",
      "Epoch 835/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4429 - accuracy: 0.8004\n",
      "Epoch 836/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4542 - accuracy: 0.7910\n",
      "Epoch 837/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4488 - accuracy: 0.7929\n",
      "Epoch 838/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4580 - accuracy: 0.7948\n",
      "Epoch 839/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4557 - accuracy: 0.7948\n",
      "Epoch 840/1500\n",
      "9/9 [==============================] - 0s 638us/step - loss: 0.4489 - accuracy: 0.7948\n",
      "Epoch 841/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4666 - accuracy: 0.7873\n",
      "Epoch 842/1500\n",
      "9/9 [==============================] - 0s 644us/step - loss: 0.4492 - accuracy: 0.7799\n",
      "Epoch 843/1500\n",
      "9/9 [==============================] - 0s 541us/step - loss: 0.4521 - accuracy: 0.7948\n",
      "Epoch 844/1500\n",
      "9/9 [==============================] - 0s 722us/step - loss: 0.4487 - accuracy: 0.7910\n",
      "Epoch 845/1500\n",
      "9/9 [==============================] - 0s 684us/step - loss: 0.4699 - accuracy: 0.7612\n",
      "Epoch 846/1500\n",
      "9/9 [==============================] - 0s 694us/step - loss: 0.4542 - accuracy: 0.7948\n",
      "Epoch 847/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4502 - accuracy: 0.8022\n",
      "Epoch 848/1500\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7985\n",
      "Epoch 849/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4452 - accuracy: 0.7910\n",
      "Epoch 850/1500\n",
      "9/9 [==============================] - 0s 685us/step - loss: 0.4471 - accuracy: 0.7910\n",
      "Epoch 851/1500\n",
      "9/9 [==============================] - 0s 639us/step - loss: 0.4448 - accuracy: 0.7929\n",
      "Epoch 852/1500\n",
      "9/9 [==============================] - 0s 559us/step - loss: 0.4515 - accuracy: 0.7873\n",
      "Epoch 853/1500\n",
      "9/9 [==============================] - 0s 696us/step - loss: 0.4433 - accuracy: 0.7948\n",
      "Epoch 854/1500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.4534 - accuracy: 0.7854\n",
      "Epoch 855/1500\n",
      "9/9 [==============================] - 0s 655us/step - loss: 0.4492 - accuracy: 0.7892\n",
      "Epoch 856/1500\n",
      "9/9 [==============================] - 0s 670us/step - loss: 0.4517 - accuracy: 0.7948\n",
      "Epoch 857/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4549 - accuracy: 0.8004\n",
      "Epoch 858/1500\n",
      "9/9 [==============================] - 0s 671us/step - loss: 0.4700 - accuracy: 0.7780\n",
      "Epoch 859/1500\n",
      "9/9 [==============================] - 0s 531us/step - loss: 0.4589 - accuracy: 0.7799\n",
      "Epoch 860/1500\n",
      "9/9 [==============================] - 0s 775us/step - loss: 0.4526 - accuracy: 0.7873\n",
      "Epoch 861/1500\n",
      "9/9 [==============================] - 0s 707us/step - loss: 0.4584 - accuracy: 0.7929\n",
      "Epoch 862/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4555 - accuracy: 0.7854\n",
      "Epoch 863/1500\n",
      "9/9 [==============================] - 0s 551us/step - loss: 0.4467 - accuracy: 0.8060\n",
      "Epoch 864/1500\n",
      "9/9 [==============================] - 0s 562us/step - loss: 0.4493 - accuracy: 0.7854\n",
      "Epoch 865/1500\n",
      "9/9 [==============================] - 0s 652us/step - loss: 0.4514 - accuracy: 0.7910\n",
      "Epoch 866/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4484 - accuracy: 0.7817\n",
      "Epoch 867/1500\n",
      "9/9 [==============================] - 0s 682us/step - loss: 0.4391 - accuracy: 0.7985\n",
      "Epoch 868/1500\n",
      "9/9 [==============================] - 0s 653us/step - loss: 0.4550 - accuracy: 0.7817\n",
      "Epoch 869/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4476 - accuracy: 0.7985\n",
      "Epoch 870/1500\n",
      "9/9 [==============================] - 0s 502us/step - loss: 0.4456 - accuracy: 0.8078\n",
      "Epoch 871/1500\n",
      "9/9 [==============================] - 0s 768us/step - loss: 0.4543 - accuracy: 0.7873\n",
      "Epoch 872/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4723 - accuracy: 0.7799\n",
      "Epoch 873/1500\n",
      "9/9 [==============================] - 0s 674us/step - loss: 0.4650 - accuracy: 0.7780\n",
      "Epoch 874/1500\n",
      "9/9 [==============================] - 0s 683us/step - loss: 0.4719 - accuracy: 0.7873\n",
      "Epoch 875/1500\n",
      "9/9 [==============================] - 0s 671us/step - loss: 0.4713 - accuracy: 0.7649\n",
      "Epoch 876/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4497 - accuracy: 0.7836\n",
      "Epoch 877/1500\n",
      "9/9 [==============================] - 0s 651us/step - loss: 0.4476 - accuracy: 0.7910\n",
      "Epoch 878/1500\n",
      "9/9 [==============================] - 0s 652us/step - loss: 0.4495 - accuracy: 0.8041\n",
      "Epoch 879/1500\n",
      "9/9 [==============================] - 0s 605us/step - loss: 0.4593 - accuracy: 0.7873\n",
      "Epoch 880/1500\n",
      "9/9 [==============================] - 0s 608us/step - loss: 0.4556 - accuracy: 0.7836\n",
      "Epoch 881/1500\n",
      "9/9 [==============================] - 0s 638us/step - loss: 0.4578 - accuracy: 0.7817\n",
      "Epoch 882/1500\n",
      "9/9 [==============================] - 0s 778us/step - loss: 0.4442 - accuracy: 0.7966\n",
      "Epoch 883/1500\n",
      "9/9 [==============================] - 0s 633us/step - loss: 0.4486 - accuracy: 0.7929\n",
      "Epoch 884/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4497 - accuracy: 0.7836\n",
      "Epoch 885/1500\n",
      "9/9 [==============================] - 0s 704us/step - loss: 0.4515 - accuracy: 0.7780\n",
      "Epoch 886/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4507 - accuracy: 0.7985\n",
      "Epoch 887/1500\n",
      "9/9 [==============================] - 0s 692us/step - loss: 0.4539 - accuracy: 0.7854\n",
      "Epoch 888/1500\n",
      "9/9 [==============================] - 0s 655us/step - loss: 0.4558 - accuracy: 0.7985\n",
      "Epoch 889/1500\n",
      "9/9 [==============================] - 0s 787us/step - loss: 0.4613 - accuracy: 0.7892\n",
      "Epoch 890/1500\n",
      "9/9 [==============================] - 0s 679us/step - loss: 0.4541 - accuracy: 0.7873\n",
      "Epoch 891/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4462 - accuracy: 0.7892\n",
      "Epoch 892/1500\n",
      "9/9 [==============================] - 0s 535us/step - loss: 0.4625 - accuracy: 0.7873\n",
      "Epoch 893/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4477 - accuracy: 0.7948\n",
      "Epoch 894/1500\n",
      "9/9 [==============================] - 0s 675us/step - loss: 0.4422 - accuracy: 0.7966\n",
      "Epoch 895/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4418 - accuracy: 0.7966\n",
      "Epoch 896/1500\n",
      "9/9 [==============================] - 0s 535us/step - loss: 0.4430 - accuracy: 0.7892\n",
      "Epoch 897/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4501 - accuracy: 0.7966\n",
      "Epoch 898/1500\n",
      "9/9 [==============================] - 0s 643us/step - loss: 0.4467 - accuracy: 0.7892\n",
      "Epoch 899/1500\n",
      "9/9 [==============================] - 0s 678us/step - loss: 0.4449 - accuracy: 0.7910\n",
      "Epoch 900/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4487 - accuracy: 0.7929\n",
      "Epoch 901/1500\n",
      "9/9 [==============================] - 0s 557us/step - loss: 0.4469 - accuracy: 0.7985\n",
      "Epoch 902/1500\n",
      "9/9 [==============================] - 0s 628us/step - loss: 0.4482 - accuracy: 0.7910\n",
      "Epoch 903/1500\n",
      "9/9 [==============================] - 0s 568us/step - loss: 0.4428 - accuracy: 0.7966\n",
      "Epoch 904/1500\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.4410 - accuracy: 0.7929\n",
      "Epoch 905/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4457 - accuracy: 0.7985\n",
      "Epoch 906/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4501 - accuracy: 0.7854\n",
      "Epoch 907/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4457 - accuracy: 0.8004\n",
      "Epoch 908/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4378 - accuracy: 0.8022\n",
      "Epoch 909/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.4465 - accuracy: 0.7929\n",
      "Epoch 910/1500\n",
      "9/9 [==============================] - 0s 549us/step - loss: 0.4470 - accuracy: 0.7948\n",
      "Epoch 911/1500\n",
      "9/9 [==============================] - 0s 653us/step - loss: 0.4414 - accuracy: 0.8022\n",
      "Epoch 912/1500\n",
      "9/9 [==============================] - 0s 559us/step - loss: 0.4430 - accuracy: 0.8022\n",
      "Epoch 913/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4451 - accuracy: 0.7948\n",
      "Epoch 914/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4388 - accuracy: 0.7985\n",
      "Epoch 915/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4395 - accuracy: 0.8004\n",
      "Epoch 916/1500\n",
      "9/9 [==============================] - 0s 675us/step - loss: 0.4426 - accuracy: 0.7910\n",
      "Epoch 917/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4419 - accuracy: 0.7892\n",
      "Epoch 918/1500\n",
      "9/9 [==============================] - 0s 631us/step - loss: 0.4394 - accuracy: 0.8022\n",
      "Epoch 919/1500\n",
      "9/9 [==============================] - 0s 538us/step - loss: 0.4511 - accuracy: 0.7948\n",
      "Epoch 920/1500\n",
      "9/9 [==============================] - 0s 764us/step - loss: 0.4369 - accuracy: 0.8060\n",
      "Epoch 921/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4512 - accuracy: 0.7780\n",
      "Epoch 922/1500\n",
      "9/9 [==============================] - 0s 746us/step - loss: 0.4630 - accuracy: 0.7799\n",
      "Epoch 923/1500\n",
      "9/9 [==============================] - 0s 558us/step - loss: 0.4558 - accuracy: 0.7948\n",
      "Epoch 924/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4443 - accuracy: 0.7854\n",
      "Epoch 925/1500\n",
      "9/9 [==============================] - 0s 608us/step - loss: 0.4427 - accuracy: 0.7966\n",
      "Epoch 926/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.4430 - accuracy: 0.8041\n",
      "Epoch 927/1500\n",
      "9/9 [==============================] - 0s 677us/step - loss: 0.4427 - accuracy: 0.7966\n",
      "Epoch 928/1500\n",
      "9/9 [==============================] - 0s 767us/step - loss: 0.4478 - accuracy: 0.7892\n",
      "Epoch 929/1500\n",
      "9/9 [==============================] - 0s 555us/step - loss: 0.4418 - accuracy: 0.8022\n",
      "Epoch 930/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4402 - accuracy: 0.7966\n",
      "Epoch 931/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4429 - accuracy: 0.7854\n",
      "Epoch 932/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4459 - accuracy: 0.7910\n",
      "Epoch 933/1500\n",
      "9/9 [==============================] - 0s 606us/step - loss: 0.4459 - accuracy: 0.7836\n",
      "Epoch 934/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4695 - accuracy: 0.7612\n",
      "Epoch 935/1500\n",
      "9/9 [==============================] - 0s 704us/step - loss: 0.4868 - accuracy: 0.7351\n",
      "Epoch 936/1500\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.4422 - accuracy: 0.7892\n",
      "Epoch 937/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4530 - accuracy: 0.7910\n",
      "Epoch 938/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4535 - accuracy: 0.7929\n",
      "Epoch 939/1500\n",
      "9/9 [==============================] - 0s 636us/step - loss: 0.4384 - accuracy: 0.8004\n",
      "Epoch 940/1500\n",
      "9/9 [==============================] - 0s 623us/step - loss: 0.4413 - accuracy: 0.7854\n",
      "Epoch 941/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.4390 - accuracy: 0.8022\n",
      "Epoch 942/1500\n",
      "9/9 [==============================] - 0s 698us/step - loss: 0.4374 - accuracy: 0.8004\n",
      "Epoch 943/1500\n",
      "9/9 [==============================] - 0s 544us/step - loss: 0.4411 - accuracy: 0.7929\n",
      "Epoch 944/1500\n",
      "9/9 [==============================] - 0s 788us/step - loss: 0.4447 - accuracy: 0.7892\n",
      "Epoch 945/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4426 - accuracy: 0.7910\n",
      "Epoch 946/1500\n",
      "9/9 [==============================] - 0s 762us/step - loss: 0.4400 - accuracy: 0.8022\n",
      "Epoch 947/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4428 - accuracy: 0.7910\n",
      "Epoch 948/1500\n",
      "9/9 [==============================] - 0s 721us/step - loss: 0.4471 - accuracy: 0.7929\n",
      "Epoch 949/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4546 - accuracy: 0.7985\n",
      "Epoch 950/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4488 - accuracy: 0.7873\n",
      "Epoch 951/1500\n",
      "9/9 [==============================] - 0s 648us/step - loss: 0.4707 - accuracy: 0.7873\n",
      "Epoch 952/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4386 - accuracy: 0.7873\n",
      "Epoch 953/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4392 - accuracy: 0.7910\n",
      "Epoch 954/1500\n",
      "9/9 [==============================] - 0s 651us/step - loss: 0.4371 - accuracy: 0.8004\n",
      "Epoch 955/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4389 - accuracy: 0.8004\n",
      "Epoch 956/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.4395 - accuracy: 0.8004\n",
      "Epoch 957/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.4381 - accuracy: 0.8060\n",
      "Epoch 958/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.4407 - accuracy: 0.7948\n",
      "Epoch 959/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4366 - accuracy: 0.7948\n",
      "Epoch 960/1500\n",
      "9/9 [==============================] - 0s 536us/step - loss: 0.4410 - accuracy: 0.7985\n",
      "Epoch 961/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4380 - accuracy: 0.8078\n",
      "Epoch 962/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 574us/step - loss: 0.4385 - accuracy: 0.7929\n",
      "Epoch 963/1500\n",
      "9/9 [==============================] - 0s 720us/step - loss: 0.4369 - accuracy: 0.8078\n",
      "Epoch 964/1500\n",
      "9/9 [==============================] - 0s 544us/step - loss: 0.4374 - accuracy: 0.8041\n",
      "Epoch 965/1500\n",
      "9/9 [==============================] - 0s 655us/step - loss: 0.4384 - accuracy: 0.8041\n",
      "Epoch 966/1500\n",
      "9/9 [==============================] - 0s 562us/step - loss: 0.4370 - accuracy: 0.8004\n",
      "Epoch 967/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4340 - accuracy: 0.8004\n",
      "Epoch 968/1500\n",
      "9/9 [==============================] - 0s 643us/step - loss: 0.4490 - accuracy: 0.7854\n",
      "Epoch 969/1500\n",
      "9/9 [==============================] - 0s 630us/step - loss: 0.4564 - accuracy: 0.7854\n",
      "Epoch 970/1500\n",
      "9/9 [==============================] - 0s 713us/step - loss: 0.4368 - accuracy: 0.8041\n",
      "Epoch 971/1500\n",
      "9/9 [==============================] - 0s 560us/step - loss: 0.4355 - accuracy: 0.8004\n",
      "Epoch 972/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4375 - accuracy: 0.8004\n",
      "Epoch 973/1500\n",
      "9/9 [==============================] - 0s 558us/step - loss: 0.4364 - accuracy: 0.7985\n",
      "Epoch 974/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4354 - accuracy: 0.7910\n",
      "Epoch 975/1500\n",
      "9/9 [==============================] - 0s 572us/step - loss: 0.4497 - accuracy: 0.7910\n",
      "Epoch 976/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4446 - accuracy: 0.7948\n",
      "Epoch 977/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.4463 - accuracy: 0.7873\n",
      "Epoch 978/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4531 - accuracy: 0.7854\n",
      "Epoch 979/1500\n",
      "9/9 [==============================] - 0s 612us/step - loss: 0.4372 - accuracy: 0.7966\n",
      "Epoch 980/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.4343 - accuracy: 0.8097\n",
      "Epoch 981/1500\n",
      "9/9 [==============================] - 0s 578us/step - loss: 0.4424 - accuracy: 0.8041\n",
      "Epoch 982/1500\n",
      "9/9 [==============================] - 0s 617us/step - loss: 0.4352 - accuracy: 0.8172\n",
      "Epoch 983/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.4384 - accuracy: 0.7948\n",
      "Epoch 984/1500\n",
      "9/9 [==============================] - 0s 610us/step - loss: 0.4326 - accuracy: 0.8004\n",
      "Epoch 985/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4327 - accuracy: 0.8022\n",
      "Epoch 986/1500\n",
      "9/9 [==============================] - 0s 703us/step - loss: 0.4341 - accuracy: 0.8097\n",
      "Epoch 987/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4353 - accuracy: 0.7985\n",
      "Epoch 988/1500\n",
      "9/9 [==============================] - 0s 688us/step - loss: 0.4425 - accuracy: 0.8004\n",
      "Epoch 989/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4697 - accuracy: 0.7668\n",
      "Epoch 990/1500\n",
      "9/9 [==============================] - 0s 646us/step - loss: 0.4315 - accuracy: 0.8004\n",
      "Epoch 991/1500\n",
      "9/9 [==============================] - 0s 555us/step - loss: 0.4339 - accuracy: 0.8060\n",
      "Epoch 992/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4350 - accuracy: 0.8078\n",
      "Epoch 993/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4361 - accuracy: 0.7966\n",
      "Epoch 994/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4383 - accuracy: 0.7854\n",
      "Epoch 995/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4318 - accuracy: 0.8097\n",
      "Epoch 996/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4370 - accuracy: 0.8078\n",
      "Epoch 997/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.4371 - accuracy: 0.7910\n",
      "Epoch 998/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4397 - accuracy: 0.7948\n",
      "Epoch 999/1500\n",
      "9/9 [==============================] - 0s 510us/step - loss: 0.4331 - accuracy: 0.7966\n",
      "Epoch 1000/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.4333 - accuracy: 0.8041\n",
      "Epoch 1001/1500\n",
      "9/9 [==============================] - 0s 708us/step - loss: 0.4373 - accuracy: 0.8078\n",
      "Epoch 1002/1500\n",
      "9/9 [==============================] - 0s 563us/step - loss: 0.4348 - accuracy: 0.8022\n",
      "Epoch 1003/1500\n",
      "9/9 [==============================] - 0s 725us/step - loss: 0.4350 - accuracy: 0.7948\n",
      "Epoch 1004/1500\n",
      "9/9 [==============================] - 0s 570us/step - loss: 0.4377 - accuracy: 0.7985\n",
      "Epoch 1005/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4364 - accuracy: 0.7985\n",
      "Epoch 1006/1500\n",
      "9/9 [==============================] - 0s 529us/step - loss: 0.4417 - accuracy: 0.7929\n",
      "Epoch 1007/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.4368 - accuracy: 0.7985\n",
      "Epoch 1008/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4420 - accuracy: 0.8022\n",
      "Epoch 1009/1500\n",
      "9/9 [==============================] - 0s 545us/step - loss: 0.4442 - accuracy: 0.7910\n",
      "Epoch 1010/1500\n",
      "9/9 [==============================] - 0s 763us/step - loss: 0.4409 - accuracy: 0.7966\n",
      "Epoch 1011/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4342 - accuracy: 0.8060\n",
      "Epoch 1012/1500\n",
      "9/9 [==============================] - 0s 710us/step - loss: 0.4325 - accuracy: 0.8041\n",
      "Epoch 1013/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4401 - accuracy: 0.7929\n",
      "Epoch 1014/1500\n",
      "9/9 [==============================] - 0s 704us/step - loss: 0.4409 - accuracy: 0.7948\n",
      "Epoch 1015/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4366 - accuracy: 0.8022\n",
      "Epoch 1016/1500\n",
      "9/9 [==============================] - 0s 617us/step - loss: 0.4376 - accuracy: 0.7873\n",
      "Epoch 1017/1500\n",
      "9/9 [==============================] - 0s 568us/step - loss: 0.4316 - accuracy: 0.8060\n",
      "Epoch 1018/1500\n",
      "9/9 [==============================] - 0s 768us/step - loss: 0.4305 - accuracy: 0.8004\n",
      "Epoch 1019/1500\n",
      "9/9 [==============================] - 0s 687us/step - loss: 0.4355 - accuracy: 0.7929\n",
      "Epoch 1020/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4352 - accuracy: 0.8097\n",
      "Epoch 1021/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4358 - accuracy: 0.8097\n",
      "Epoch 1022/1500\n",
      "9/9 [==============================] - 0s 560us/step - loss: 0.4329 - accuracy: 0.7966\n",
      "Epoch 1023/1500\n",
      "9/9 [==============================] - 0s 762us/step - loss: 0.4430 - accuracy: 0.7948\n",
      "Epoch 1024/1500\n",
      "9/9 [==============================] - 0s 653us/step - loss: 0.4425 - accuracy: 0.7854\n",
      "Epoch 1025/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4335 - accuracy: 0.8060\n",
      "Epoch 1026/1500\n",
      "9/9 [==============================] - 0s 643us/step - loss: 0.4494 - accuracy: 0.7836\n",
      "Epoch 1027/1500\n",
      "9/9 [==============================] - 0s 652us/step - loss: 0.4365 - accuracy: 0.8022\n",
      "Epoch 1028/1500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.4378 - accuracy: 0.7948\n",
      "Epoch 1029/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4308 - accuracy: 0.7910\n",
      "Epoch 1030/1500\n",
      "9/9 [==============================] - 0s 686us/step - loss: 0.4319 - accuracy: 0.8097\n",
      "Epoch 1031/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4367 - accuracy: 0.7929\n",
      "Epoch 1032/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4333 - accuracy: 0.8060\n",
      "Epoch 1033/1500\n",
      "9/9 [==============================] - 0s 557us/step - loss: 0.4338 - accuracy: 0.8004\n",
      "Epoch 1034/1500\n",
      "9/9 [==============================] - 0s 617us/step - loss: 0.4315 - accuracy: 0.7929\n",
      "Epoch 1035/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4288 - accuracy: 0.8004\n",
      "Epoch 1036/1500\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.4383 - accuracy: 0.8004\n",
      "Epoch 1037/1500\n",
      "9/9 [==============================] - 0s 560us/step - loss: 0.4378 - accuracy: 0.8022\n",
      "Epoch 1038/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4552 - accuracy: 0.7836\n",
      "Epoch 1039/1500\n",
      "9/9 [==============================] - 0s 722us/step - loss: 0.4400 - accuracy: 0.7948\n",
      "Epoch 1040/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4296 - accuracy: 0.8097\n",
      "Epoch 1041/1500\n",
      "9/9 [==============================] - 0s 674us/step - loss: 0.4300 - accuracy: 0.7892\n",
      "Epoch 1042/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 660us/step - loss: 0.4341 - accuracy: 0.7985\n",
      "Epoch 1043/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4363 - accuracy: 0.7948\n",
      "Epoch 1044/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4336 - accuracy: 0.7985\n",
      "Epoch 1045/1500\n",
      "9/9 [==============================] - 0s 729us/step - loss: 0.4335 - accuracy: 0.7929\n",
      "Epoch 1046/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4325 - accuracy: 0.7985\n",
      "Epoch 1047/1500\n",
      "9/9 [==============================] - 0s 782us/step - loss: 0.4395 - accuracy: 0.7948\n",
      "Epoch 1048/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.4307 - accuracy: 0.8022\n",
      "Epoch 1049/1500\n",
      "9/9 [==============================] - 0s 771us/step - loss: 0.4368 - accuracy: 0.8022\n",
      "Epoch 1050/1500\n",
      "9/9 [==============================] - 0s 676us/step - loss: 0.4581 - accuracy: 0.7799\n",
      "Epoch 1051/1500\n",
      "9/9 [==============================] - 0s 692us/step - loss: 0.4324 - accuracy: 0.7966\n",
      "Epoch 1052/1500\n",
      "9/9 [==============================] - 0s 615us/step - loss: 0.4347 - accuracy: 0.8022\n",
      "Epoch 1053/1500\n",
      "9/9 [==============================] - 0s 645us/step - loss: 0.4336 - accuracy: 0.8022\n",
      "Epoch 1054/1500\n",
      "9/9 [==============================] - 0s 593us/step - loss: 0.4270 - accuracy: 0.8097\n",
      "Epoch 1055/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4360 - accuracy: 0.7892\n",
      "Epoch 1056/1500\n",
      "9/9 [==============================] - 0s 629us/step - loss: 0.4431 - accuracy: 0.7892\n",
      "Epoch 1057/1500\n",
      "9/9 [==============================] - 0s 655us/step - loss: 0.4384 - accuracy: 0.7948\n",
      "Epoch 1058/1500\n",
      "9/9 [==============================] - 0s 571us/step - loss: 0.4348 - accuracy: 0.7910\n",
      "Epoch 1059/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4489 - accuracy: 0.7705\n",
      "Epoch 1060/1500\n",
      "9/9 [==============================] - 0s 564us/step - loss: 0.4666 - accuracy: 0.7743\n",
      "Epoch 1061/1500\n",
      "9/9 [==============================] - 0s 596us/step - loss: 0.4609 - accuracy: 0.7743\n",
      "Epoch 1062/1500\n",
      "9/9 [==============================] - 0s 711us/step - loss: 0.4565 - accuracy: 0.7836\n",
      "Epoch 1063/1500\n",
      "9/9 [==============================] - 0s 627us/step - loss: 0.4433 - accuracy: 0.7910\n",
      "Epoch 1064/1500\n",
      "9/9 [==============================] - 0s 672us/step - loss: 0.4386 - accuracy: 0.7966\n",
      "Epoch 1065/1500\n",
      "9/9 [==============================] - 0s 628us/step - loss: 0.4460 - accuracy: 0.7929\n",
      "Epoch 1066/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4350 - accuracy: 0.8041\n",
      "Epoch 1067/1500\n",
      "9/9 [==============================] - 0s 653us/step - loss: 0.4384 - accuracy: 0.7780\n",
      "Epoch 1068/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.4422 - accuracy: 0.8004\n",
      "Epoch 1069/1500\n",
      "9/9 [==============================] - 0s 607us/step - loss: 0.4453 - accuracy: 0.7892\n",
      "Epoch 1070/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4411 - accuracy: 0.7854\n",
      "Epoch 1071/1500\n",
      "9/9 [==============================] - 0s 630us/step - loss: 0.4362 - accuracy: 0.7966\n",
      "Epoch 1072/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4298 - accuracy: 0.7966\n",
      "Epoch 1073/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4281 - accuracy: 0.7966\n",
      "Epoch 1074/1500\n",
      "9/9 [==============================] - 0s 596us/step - loss: 0.4352 - accuracy: 0.8022\n",
      "Epoch 1075/1500\n",
      "9/9 [==============================] - 0s 781us/step - loss: 0.4330 - accuracy: 0.7929\n",
      "Epoch 1076/1500\n",
      "9/9 [==============================] - 0s 486us/step - loss: 0.4304 - accuracy: 0.7985\n",
      "Epoch 1077/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4276 - accuracy: 0.8060\n",
      "Epoch 1078/1500\n",
      "9/9 [==============================] - 0s 647us/step - loss: 0.4310 - accuracy: 0.8022\n",
      "Epoch 1079/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4324 - accuracy: 0.7910\n",
      "Epoch 1080/1500\n",
      "9/9 [==============================] - 0s 622us/step - loss: 0.4348 - accuracy: 0.7985\n",
      "Epoch 1081/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4303 - accuracy: 0.8134\n",
      "Epoch 1082/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4417 - accuracy: 0.7910\n",
      "Epoch 1083/1500\n",
      "9/9 [==============================] - 0s 625us/step - loss: 0.4340 - accuracy: 0.8004\n",
      "Epoch 1084/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4423 - accuracy: 0.7929\n",
      "Epoch 1085/1500\n",
      "9/9 [==============================] - 0s 580us/step - loss: 0.4401 - accuracy: 0.7836\n",
      "Epoch 1086/1500\n",
      "9/9 [==============================] - 0s 762us/step - loss: 0.4308 - accuracy: 0.7929\n",
      "Epoch 1087/1500\n",
      "9/9 [==============================] - 0s 531us/step - loss: 0.4378 - accuracy: 0.8022\n",
      "Epoch 1088/1500\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.4352 - accuracy: 0.7985\n",
      "Epoch 1089/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4232 - accuracy: 0.8097\n",
      "Epoch 1090/1500\n",
      "9/9 [==============================] - 0s 679us/step - loss: 0.4250 - accuracy: 0.8022\n",
      "Epoch 1091/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.4285 - accuracy: 0.8022\n",
      "Epoch 1092/1500\n",
      "9/9 [==============================] - 0s 568us/step - loss: 0.4281 - accuracy: 0.8041\n",
      "Epoch 1093/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4215 - accuracy: 0.8060\n",
      "Epoch 1094/1500\n",
      "9/9 [==============================] - 0s 714us/step - loss: 0.4275 - accuracy: 0.8060\n",
      "Epoch 1095/1500\n",
      "9/9 [==============================] - 0s 766us/step - loss: 0.4269 - accuracy: 0.8060\n",
      "Epoch 1096/1500\n",
      "9/9 [==============================] - 0s 671us/step - loss: 0.4290 - accuracy: 0.7910\n",
      "Epoch 1097/1500\n",
      "9/9 [==============================] - 0s 765us/step - loss: 0.4442 - accuracy: 0.8022\n",
      "Epoch 1098/1500\n",
      "9/9 [==============================] - 0s 655us/step - loss: 0.4333 - accuracy: 0.7948\n",
      "Epoch 1099/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.4260 - accuracy: 0.7985\n",
      "Epoch 1100/1500\n",
      "9/9 [==============================] - 0s 625us/step - loss: 0.4263 - accuracy: 0.8022\n",
      "Epoch 1101/1500\n",
      "9/9 [==============================] - 0s 680us/step - loss: 0.4244 - accuracy: 0.8022\n",
      "Epoch 1102/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.4235 - accuracy: 0.8022\n",
      "Epoch 1103/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4262 - accuracy: 0.8041\n",
      "Epoch 1104/1500\n",
      "9/9 [==============================] - 0s 704us/step - loss: 0.4248 - accuracy: 0.7892\n",
      "Epoch 1105/1500\n",
      "9/9 [==============================] - 0s 562us/step - loss: 0.4266 - accuracy: 0.8116\n",
      "Epoch 1106/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4275 - accuracy: 0.8004\n",
      "Epoch 1107/1500\n",
      "9/9 [==============================] - 0s 663us/step - loss: 0.4268 - accuracy: 0.7948\n",
      "Epoch 1108/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4221 - accuracy: 0.8116\n",
      "Epoch 1109/1500\n",
      "9/9 [==============================] - 0s 703us/step - loss: 0.4237 - accuracy: 0.8022\n",
      "Epoch 1110/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.4222 - accuracy: 0.8078\n",
      "Epoch 1111/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4248 - accuracy: 0.8022\n",
      "Epoch 1112/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4247 - accuracy: 0.8041\n",
      "Epoch 1113/1500\n",
      "9/9 [==============================] - 0s 729us/step - loss: 0.4316 - accuracy: 0.7929\n",
      "Epoch 1114/1500\n",
      "9/9 [==============================] - 0s 557us/step - loss: 0.4247 - accuracy: 0.8060\n",
      "Epoch 1115/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4220 - accuracy: 0.8022\n",
      "Epoch 1116/1500\n",
      "9/9 [==============================] - 0s 605us/step - loss: 0.4211 - accuracy: 0.8116\n",
      "Epoch 1117/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4219 - accuracy: 0.8004\n",
      "Epoch 1118/1500\n",
      "9/9 [==============================] - 0s 543us/step - loss: 0.4238 - accuracy: 0.8041\n",
      "Epoch 1119/1500\n",
      "9/9 [==============================] - 0s 662us/step - loss: 0.4235 - accuracy: 0.8022\n",
      "Epoch 1120/1500\n",
      "9/9 [==============================] - 0s 679us/step - loss: 0.4235 - accuracy: 0.8060\n",
      "Epoch 1121/1500\n",
      "9/9 [==============================] - 0s 670us/step - loss: 0.4226 - accuracy: 0.8022\n",
      "Epoch 1122/1500\n",
      "9/9 [==============================] - 0s 693us/step - loss: 0.4260 - accuracy: 0.7948\n",
      "Epoch 1123/1500\n",
      "9/9 [==============================] - 0s 555us/step - loss: 0.4239 - accuracy: 0.8004\n",
      "Epoch 1124/1500\n",
      "9/9 [==============================] - 0s 674us/step - loss: 0.4255 - accuracy: 0.8041\n",
      "Epoch 1125/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4259 - accuracy: 0.8078\n",
      "Epoch 1126/1500\n",
      "9/9 [==============================] - 0s 772us/step - loss: 0.4295 - accuracy: 0.8060\n",
      "Epoch 1127/1500\n",
      "9/9 [==============================] - 0s 670us/step - loss: 0.4238 - accuracy: 0.8097\n",
      "Epoch 1128/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4211 - accuracy: 0.8078\n",
      "Epoch 1129/1500\n",
      "9/9 [==============================] - 0s 564us/step - loss: 0.4320 - accuracy: 0.7985\n",
      "Epoch 1130/1500\n",
      "9/9 [==============================] - 0s 692us/step - loss: 0.4231 - accuracy: 0.8022\n",
      "Epoch 1131/1500\n",
      "9/9 [==============================] - 0s 559us/step - loss: 0.4235 - accuracy: 0.8041\n",
      "Epoch 1132/1500\n",
      "9/9 [==============================] - 0s 754us/step - loss: 0.4293 - accuracy: 0.7929\n",
      "Epoch 1133/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.4297 - accuracy: 0.7985\n",
      "Epoch 1134/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4331 - accuracy: 0.7966\n",
      "Epoch 1135/1500\n",
      "9/9 [==============================] - 0s 670us/step - loss: 0.4252 - accuracy: 0.8022\n",
      "Epoch 1136/1500\n",
      "9/9 [==============================] - 0s 559us/step - loss: 0.4194 - accuracy: 0.8116\n",
      "Epoch 1137/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.4216 - accuracy: 0.7985\n",
      "Epoch 1138/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4226 - accuracy: 0.8041\n",
      "Epoch 1139/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4243 - accuracy: 0.7985\n",
      "Epoch 1140/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.4268 - accuracy: 0.8022\n",
      "Epoch 1141/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4240 - accuracy: 0.7948\n",
      "Epoch 1142/1500\n",
      "9/9 [==============================] - 0s 620us/step - loss: 0.4358 - accuracy: 0.7854\n",
      "Epoch 1143/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4252 - accuracy: 0.7929\n",
      "Epoch 1144/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4219 - accuracy: 0.8004\n",
      "Epoch 1145/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4183 - accuracy: 0.8022\n",
      "Epoch 1146/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4220 - accuracy: 0.7985\n",
      "Epoch 1147/1500\n",
      "9/9 [==============================] - 0s 645us/step - loss: 0.4197 - accuracy: 0.8004\n",
      "Epoch 1148/1500\n",
      "9/9 [==============================] - 0s 621us/step - loss: 0.4182 - accuracy: 0.8097\n",
      "Epoch 1149/1500\n",
      "9/9 [==============================] - 0s 580us/step - loss: 0.4188 - accuracy: 0.8078\n",
      "Epoch 1150/1500\n",
      "9/9 [==============================] - 0s 773us/step - loss: 0.4177 - accuracy: 0.8097\n",
      "Epoch 1151/1500\n",
      "9/9 [==============================] - 0s 539us/step - loss: 0.4191 - accuracy: 0.8116\n",
      "Epoch 1152/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4243 - accuracy: 0.7892\n",
      "Epoch 1153/1500\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.4237 - accuracy: 0.8022\n",
      "Epoch 1154/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4237 - accuracy: 0.8022\n",
      "Epoch 1155/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4232 - accuracy: 0.8060\n",
      "Epoch 1156/1500\n",
      "9/9 [==============================] - 0s 675us/step - loss: 0.4213 - accuracy: 0.8116\n",
      "Epoch 1157/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4243 - accuracy: 0.8004\n",
      "Epoch 1158/1500\n",
      "9/9 [==============================] - 0s 649us/step - loss: 0.4502 - accuracy: 0.7836\n",
      "Epoch 1159/1500\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.4847 - accuracy: 0.7612\n",
      "Epoch 1160/1500\n",
      "9/9 [==============================] - 0s 611us/step - loss: 0.4585 - accuracy: 0.7724\n",
      "Epoch 1161/1500\n",
      "9/9 [==============================] - 0s 779us/step - loss: 0.4475 - accuracy: 0.7817\n",
      "Epoch 1162/1500\n",
      "9/9 [==============================] - 0s 538us/step - loss: 0.4369 - accuracy: 0.7910\n",
      "Epoch 1163/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4270 - accuracy: 0.8060\n",
      "Epoch 1164/1500\n",
      "9/9 [==============================] - 0s 681us/step - loss: 0.4230 - accuracy: 0.8097\n",
      "Epoch 1165/1500\n",
      "9/9 [==============================] - 0s 684us/step - loss: 0.4261 - accuracy: 0.8022\n",
      "Epoch 1166/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4180 - accuracy: 0.8078\n",
      "Epoch 1167/1500\n",
      "9/9 [==============================] - 0s 549us/step - loss: 0.4224 - accuracy: 0.8097\n",
      "Epoch 1168/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4311 - accuracy: 0.8022\n",
      "Epoch 1169/1500\n",
      "9/9 [==============================] - 0s 544us/step - loss: 0.4246 - accuracy: 0.7985\n",
      "Epoch 1170/1500\n",
      "9/9 [==============================] - 0s 709us/step - loss: 0.4323 - accuracy: 0.8041\n",
      "Epoch 1171/1500\n",
      "9/9 [==============================] - 0s 715us/step - loss: 0.4218 - accuracy: 0.8060\n",
      "Epoch 1172/1500\n",
      "9/9 [==============================] - 0s 653us/step - loss: 0.4217 - accuracy: 0.8116\n",
      "Epoch 1173/1500\n",
      "9/9 [==============================] - 0s 651us/step - loss: 0.4195 - accuracy: 0.8134\n",
      "Epoch 1174/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4226 - accuracy: 0.8134\n",
      "Epoch 1175/1500\n",
      "9/9 [==============================] - 0s 583us/step - loss: 0.4212 - accuracy: 0.8041\n",
      "Epoch 1176/1500\n",
      "9/9 [==============================] - 0s 548us/step - loss: 0.4207 - accuracy: 0.8041\n",
      "Epoch 1177/1500\n",
      "9/9 [==============================] - 0s 688us/step - loss: 0.4240 - accuracy: 0.8060\n",
      "Epoch 1178/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4245 - accuracy: 0.8060\n",
      "Epoch 1179/1500\n",
      "9/9 [==============================] - 0s 672us/step - loss: 0.4163 - accuracy: 0.8078\n",
      "Epoch 1180/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4293 - accuracy: 0.8060\n",
      "Epoch 1181/1500\n",
      "9/9 [==============================] - 0s 673us/step - loss: 0.4335 - accuracy: 0.7910\n",
      "Epoch 1182/1500\n",
      "9/9 [==============================] - 0s 725us/step - loss: 0.4315 - accuracy: 0.7836\n",
      "Epoch 1183/1500\n",
      "9/9 [==============================] - 0s 671us/step - loss: 0.4294 - accuracy: 0.7985\n",
      "Epoch 1184/1500\n",
      "9/9 [==============================] - 0s 623us/step - loss: 0.4202 - accuracy: 0.8097\n",
      "Epoch 1185/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.4218 - accuracy: 0.8078\n",
      "Epoch 1186/1500\n",
      "9/9 [==============================] - 0s 692us/step - loss: 0.4250 - accuracy: 0.8078\n",
      "Epoch 1187/1500\n",
      "9/9 [==============================] - 0s 652us/step - loss: 0.4174 - accuracy: 0.8004\n",
      "Epoch 1188/1500\n",
      "9/9 [==============================] - 0s 527us/step - loss: 0.4244 - accuracy: 0.8134\n",
      "Epoch 1189/1500\n",
      "9/9 [==============================] - 0s 670us/step - loss: 0.4200 - accuracy: 0.8134\n",
      "Epoch 1190/1500\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.4242 - accuracy: 0.8041\n",
      "Epoch 1191/1500\n",
      "9/9 [==============================] - 0s 671us/step - loss: 0.4264 - accuracy: 0.8041\n",
      "Epoch 1192/1500\n",
      "9/9 [==============================] - 0s 679us/step - loss: 0.4206 - accuracy: 0.8060\n",
      "Epoch 1193/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4172 - accuracy: 0.8153\n",
      "Epoch 1194/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4175 - accuracy: 0.8097\n",
      "Epoch 1195/1500\n",
      "9/9 [==============================] - 0s 581us/step - loss: 0.4180 - accuracy: 0.8097\n",
      "Epoch 1196/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4228 - accuracy: 0.7985\n",
      "Epoch 1197/1500\n",
      "9/9 [==============================] - 0s 591us/step - loss: 0.4235 - accuracy: 0.8097\n",
      "Epoch 1198/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4271 - accuracy: 0.8022\n",
      "Epoch 1199/1500\n",
      "9/9 [==============================] - 0s 663us/step - loss: 0.4226 - accuracy: 0.7985\n",
      "Epoch 1200/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 554us/step - loss: 0.4171 - accuracy: 0.8153\n",
      "Epoch 1201/1500\n",
      "9/9 [==============================] - 0s 742us/step - loss: 0.4173 - accuracy: 0.8078\n",
      "Epoch 1202/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4324 - accuracy: 0.7873\n",
      "Epoch 1203/1500\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.4518 - accuracy: 0.7761\n",
      "Epoch 1204/1500\n",
      "9/9 [==============================] - 0s 651us/step - loss: 0.4362 - accuracy: 0.8004\n",
      "Epoch 1205/1500\n",
      "9/9 [==============================] - 0s 679us/step - loss: 0.4244 - accuracy: 0.7948\n",
      "Epoch 1206/1500\n",
      "9/9 [==============================] - 0s 537us/step - loss: 0.4178 - accuracy: 0.8022\n",
      "Epoch 1207/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4195 - accuracy: 0.8022\n",
      "Epoch 1208/1500\n",
      "9/9 [==============================] - 0s 575us/step - loss: 0.4181 - accuracy: 0.8078\n",
      "Epoch 1209/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.4168 - accuracy: 0.8041\n",
      "Epoch 1210/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4199 - accuracy: 0.8078\n",
      "Epoch 1211/1500\n",
      "9/9 [==============================] - 0s 547us/step - loss: 0.4212 - accuracy: 0.7985\n",
      "Epoch 1212/1500\n",
      "9/9 [==============================] - 0s 721us/step - loss: 0.4205 - accuracy: 0.8060\n",
      "Epoch 1213/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.4143 - accuracy: 0.8153\n",
      "Epoch 1214/1500\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.4158 - accuracy: 0.8172\n",
      "Epoch 1215/1500\n",
      "9/9 [==============================] - 0s 599us/step - loss: 0.4229 - accuracy: 0.7910\n",
      "Epoch 1216/1500\n",
      "9/9 [==============================] - 0s 664us/step - loss: 0.4206 - accuracy: 0.8022\n",
      "Epoch 1217/1500\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.4225 - accuracy: 0.8078\n",
      "Epoch 1218/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4334 - accuracy: 0.7854\n",
      "Epoch 1219/1500\n",
      "9/9 [==============================] - 0s 646us/step - loss: 0.4239 - accuracy: 0.7985\n",
      "Epoch 1220/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4230 - accuracy: 0.8041\n",
      "Epoch 1221/1500\n",
      "9/9 [==============================] - 0s 740us/step - loss: 0.4228 - accuracy: 0.8060\n",
      "Epoch 1222/1500\n",
      "9/9 [==============================] - 0s 814us/step - loss: 0.4155 - accuracy: 0.8060\n",
      "Epoch 1223/1500\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.4179 - accuracy: 0.8116\n",
      "Epoch 1224/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4180 - accuracy: 0.8116\n",
      "Epoch 1225/1500\n",
      "9/9 [==============================] - 0s 691us/step - loss: 0.4197 - accuracy: 0.8041\n",
      "Epoch 1226/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4201 - accuracy: 0.8022\n",
      "Epoch 1227/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.4164 - accuracy: 0.8116\n",
      "Epoch 1228/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4178 - accuracy: 0.8004\n",
      "Epoch 1229/1500\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.4165 - accuracy: 0.8041\n",
      "Epoch 1230/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4152 - accuracy: 0.8041\n",
      "Epoch 1231/1500\n",
      "9/9 [==============================] - 0s 693us/step - loss: 0.4151 - accuracy: 0.8097\n",
      "Epoch 1232/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.4143 - accuracy: 0.8116\n",
      "Epoch 1233/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4221 - accuracy: 0.8004\n",
      "Epoch 1234/1500\n",
      "9/9 [==============================] - 0s 652us/step - loss: 0.4195 - accuracy: 0.8022\n",
      "Epoch 1235/1500\n",
      "9/9 [==============================] - 0s 664us/step - loss: 0.4279 - accuracy: 0.7948\n",
      "Epoch 1236/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.4257 - accuracy: 0.8004\n",
      "Epoch 1237/1500\n",
      "9/9 [==============================] - 0s 767us/step - loss: 0.4213 - accuracy: 0.7873\n",
      "Epoch 1238/1500\n",
      "9/9 [==============================] - 0s 569us/step - loss: 0.4249 - accuracy: 0.8022\n",
      "Epoch 1239/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4334 - accuracy: 0.7854\n",
      "Epoch 1240/1500\n",
      "9/9 [==============================] - 0s 638us/step - loss: 0.4407 - accuracy: 0.7948\n",
      "Epoch 1241/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4341 - accuracy: 0.8022\n",
      "Epoch 1242/1500\n",
      "9/9 [==============================] - 0s 752us/step - loss: 0.4149 - accuracy: 0.8153\n",
      "Epoch 1243/1500\n",
      "9/9 [==============================] - 0s 609us/step - loss: 0.4154 - accuracy: 0.8078\n",
      "Epoch 1244/1500\n",
      "9/9 [==============================] - 0s 709us/step - loss: 0.4317 - accuracy: 0.7985\n",
      "Epoch 1245/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4552 - accuracy: 0.7780\n",
      "Epoch 1246/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4246 - accuracy: 0.7985\n",
      "Epoch 1247/1500\n",
      "9/9 [==============================] - 0s 549us/step - loss: 0.4248 - accuracy: 0.7948\n",
      "Epoch 1248/1500\n",
      "9/9 [==============================] - 0s 686us/step - loss: 0.4138 - accuracy: 0.8097\n",
      "Epoch 1249/1500\n",
      "9/9 [==============================] - 0s 521us/step - loss: 0.4147 - accuracy: 0.8134\n",
      "Epoch 1250/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4159 - accuracy: 0.8134\n",
      "Epoch 1251/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4195 - accuracy: 0.7892\n",
      "Epoch 1252/1500\n",
      "9/9 [==============================] - 0s 673us/step - loss: 0.4274 - accuracy: 0.7985\n",
      "Epoch 1253/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4167 - accuracy: 0.8209\n",
      "Epoch 1254/1500\n",
      "9/9 [==============================] - 0s 551us/step - loss: 0.4173 - accuracy: 0.8060\n",
      "Epoch 1255/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4132 - accuracy: 0.8153\n",
      "Epoch 1256/1500\n",
      "9/9 [==============================] - 0s 618us/step - loss: 0.4132 - accuracy: 0.8078\n",
      "Epoch 1257/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4156 - accuracy: 0.8041\n",
      "Epoch 1258/1500\n",
      "9/9 [==============================] - 0s 593us/step - loss: 0.4270 - accuracy: 0.7966\n",
      "Epoch 1259/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4351 - accuracy: 0.8004\n",
      "Epoch 1260/1500\n",
      "9/9 [==============================] - 0s 559us/step - loss: 0.4197 - accuracy: 0.7948\n",
      "Epoch 1261/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.4355 - accuracy: 0.7929\n",
      "Epoch 1262/1500\n",
      "9/9 [==============================] - 0s 561us/step - loss: 0.4312 - accuracy: 0.7948\n",
      "Epoch 1263/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4176 - accuracy: 0.8022\n",
      "Epoch 1264/1500\n",
      "9/9 [==============================] - 0s 686us/step - loss: 0.4155 - accuracy: 0.8116\n",
      "Epoch 1265/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4177 - accuracy: 0.8060\n",
      "Epoch 1266/1500\n",
      "9/9 [==============================] - 0s 597us/step - loss: 0.4305 - accuracy: 0.7854\n",
      "Epoch 1267/1500\n",
      "9/9 [==============================] - 0s 618us/step - loss: 0.4509 - accuracy: 0.7854\n",
      "Epoch 1268/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4275 - accuracy: 0.8022\n",
      "Epoch 1269/1500\n",
      "9/9 [==============================] - 0s 640us/step - loss: 0.4288 - accuracy: 0.7836\n",
      "Epoch 1270/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.4216 - accuracy: 0.8097\n",
      "Epoch 1271/1500\n",
      "9/9 [==============================] - 0s 586us/step - loss: 0.4113 - accuracy: 0.8134\n",
      "Epoch 1272/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4121 - accuracy: 0.8172\n",
      "Epoch 1273/1500\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.4114 - accuracy: 0.8078\n",
      "Epoch 1274/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4195 - accuracy: 0.8004\n",
      "Epoch 1275/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4263 - accuracy: 0.7910\n",
      "Epoch 1276/1500\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.4289 - accuracy: 0.7929\n",
      "Epoch 1277/1500\n",
      "9/9 [==============================] - 0s 730us/step - loss: 0.4185 - accuracy: 0.8041\n",
      "Epoch 1278/1500\n",
      "9/9 [==============================] - 0s 655us/step - loss: 0.4160 - accuracy: 0.8022\n",
      "Epoch 1279/1500\n",
      "9/9 [==============================] - 0s 712us/step - loss: 0.4185 - accuracy: 0.8004\n",
      "Epoch 1280/1500\n",
      "9/9 [==============================] - 0s 599us/step - loss: 0.4192 - accuracy: 0.7966\n",
      "Epoch 1281/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4191 - accuracy: 0.7910\n",
      "Epoch 1282/1500\n",
      "9/9 [==============================] - 0s 694us/step - loss: 0.4263 - accuracy: 0.7873\n",
      "Epoch 1283/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4342 - accuracy: 0.7966\n",
      "Epoch 1284/1500\n",
      "9/9 [==============================] - 0s 684us/step - loss: 0.4190 - accuracy: 0.8004\n",
      "Epoch 1285/1500\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.4263 - accuracy: 0.7948\n",
      "Epoch 1286/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4226 - accuracy: 0.7929\n",
      "Epoch 1287/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4161 - accuracy: 0.7985\n",
      "Epoch 1288/1500\n",
      "9/9 [==============================] - 0s 678us/step - loss: 0.4276 - accuracy: 0.7966\n",
      "Epoch 1289/1500\n",
      "9/9 [==============================] - 0s 650us/step - loss: 0.4255 - accuracy: 0.7873\n",
      "Epoch 1290/1500\n",
      "9/9 [==============================] - 0s 623us/step - loss: 0.4134 - accuracy: 0.8116\n",
      "Epoch 1291/1500\n",
      "9/9 [==============================] - 0s 652us/step - loss: 0.4142 - accuracy: 0.8041\n",
      "Epoch 1292/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4122 - accuracy: 0.7985\n",
      "Epoch 1293/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4133 - accuracy: 0.8134\n",
      "Epoch 1294/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4083 - accuracy: 0.8060\n",
      "Epoch 1295/1500\n",
      "9/9 [==============================] - 0s 634us/step - loss: 0.4117 - accuracy: 0.8022\n",
      "Epoch 1296/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4180 - accuracy: 0.7966\n",
      "Epoch 1297/1500\n",
      "9/9 [==============================] - 0s 516us/step - loss: 0.4226 - accuracy: 0.7985\n",
      "Epoch 1298/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4178 - accuracy: 0.8004\n",
      "Epoch 1299/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4452 - accuracy: 0.7649\n",
      "Epoch 1300/1500\n",
      "9/9 [==============================] - 0s 688us/step - loss: 0.4097 - accuracy: 0.8116\n",
      "Epoch 1301/1500\n",
      "9/9 [==============================] - 0s 698us/step - loss: 0.4135 - accuracy: 0.8078\n",
      "Epoch 1302/1500\n",
      "9/9 [==============================] - 0s 600us/step - loss: 0.4114 - accuracy: 0.8097\n",
      "Epoch 1303/1500\n",
      "9/9 [==============================] - 0s 746us/step - loss: 0.4183 - accuracy: 0.7985\n",
      "Epoch 1304/1500\n",
      "9/9 [==============================] - 0s 670us/step - loss: 0.4284 - accuracy: 0.8004\n",
      "Epoch 1305/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4298 - accuracy: 0.7985\n",
      "Epoch 1306/1500\n",
      "9/9 [==============================] - 0s 595us/step - loss: 0.4211 - accuracy: 0.8004\n",
      "Epoch 1307/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.4258 - accuracy: 0.7985\n",
      "Epoch 1308/1500\n",
      "9/9 [==============================] - 0s 641us/step - loss: 0.4179 - accuracy: 0.8116\n",
      "Epoch 1309/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4159 - accuracy: 0.8041\n",
      "Epoch 1310/1500\n",
      "9/9 [==============================] - 0s 557us/step - loss: 0.4155 - accuracy: 0.8097\n",
      "Epoch 1311/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4102 - accuracy: 0.7985\n",
      "Epoch 1312/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4149 - accuracy: 0.7948\n",
      "Epoch 1313/1500\n",
      "9/9 [==============================] - 0s 623us/step - loss: 0.4252 - accuracy: 0.7929\n",
      "Epoch 1314/1500\n",
      "9/9 [==============================] - 0s 770us/step - loss: 0.4139 - accuracy: 0.8022\n",
      "Epoch 1315/1500\n",
      "9/9 [==============================] - 0s 524us/step - loss: 0.4230 - accuracy: 0.8004\n",
      "Epoch 1316/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4221 - accuracy: 0.8004\n",
      "Epoch 1317/1500\n",
      "9/9 [==============================] - 0s 512us/step - loss: 0.4424 - accuracy: 0.7929\n",
      "Epoch 1318/1500\n",
      "9/9 [==============================] - 0s 662us/step - loss: 0.4272 - accuracy: 0.7929\n",
      "Epoch 1319/1500\n",
      "9/9 [==============================] - 0s 684us/step - loss: 0.4298 - accuracy: 0.7929\n",
      "Epoch 1320/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4396 - accuracy: 0.7892\n",
      "Epoch 1321/1500\n",
      "9/9 [==============================] - 0s 782us/step - loss: 0.4278 - accuracy: 0.7985\n",
      "Epoch 1322/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4363 - accuracy: 0.7910\n",
      "Epoch 1323/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4216 - accuracy: 0.7985\n",
      "Epoch 1324/1500\n",
      "9/9 [==============================] - 0s 565us/step - loss: 0.4272 - accuracy: 0.7854\n",
      "Epoch 1325/1500\n",
      "9/9 [==============================] - 0s 672us/step - loss: 0.4153 - accuracy: 0.7929\n",
      "Epoch 1326/1500\n",
      "9/9 [==============================] - 0s 673us/step - loss: 0.4147 - accuracy: 0.8097\n",
      "Epoch 1327/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.4121 - accuracy: 0.8022\n",
      "Epoch 1328/1500\n",
      "9/9 [==============================] - 0s 701us/step - loss: 0.4157 - accuracy: 0.8022\n",
      "Epoch 1329/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4139 - accuracy: 0.8022\n",
      "Epoch 1330/1500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.4182 - accuracy: 0.8097\n",
      "Epoch 1331/1500\n",
      "9/9 [==============================] - 0s 565us/step - loss: 0.4115 - accuracy: 0.8004\n",
      "Epoch 1332/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4181 - accuracy: 0.7985\n",
      "Epoch 1333/1500\n",
      "9/9 [==============================] - 0s 640us/step - loss: 0.4254 - accuracy: 0.7910\n",
      "Epoch 1334/1500\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.4250 - accuracy: 0.7948\n",
      "Epoch 1335/1500\n",
      "9/9 [==============================] - 0s 564us/step - loss: 0.4090 - accuracy: 0.8022\n",
      "Epoch 1336/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.4163 - accuracy: 0.7948\n",
      "Epoch 1337/1500\n",
      "9/9 [==============================] - 0s 576us/step - loss: 0.4136 - accuracy: 0.8209\n",
      "Epoch 1338/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4140 - accuracy: 0.7985\n",
      "Epoch 1339/1500\n",
      "9/9 [==============================] - 0s 653us/step - loss: 0.4115 - accuracy: 0.8060\n",
      "Epoch 1340/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.4173 - accuracy: 0.7966\n",
      "Epoch 1341/1500\n",
      "9/9 [==============================] - 0s 663us/step - loss: 0.4301 - accuracy: 0.8004\n",
      "Epoch 1342/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.4201 - accuracy: 0.8004\n",
      "Epoch 1343/1500\n",
      "9/9 [==============================] - 0s 740us/step - loss: 0.4117 - accuracy: 0.8060\n",
      "Epoch 1344/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4133 - accuracy: 0.8097\n",
      "Epoch 1345/1500\n",
      "9/9 [==============================] - 0s 673us/step - loss: 0.4267 - accuracy: 0.7854\n",
      "Epoch 1346/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4067 - accuracy: 0.8153\n",
      "Epoch 1347/1500\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4147 - accuracy: 0.8078\n",
      "Epoch 1348/1500\n",
      "9/9 [==============================] - 0s 562us/step - loss: 0.4149 - accuracy: 0.8060\n",
      "Epoch 1349/1500\n",
      "9/9 [==============================] - 0s 662us/step - loss: 0.4086 - accuracy: 0.8097\n",
      "Epoch 1350/1500\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.4182 - accuracy: 0.8041\n",
      "Epoch 1351/1500\n",
      "9/9 [==============================] - 0s 675us/step - loss: 0.4264 - accuracy: 0.7948\n",
      "Epoch 1352/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4194 - accuracy: 0.7966\n",
      "Epoch 1353/1500\n",
      "9/9 [==============================] - 0s 676us/step - loss: 0.4134 - accuracy: 0.8004\n",
      "Epoch 1354/1500\n",
      "9/9 [==============================] - 0s 680us/step - loss: 0.4138 - accuracy: 0.8004\n",
      "Epoch 1355/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4098 - accuracy: 0.8078\n",
      "Epoch 1356/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4210 - accuracy: 0.7854\n",
      "Epoch 1357/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4193 - accuracy: 0.7966\n",
      "Epoch 1358/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 674us/step - loss: 0.4093 - accuracy: 0.8078\n",
      "Epoch 1359/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4214 - accuracy: 0.7948\n",
      "Epoch 1360/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4219 - accuracy: 0.7985\n",
      "Epoch 1361/1500\n",
      "9/9 [==============================] - 0s 683us/step - loss: 0.4213 - accuracy: 0.7910\n",
      "Epoch 1362/1500\n",
      "9/9 [==============================] - 0s 672us/step - loss: 0.4212 - accuracy: 0.7948\n",
      "Epoch 1363/1500\n",
      "9/9 [==============================] - 0s 767us/step - loss: 0.4298 - accuracy: 0.7705\n",
      "Epoch 1364/1500\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.4330 - accuracy: 0.7892\n",
      "Epoch 1365/1500\n",
      "9/9 [==============================] - 0s 614us/step - loss: 0.4427 - accuracy: 0.7892\n",
      "Epoch 1366/1500\n",
      "9/9 [==============================] - 0s 663us/step - loss: 0.4352 - accuracy: 0.7817\n",
      "Epoch 1367/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4391 - accuracy: 0.7799\n",
      "Epoch 1368/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4119 - accuracy: 0.8078\n",
      "Epoch 1369/1500\n",
      "9/9 [==============================] - 0s 674us/step - loss: 0.4077 - accuracy: 0.8172\n",
      "Epoch 1370/1500\n",
      "9/9 [==============================] - 0s 622us/step - loss: 0.4145 - accuracy: 0.8116\n",
      "Epoch 1371/1500\n",
      "9/9 [==============================] - 0s 673us/step - loss: 0.4257 - accuracy: 0.8060\n",
      "Epoch 1372/1500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.4203 - accuracy: 0.7854\n",
      "Epoch 1373/1500\n",
      "9/9 [==============================] - 0s 743us/step - loss: 0.4344 - accuracy: 0.7799\n",
      "Epoch 1374/1500\n",
      "9/9 [==============================] - 0s 655us/step - loss: 0.4199 - accuracy: 0.7929\n",
      "Epoch 1375/1500\n",
      "9/9 [==============================] - 0s 660us/step - loss: 0.4091 - accuracy: 0.8041\n",
      "Epoch 1376/1500\n",
      "9/9 [==============================] - 0s 576us/step - loss: 0.4088 - accuracy: 0.8078\n",
      "Epoch 1377/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4097 - accuracy: 0.8041\n",
      "Epoch 1378/1500\n",
      "9/9 [==============================] - 0s 672us/step - loss: 0.4157 - accuracy: 0.7985\n",
      "Epoch 1379/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4148 - accuracy: 0.8116\n",
      "Epoch 1380/1500\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.4140 - accuracy: 0.8041\n",
      "Epoch 1381/1500\n",
      "9/9 [==============================] - 0s 562us/step - loss: 0.4149 - accuracy: 0.7929\n",
      "Epoch 1382/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4038 - accuracy: 0.8190\n",
      "Epoch 1383/1500\n",
      "9/9 [==============================] - 0s 719us/step - loss: 0.4094 - accuracy: 0.7966\n",
      "Epoch 1384/1500\n",
      "9/9 [==============================] - 0s 822us/step - loss: 0.4090 - accuracy: 0.8078\n",
      "Epoch 1385/1500\n",
      "9/9 [==============================] - 0s 458us/step - loss: 0.4202 - accuracy: 0.8004\n",
      "Epoch 1386/1500\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.4079 - accuracy: 0.8041\n",
      "Epoch 1387/1500\n",
      "9/9 [==============================] - 0s 606us/step - loss: 0.4130 - accuracy: 0.8078\n",
      "Epoch 1388/1500\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4100 - accuracy: 0.8097\n",
      "Epoch 1389/1500\n",
      "9/9 [==============================] - 0s 676us/step - loss: 0.4053 - accuracy: 0.8022\n",
      "Epoch 1390/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4058 - accuracy: 0.8041\n",
      "Epoch 1391/1500\n",
      "9/9 [==============================] - 0s 777us/step - loss: 0.4085 - accuracy: 0.8190\n",
      "Epoch 1392/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4135 - accuracy: 0.8041\n",
      "Epoch 1393/1500\n",
      "9/9 [==============================] - 0s 710us/step - loss: 0.4075 - accuracy: 0.8041\n",
      "Epoch 1394/1500\n",
      "9/9 [==============================] - 0s 679us/step - loss: 0.4091 - accuracy: 0.8134\n",
      "Epoch 1395/1500\n",
      "9/9 [==============================] - 0s 728us/step - loss: 0.4064 - accuracy: 0.8041\n",
      "Epoch 1396/1500\n",
      "9/9 [==============================] - 0s 605us/step - loss: 0.4069 - accuracy: 0.7966\n",
      "Epoch 1397/1500\n",
      "9/9 [==============================] - 0s 553us/step - loss: 0.4095 - accuracy: 0.8004\n",
      "Epoch 1398/1500\n",
      "9/9 [==============================] - 0s 664us/step - loss: 0.4107 - accuracy: 0.8060\n",
      "Epoch 1399/1500\n",
      "9/9 [==============================] - 0s 571us/step - loss: 0.4097 - accuracy: 0.8078\n",
      "Epoch 1400/1500\n",
      "9/9 [==============================] - 0s 688us/step - loss: 0.4178 - accuracy: 0.8004\n",
      "Epoch 1401/1500\n",
      "9/9 [==============================] - 0s 663us/step - loss: 0.4099 - accuracy: 0.8116\n",
      "Epoch 1402/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4068 - accuracy: 0.8041\n",
      "Epoch 1403/1500\n",
      "9/9 [==============================] - 0s 703us/step - loss: 0.4090 - accuracy: 0.8097\n",
      "Epoch 1404/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4078 - accuracy: 0.8060\n",
      "Epoch 1405/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4127 - accuracy: 0.8078\n",
      "Epoch 1406/1500\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.4174 - accuracy: 0.7948\n",
      "Epoch 1407/1500\n",
      "9/9 [==============================] - 0s 587us/step - loss: 0.4099 - accuracy: 0.8060\n",
      "Epoch 1408/1500\n",
      "9/9 [==============================] - 0s 663us/step - loss: 0.4109 - accuracy: 0.8116\n",
      "Epoch 1409/1500\n",
      "9/9 [==============================] - 0s 541us/step - loss: 0.4062 - accuracy: 0.8134\n",
      "Epoch 1410/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4043 - accuracy: 0.8097\n",
      "Epoch 1411/1500\n",
      "9/9 [==============================] - 0s 672us/step - loss: 0.4089 - accuracy: 0.8078\n",
      "Epoch 1412/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4117 - accuracy: 0.7985\n",
      "Epoch 1413/1500\n",
      "9/9 [==============================] - 0s 708us/step - loss: 0.4192 - accuracy: 0.7929\n",
      "Epoch 1414/1500\n",
      "9/9 [==============================] - 0s 616us/step - loss: 0.4050 - accuracy: 0.8097\n",
      "Epoch 1415/1500\n",
      "9/9 [==============================] - 0s 768us/step - loss: 0.4167 - accuracy: 0.7948\n",
      "Epoch 1416/1500\n",
      "9/9 [==============================] - 0s 544us/step - loss: 0.4239 - accuracy: 0.7966\n",
      "Epoch 1417/1500\n",
      "9/9 [==============================] - 0s 788us/step - loss: 0.4220 - accuracy: 0.7892\n",
      "Epoch 1418/1500\n",
      "9/9 [==============================] - 0s 708us/step - loss: 0.4108 - accuracy: 0.8116\n",
      "Epoch 1419/1500\n",
      "9/9 [==============================] - 0s 655us/step - loss: 0.4068 - accuracy: 0.8078\n",
      "Epoch 1420/1500\n",
      "9/9 [==============================] - 0s 724us/step - loss: 0.4093 - accuracy: 0.8022\n",
      "Epoch 1421/1500\n",
      "9/9 [==============================] - 0s 653us/step - loss: 0.4125 - accuracy: 0.8060\n",
      "Epoch 1422/1500\n",
      "9/9 [==============================] - 0s 632us/step - loss: 0.4309 - accuracy: 0.7966\n",
      "Epoch 1423/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4287 - accuracy: 0.7892\n",
      "Epoch 1424/1500\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.4126 - accuracy: 0.7966\n",
      "Epoch 1425/1500\n",
      "9/9 [==============================] - 0s 549us/step - loss: 0.4244 - accuracy: 0.7892\n",
      "Epoch 1426/1500\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.4078 - accuracy: 0.8116\n",
      "Epoch 1427/1500\n",
      "9/9 [==============================] - 0s 443us/step - loss: 0.4030 - accuracy: 0.8041\n",
      "Epoch 1428/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4095 - accuracy: 0.8004\n",
      "Epoch 1429/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4109 - accuracy: 0.8097\n",
      "Epoch 1430/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4062 - accuracy: 0.8004\n",
      "Epoch 1431/1500\n",
      "9/9 [==============================] - 0s 714us/step - loss: 0.4105 - accuracy: 0.8078\n",
      "Epoch 1432/1500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.4078 - accuracy: 0.8172\n",
      "Epoch 1433/1500\n",
      "9/9 [==============================] - 0s 752us/step - loss: 0.4084 - accuracy: 0.8060\n",
      "Epoch 1434/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4048 - accuracy: 0.8060\n",
      "Epoch 1435/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.4052 - accuracy: 0.7985\n",
      "Epoch 1436/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.4054 - accuracy: 0.8097\n",
      "Epoch 1437/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4058 - accuracy: 0.8153\n",
      "Epoch 1438/1500\n",
      "9/9 [==============================] - 0s 605us/step - loss: 0.4079 - accuracy: 0.8041\n",
      "Epoch 1439/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4043 - accuracy: 0.8116\n",
      "Epoch 1440/1500\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.3987 - accuracy: 0.8097\n",
      "Epoch 1441/1500\n",
      "9/9 [==============================] - 0s 698us/step - loss: 0.4063 - accuracy: 0.8116\n",
      "Epoch 1442/1500\n",
      "9/9 [==============================] - 0s 648us/step - loss: 0.4088 - accuracy: 0.8134\n",
      "Epoch 1443/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4062 - accuracy: 0.8022\n",
      "Epoch 1444/1500\n",
      "9/9 [==============================] - 0s 516us/step - loss: 0.4032 - accuracy: 0.8004\n",
      "Epoch 1445/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4062 - accuracy: 0.8078\n",
      "Epoch 1446/1500\n",
      "9/9 [==============================] - 0s 603us/step - loss: 0.4103 - accuracy: 0.8041\n",
      "Epoch 1447/1500\n",
      "9/9 [==============================] - 0s 608us/step - loss: 0.4117 - accuracy: 0.8060\n",
      "Epoch 1448/1500\n",
      "9/9 [==============================] - 0s 681us/step - loss: 0.4099 - accuracy: 0.8060\n",
      "Epoch 1449/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4055 - accuracy: 0.8078\n",
      "Epoch 1450/1500\n",
      "9/9 [==============================] - 0s 714us/step - loss: 0.4042 - accuracy: 0.8097\n",
      "Epoch 1451/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4033 - accuracy: 0.8097\n",
      "Epoch 1452/1500\n",
      "9/9 [==============================] - 0s 783us/step - loss: 0.4045 - accuracy: 0.8041\n",
      "Epoch 1453/1500\n",
      "9/9 [==============================] - 0s 518us/step - loss: 0.4091 - accuracy: 0.8022\n",
      "Epoch 1454/1500\n",
      "9/9 [==============================] - 0s 659us/step - loss: 0.4097 - accuracy: 0.8078\n",
      "Epoch 1455/1500\n",
      "9/9 [==============================] - 0s 624us/step - loss: 0.4032 - accuracy: 0.8060\n",
      "Epoch 1456/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4077 - accuracy: 0.8078\n",
      "Epoch 1457/1500\n",
      "9/9 [==============================] - 0s 728us/step - loss: 0.4054 - accuracy: 0.8097\n",
      "Epoch 1458/1500\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4883 - accuracy: 0.70 - 0s 554us/step - loss: 0.4034 - accuracy: 0.7966\n",
      "Epoch 1459/1500\n",
      "9/9 [==============================] - 0s 563us/step - loss: 0.4205 - accuracy: 0.8004\n",
      "Epoch 1460/1500\n",
      "9/9 [==============================] - 0s 552us/step - loss: 0.4876 - accuracy: 0.7612\n",
      "Epoch 1461/1500\n",
      "9/9 [==============================] - 0s 797us/step - loss: 0.4274 - accuracy: 0.7966\n",
      "Epoch 1462/1500\n",
      "9/9 [==============================] - 0s 576us/step - loss: 0.4059 - accuracy: 0.8022\n",
      "Epoch 1463/1500\n",
      "9/9 [==============================] - 0s 624us/step - loss: 0.4059 - accuracy: 0.8041\n",
      "Epoch 1464/1500\n",
      "9/9 [==============================] - 0s 562us/step - loss: 0.4060 - accuracy: 0.8041\n",
      "Epoch 1465/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4135 - accuracy: 0.7985\n",
      "Epoch 1466/1500\n",
      "9/9 [==============================] - 0s 598us/step - loss: 0.4110 - accuracy: 0.8022\n",
      "Epoch 1467/1500\n",
      "9/9 [==============================] - 0s 662us/step - loss: 0.4085 - accuracy: 0.8060\n",
      "Epoch 1468/1500\n",
      "9/9 [==============================] - 0s 688us/step - loss: 0.4046 - accuracy: 0.8078\n",
      "Epoch 1469/1500\n",
      "9/9 [==============================] - 0s 642us/step - loss: 0.4001 - accuracy: 0.8022\n",
      "Epoch 1470/1500\n",
      "9/9 [==============================] - 0s 552us/step - loss: 0.4162 - accuracy: 0.7910\n",
      "Epoch 1471/1500\n",
      "9/9 [==============================] - 0s 657us/step - loss: 0.4163 - accuracy: 0.8004\n",
      "Epoch 1472/1500\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.4332 - accuracy: 0.7817\n",
      "Epoch 1473/1500\n",
      "9/9 [==============================] - 0s 552us/step - loss: 0.4342 - accuracy: 0.7649\n",
      "Epoch 1474/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4076 - accuracy: 0.8004\n",
      "Epoch 1475/1500\n",
      "9/9 [==============================] - 0s 715us/step - loss: 0.4050 - accuracy: 0.8097\n",
      "Epoch 1476/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.4129 - accuracy: 0.8116\n",
      "Epoch 1477/1500\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.3988 - accuracy: 0.8060\n",
      "Epoch 1478/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4130 - accuracy: 0.8153\n",
      "Epoch 1479/1500\n",
      "9/9 [==============================] - 0s 694us/step - loss: 0.4104 - accuracy: 0.8116\n",
      "Epoch 1480/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4109 - accuracy: 0.8004\n",
      "Epoch 1481/1500\n",
      "9/9 [==============================] - 0s 682us/step - loss: 0.4151 - accuracy: 0.7948\n",
      "Epoch 1482/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4179 - accuracy: 0.7948\n",
      "Epoch 1483/1500\n",
      "9/9 [==============================] - 0s 795us/step - loss: 0.4032 - accuracy: 0.7985\n",
      "Epoch 1484/1500\n",
      "9/9 [==============================] - 0s 633us/step - loss: 0.4089 - accuracy: 0.7985\n",
      "Epoch 1485/1500\n",
      "9/9 [==============================] - 0s 698us/step - loss: 0.4075 - accuracy: 0.8004\n",
      "Epoch 1486/1500\n",
      "9/9 [==============================] - 0s 615us/step - loss: 0.4180 - accuracy: 0.8004\n",
      "Epoch 1487/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4067 - accuracy: 0.8004\n",
      "Epoch 1488/1500\n",
      "9/9 [==============================] - 0s 702us/step - loss: 0.4023 - accuracy: 0.8097\n",
      "Epoch 1489/1500\n",
      "9/9 [==============================] - 0s 771us/step - loss: 0.4180 - accuracy: 0.7929\n",
      "Epoch 1490/1500\n",
      "9/9 [==============================] - 0s 556us/step - loss: 0.4136 - accuracy: 0.8060\n",
      "Epoch 1491/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4134 - accuracy: 0.8004\n",
      "Epoch 1492/1500\n",
      "9/9 [==============================] - 0s 557us/step - loss: 0.4067 - accuracy: 0.8060\n",
      "Epoch 1493/1500\n",
      "9/9 [==============================] - 0s 545us/step - loss: 0.4083 - accuracy: 0.8097\n",
      "Epoch 1494/1500\n",
      "9/9 [==============================] - 0s 658us/step - loss: 0.4038 - accuracy: 0.8116\n",
      "Epoch 1495/1500\n",
      "9/9 [==============================] - 0s 607us/step - loss: 0.4043 - accuracy: 0.8060\n",
      "Epoch 1496/1500\n",
      "9/9 [==============================] - 0s 663us/step - loss: 0.4012 - accuracy: 0.8041\n",
      "Epoch 1497/1500\n",
      "9/9 [==============================] - 0s 699us/step - loss: 0.4047 - accuracy: 0.8097\n",
      "Epoch 1498/1500\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4016 - accuracy: 0.8060\n",
      "Epoch 1499/1500\n",
      "9/9 [==============================] - 0s 550us/step - loss: 0.3994 - accuracy: 0.8097\n",
      "Epoch 1500/1500\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.3972 - accuracy: 0.8153\n",
      "8/8 [==============================] - 0s 494us/step - loss: 0.5775 - accuracy: 0.7056\n",
      "accuracy:70.56%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "seed=0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "df=pd.read_csv('C:/Users/user/machine_learning1/pima-indians-diabetes.csv')  \n",
    "dataset=df.values\n",
    "X=dataset[:,0:8]\n",
    "Y=dataset[:,8]\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=seed) \n",
    "#x_train=dataset[:700,0:8]\n",
    "#y_train=dataset[:700,8]\n",
    "#x_test=dataset[700:,0:8]\n",
    "#y_test=dataset[700:,8]\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))  \n",
    "       \n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(X_train,Y_train,epochs=1500,batch_size=64)\n",
    "\n",
    "scores=model.evaluate(X_test,Y_test)\n",
    "#print('Test Accuracy:{}'.format(model.evaluate(X_test,Y_test)[1])) \n",
    "print('%s:%.2f%%'%(model.metrics_names[1],scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습셋 이미지 수 : 60000개\n",
      "테스트셋 이미지 수 : 10000개\n"
     ]
    }
   ],
   "source": [
    "(X_train,Y_class_train),(X_test,Y_class_test)=mnist.load_data()  #학습셋, 검증셋\n",
    "print('학습셋 이미지 수 : {}개'.format(X_train.shape[0]))  #kears의 mnist 70000개 데이터 중 60000개는 학습셋,10000개는 데이터셋\n",
    "print('테스트셋 이미지 수 : {}개'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  3 18 18 18126136175 26166255247127  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 30 36 94154170253253253253253225172253242195 64  0  0  0  0\n",
      "  0  0  0  0  0  0  0 49238253253253253253253253253251 93 82 82 56 39  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0 18219253253253253253198182247241  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 80156107253253205 11  0 43154  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 14  1154253 90  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0139253190  2  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 11190253 70  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 35241225160108  1  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0 81240253253119 25  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 45186253253150 27  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16 93252253187  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0249253249 64  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 46130183253253207  2  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 39148229253253253250182  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0 24114221253253253253201 78  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 23 66213253253253253198 81  2  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 18171219253253253253195 80  9  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0 55172226253253253253244133 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0136253253253212135132 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0],cmap='Greys') #.imshow : 이미지 불러옴\n",
    "plt.show()\n",
    "\n",
    "#가로28x세로28=784개의 픽셀로 이루어져있음\n",
    "#255개의 등급으로 색깔진함 정도가 나뉨\n",
    "\n",
    "#이미지는 숫자의 집합으로 바뀌어 학습셋으로 사용됨\n",
    "#28x28=784개의 속성을 이용해, 0~9까지 10개 클래스 중 하나를 맞히는 문제가 됨\n",
    "\n",
    "import sys\n",
    "\n",
    "for x in X_train[0]:\n",
    "    for i in x:\n",
    "        sys.stdout.write('%3d' % i)\n",
    "    sys.stdout.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 속성(이미지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class:5\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.reshape(X_train.shape[0],784) #28x28개의 2차원 배열을 784개의 1차원 배열로 바꾸어주어야함\n",
    "#정규화 : 케라스는 데이터를 0~1로 변환할 때 최적의 성능 -> 0~255를 0~1로 바꾸어주어야함(/255)\n",
    "X_train=X_train.astype('float64') #나누기위해 실수형으로 먼저 바꿔줌\n",
    "X_train=X_train/255\n",
    "\n",
    "X_test=X_test.reshape(X_test.shape[0],784).astype('float64')/255\n",
    "\n",
    "print('class:{}'.format(Y_class_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#np_utils.to_categorical(클래스,클래스의 개수) : [5]를 [0,0,0,0,1,0,0,0,0,0]으로 바꿔줌\n",
    "from keras.utils import np_utils\n",
    "\n",
    "Y_train=np_utils.to_categorical(Y_class_train,10) \n",
    "Y_test=np_utils.to_categorical(Y_class_test,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (합치기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습셋 이미지 수 : 60000개\n",
      "테스트셋 이미지 수 : 10000개\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  3 18 18 18126136175 26166255247127  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 30 36 94154170253253253253253225172253242195 64  0  0  0  0\n",
      "  0  0  0  0  0  0  0 49238253253253253253253253253251 93 82 82 56 39  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0 18219253253253253253198182247241  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 80156107253253205 11  0 43154  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 14  1154253 90  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0139253190  2  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 11190253 70  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 35241225160108  1  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0 81240253253119 25  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 45186253253150 27  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16 93252253187  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0249253249 64  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 46130183253253207  2  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0 39148229253253253250182  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0 24114221253253253253201 78  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 23 66213253253253253198 81  2  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 18171219253253253253195 80  9  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0 55172226253253253253244133 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0136253253253212135132 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.26976, saving model to ./model\\01-0.2698.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.26976 to 0.21997, saving model to ./model\\02-0.2200.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21997 to 0.19050, saving model to ./model\\03-0.1905.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.19050 to 0.17972, saving model to ./model\\04-0.1797.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.17972 to 0.16359, saving model to ./model\\05-0.1636.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.16359 to 0.15364, saving model to ./model\\06-0.1536.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.15364 to 0.14364, saving model to ./model\\07-0.1436.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.14364 to 0.13726, saving model to ./model\\08-0.1373.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.13726 to 0.13019, saving model to ./model\\09-0.1302.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.13019 to 0.12921, saving model to ./model\\10-0.1292.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.12921 to 0.12392, saving model to ./model\\11-0.1239.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.12392 to 0.11806, saving model to ./model\\12-0.1181.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.11806 to 0.11739, saving model to ./model\\13-0.1174.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.11739 to 0.11210, saving model to ./model\\14-0.1121.hdf5\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.11210\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.11210\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.11210\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.11210\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.11210\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.11210 to 0.11122, saving model to ./model\\20-0.1112.hdf5\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.11122\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.11122\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.11122\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.11122\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.11122\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.11122\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.11122\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.11122\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.11122\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.11122\n",
      "313/313 [==============================] - 0s 855us/step - loss: 0.1278 - accuracy: 0.9637\n",
      "Accuracy:0.963699996471405\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "seed=0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "(X_train,Y_class_train),(X_test,Y_class_test)=mnist.load_data()  \n",
    "print('학습셋 이미지 수 : {}개'.format(X_train.shape[0]))  \n",
    "print('테스트셋 이미지 수 : {}개'.format(X_test.shape[0]))\n",
    "\n",
    "plt.imshow(X_train[0],cmap='Greys') \n",
    "plt.show()\n",
    "\n",
    "for x in X_train[0]:\n",
    "    for i in x:\n",
    "        sys.stdout.write('%3d' % i)\n",
    "    sys.stdout.write('\\n')\n",
    "\n",
    "#차원 변환 과정(속성인 이미지를 0~1로 정규화)\n",
    "X_train=X_train.reshape(X_train.shape[0],784).astype('float64')/255 \n",
    "X_test=X_test.reshape(X_test.shape[0],784).astype('float64')/255\n",
    "\n",
    "#클래스 값 확인\n",
    "#print('class:{}'.format(Y_class_train[0]))\n",
    "#바이너리화 과정(클래스를 0과 1로 표현)\n",
    "Y_train=np_utils.to_categorical(Y_class_train,10) \n",
    "Y_test=np_utils.to_categorical(Y_class_test,10)\n",
    "\n",
    "#print(Y_train[0])\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(30,input_dim=784,activation='relu'))\n",
    "model.add(Dense(30,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax')) #이진법이 아니니까\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#모델 저장 폴더 만들기\n",
    "import os\n",
    "MODEL_DIR='./model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "modelpath='./model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "#모델 업데이트 및 저장\n",
    "checkpointer=ModelCheckpoint(filepath=modelpath,monitor='val_loss',verbose=1,save_best_only=True) #validation_data에서 val_loss\n",
    "\n",
    "#학습 자동중단 설정\n",
    "early_stopping_callback=EarlyStopping(monitor='val_loss',patience=10) \n",
    "\n",
    "#모델 실행\n",
    "hist=model.fit(X_train,Y_train,epochs=30,batch_size=200,validation_data=(X_test,Y_test), #검증데이터를 X_test,Y_test로 하겠다\n",
    "               verbose=0,callbacks=[early_stopping_callback,checkpointer]) #validation_split 필요없음(테스트셋,학습셋 나눴으니까)\n",
    "\n",
    "print('Accuracy:{}'.format(model.evaluate(X_test,Y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss=hist.history['val_loss'] #검증 손실값\n",
    "y_loss=hist.history['loss']  #훈련 손실값\n",
    "\n",
    "x_len=np.arange(len(y_loss))\n",
    "plt.plot(x_len,y_vloss,'o',marker='.',c='red',label='Testset_loss')\n",
    "plt.plot(x_len,y_loss,'o',marker='.',c='blue',label='Trainset_loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.4.0.42-cp37-cp37m-win_amd64.whl (33.5 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\user\\anaconda3\\envs\\new\\lib\\site-packages (from opencv-python) (1.18.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.4.0.42\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21df5e31788>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.save('C:/Users/user/machine_learning1/my_model.h5')\n",
    "model=load_model('C:/Users/user/machine_learning1/my_model.h5')\n",
    "\n",
    "img_1=mpimg.imread('C:/Users/user/machine_learning1/a.png')\n",
    "img_2=mpimg.imread('C:/Users/user/machine_learning1/b.png')\n",
    "img_3=mpimg.imread('C:/Users/user/machine_learning1/c.png')\n",
    "\n",
    "img_1=cv2.cvtColor(img_1,cv2.COLOR_BGR2GRAY)\n",
    "img_2=cv2.cvtColor(img_2,cv2.COLOR_BGR2GRAY)\n",
    "img_3=cv2.cvtColor(img_3,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.imshow(img_1)\n",
    "plt.imshow(img_2)\n",
    "plt.imshow(img_3,cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "for x in img_3:\n",
    "    for i in x:\n",
    "        sys.stdout.write('%3d' % i)\n",
    "    sys.stdout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer is [5]\n"
     ]
    }
   ],
   "source": [
    "img_3=img_3.reshape(1,784).astype('float64')/255\n",
    "print('Answer is',model.predict_classes(img_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 컨볼루션 신경망(CNN)  \n",
    "컨볼루션층과 서브샘플링층을 반복적으로 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.2753 - accuracy: 0.9173\n",
      "Epoch 00001: val_loss improved from inf to 0.05715, saving model to ./model_cnn\\01-0.0572.hdf5\n",
      "300/300 [==============================] - 36s 119ms/step - loss: 0.2753 - accuracy: 0.9173 - val_loss: 0.0572 - val_accuracy: 0.9824\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.9734\n",
      "Epoch 00002: val_loss improved from 0.05715 to 0.04355, saving model to ./model_cnn\\02-0.0435.hdf5\n",
      "300/300 [==============================] - 36s 119ms/step - loss: 0.0905 - accuracy: 0.9734 - val_loss: 0.0435 - val_accuracy: 0.9852\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9797\n",
      "Epoch 00003: val_loss improved from 0.04355 to 0.03457, saving model to ./model_cnn\\03-0.0346.hdf5\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.0680 - accuracy: 0.9797 - val_loss: 0.0346 - val_accuracy: 0.9877\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9836\n",
      "Epoch 00004: val_loss improved from 0.03457 to 0.03444, saving model to ./model_cnn\\04-0.0344.hdf5\n",
      "300/300 [==============================] - 35s 118ms/step - loss: 0.0544 - accuracy: 0.9836 - val_loss: 0.0344 - val_accuracy: 0.9891\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9853\n",
      "Epoch 00005: val_loss improved from 0.03444 to 0.02862, saving model to ./model_cnn\\05-0.0286.hdf5\n",
      "300/300 [==============================] - 36s 120ms/step - loss: 0.0470 - accuracy: 0.9853 - val_loss: 0.0286 - val_accuracy: 0.9905\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.9874\n",
      "Epoch 00006: val_loss improved from 0.02862 to 0.02826, saving model to ./model_cnn\\06-0.0283.hdf5\n",
      "300/300 [==============================] - 37s 122ms/step - loss: 0.0406 - accuracy: 0.9874 - val_loss: 0.0283 - val_accuracy: 0.9907\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9883\n",
      "Epoch 00007: val_loss improved from 0.02826 to 0.02651, saving model to ./model_cnn\\07-0.0265.hdf5\n",
      "300/300 [==============================] - 37s 123ms/step - loss: 0.0359 - accuracy: 0.9883 - val_loss: 0.0265 - val_accuracy: 0.9911\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9892\n",
      "Epoch 00008: val_loss did not improve from 0.02651\n",
      "300/300 [==============================] - 36s 120ms/step - loss: 0.0330 - accuracy: 0.9892 - val_loss: 0.0311 - val_accuracy: 0.9900\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9907\n",
      "Epoch 00009: val_loss did not improve from 0.02651\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.0287 - accuracy: 0.9907 - val_loss: 0.0273 - val_accuracy: 0.9916\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9911\n",
      "Epoch 00010: val_loss did not improve from 0.02651\n",
      "300/300 [==============================] - 37s 122ms/step - loss: 0.0270 - accuracy: 0.9911 - val_loss: 0.0284 - val_accuracy: 0.9918\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9908\n",
      "Epoch 00011: val_loss did not improve from 0.02651\n",
      "300/300 [==============================] - 37s 122ms/step - loss: 0.0262 - accuracy: 0.9908 - val_loss: 0.0310 - val_accuracy: 0.9903\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9921\n",
      "Epoch 00012: val_loss did not improve from 0.02651\n",
      "300/300 [==============================] - 36s 122ms/step - loss: 0.0227 - accuracy: 0.9921 - val_loss: 0.0286 - val_accuracy: 0.9918\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9931\n",
      "Epoch 00013: val_loss did not improve from 0.02651\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.0288 - val_accuracy: 0.9915\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9935\n",
      "Epoch 00014: val_loss did not improve from 0.02651\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.0188 - accuracy: 0.9935 - val_loss: 0.0283 - val_accuracy: 0.9929\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9931\n",
      "Epoch 00015: val_loss did not improve from 0.02651\n",
      "300/300 [==============================] - 37s 122ms/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 0.0273 - val_accuracy: 0.9929\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9940\n",
      "Epoch 00016: val_loss improved from 0.02651 to 0.02609, saving model to ./model_cnn\\16-0.0261.hdf5\n",
      "300/300 [==============================] - 37s 123ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.0261 - val_accuracy: 0.9936\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9945\n",
      "Epoch 00017: val_loss did not improve from 0.02609\n",
      "300/300 [==============================] - 37s 122ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.0264 - val_accuracy: 0.9931\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9951\n",
      "Epoch 00018: val_loss did not improve from 0.02609\n",
      "300/300 [==============================] - 37s 122ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0327 - val_accuracy: 0.9926\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9949\n",
      "Epoch 00019: val_loss did not improve from 0.02609\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0269 - val_accuracy: 0.9927\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9948\n",
      "Epoch 00020: val_loss did not improve from 0.02609\n",
      "300/300 [==============================] - 37s 122ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 0.0294 - val_accuracy: 0.9936\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9952\n",
      "Epoch 00021: val_loss did not improve from 0.02609\n",
      "300/300 [==============================] - 37s 122ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0303 - val_accuracy: 0.9927\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9952\n",
      "Epoch 00022: val_loss did not improve from 0.02609\n",
      "300/300 [==============================] - 37s 122ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0361 - val_accuracy: 0.9925\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9956\n",
      "Epoch 00023: val_loss did not improve from 0.02609\n",
      "300/300 [==============================] - 37s 123ms/step - loss: 0.0127 - accuracy: 0.9956 - val_loss: 0.0349 - val_accuracy: 0.9930\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9958\n",
      "Epoch 00024: val_loss did not improve from 0.02609\n",
      "300/300 [==============================] - 37s 122ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.0323 - val_accuracy: 0.9921\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9950\n",
      "Epoch 00025: val_loss did not improve from 0.02609\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.0142 - accuracy: 0.9950 - val_loss: 0.0314 - val_accuracy: 0.9929\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9956\n",
      "Epoch 00026: val_loss did not improve from 0.02609\n",
      "300/300 [==============================] - 36s 121ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.0298 - val_accuracy: 0.9928\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0298 - accuracy: 0.9928\n",
      "Accuracy:0.9927999973297119\n"
     ]
    }
   ],
   "source": [
    "seed=0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "(X_train,Y_class_train),(X_test,Y_class_test)=mnist.load_data()  \n",
    "X_train=X_train.reshape(X_train.shape[0],28,28,1).astype('float32')/255 \n",
    "X_test=X_test.reshape(X_test.shape[0],28,28,1).astype('float32')/255\n",
    "#원-핫 인코딩 방식 적용\n",
    "Y_train=np_utils.to_categorical(Y_class_train,10) \n",
    "Y_test=np_utils.to_categorical(Y_class_test,10)\n",
    "\n",
    "#컨볼루션 신경망 설정\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,kernel_size=(3,3),input_shape=(28,28,1),activation='relu'))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=2)) #결과 여전히 크고 복잡하면, 다시한번 축소해줌->구역 나눠서 큰 값 추출\n",
    "\n",
    "model.add(Dropout(0.25)) #과적합 피함(25%의 노드를 끔)\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "MODEL_DIR='./model_cnn/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "modelpath='./model_cnn/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "checkpointer=ModelCheckpoint(filepath=modelpath,monitor='val_loss',verbose=1,save_best_only=True) \n",
    "\n",
    "early_stopping_callback=EarlyStopping(monitor='val_loss',patience=10) \n",
    "\n",
    "#모델 실행\n",
    "hist=model.fit(X_train,Y_train,epochs=30,batch_size=200,validation_data=(X_test,Y_test), \n",
    "               verbose=1,callbacks=[early_stopping_callback,checkpointer]) \n",
    "model.save('C:/Users/user/machine_learning1/my_cnn_model.h5')\n",
    "print('Accuracy:{}'.format(model.evaluate(X_test,Y_test)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss=hist.history['val_loss'] \n",
    "y_loss=hist.history['loss']  \n",
    "\n",
    "x_len=np.arange(len(y_loss))\n",
    "plt.plot(x_len,y_vloss,'o',marker='.',c='red',label='Testset_loss')\n",
    "plt.plot(x_len,y_loss,'o',marker='.',c='blue',label='Trainset_loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
